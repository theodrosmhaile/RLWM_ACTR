---
title: "model Analysis"
author: "Theodros H."
date: "04/12/20220"
output: 
  html_document:
    code_folding: hide
editor_options: 
  chunk_output_type: console
---


```{r set up, echo=FALSE, warning=FALSE, message=FALSE}
#rm(list = ls())
library(matlab)
library(reshape2)
library(ggplot2)
library(dplyr)
library(tidyr)
library(MLmetrics)
library(readr)
library(data.table)
library(jsonlite)
library(data.table)
library(knitr)
library(gridExtra)
source('param_influence.R')
library(Rmisc)
library(ggpubr)
```




```{r import data,  message=FALSE, warning=FALSE}
#----- import subject data
# 

sdat = fread('./RLWM_data/all_subject_n83_learn_test_data.csv', header = T) %>% t()
# sdat contains data fro 83 participants (columns), 
# rows 1:12 learn accuracy set 3 ; 
# rows 13:24 learn accuracy set 6 ;
# row 25 test set 3 accuracy ;
# row 26 test set 6 accuracy ;

#------ Modify subject data to 'weight' accuracy in test for 3 and 6 by repeating each 12x 
sdat.temp <- rep(sdat[ , 25:26], 12) %>% 
  as.matrix() %>% 
  reshape(., 996,2) %>% 
  reshape(., 166,12) 

sdat.mod  <- cbind(sdat[, 1:24], 
                   sdat.temp[1:83,], 
                   sdat.temp[84:166, ])



#----- import model data (has to be converted from JSON to data frames)
#--------- Integrated model original
# simsRL_LTMorig <- fromJSON('./outdated_sim_data/RLLTMorig_sim_data050520.JSON')
# 
#  simsRL_LTMorig.set3learn <- simsRL_LTMorig$data$set3_learn %>%
#   unlist() %>%
#   as.matrix() %>%
#   reshape(., 12, nrow(simsRL_LTMorig$data)) %>%
#   t()
# 
# simsRL_LTMorig.set6learn <- simsRL_LTMorig$data$set6_learn %>% 
#   unlist() %>% 
#   as.matrix() %>%
#   reshape(., 12, nrow(simsRL_LTMorig$data)) %>%
#   t() 
# 
# simsRL_LTMorig.s3s6test.temp <-
#   simsRL_LTMorig$data$set3_test %>%
#   cbind(., simsRL_LTMorig$data$set6_test) %>% 
#    rep(., 12) %>%
#    as.matrix() %>%
#    reshape(., nrow(simsRL_LTMorig$data)*12, 2) %>%
#    reshape(., nrow(simsRL_LTMorig$data)*2, 12) 
# 
#  RL_LTMorig.sim.dat <- cbind(simsRL_LTMorig.set3learn, 
#                          simsRL_LTMorig.set6learn, 
#                          simsRL_LTMorig.s3s6test.temp[1:nrow(simsRL_LTMorig$data), ], 
#                          simsRL_LTMorig.s3s6test.temp[244:486, ],
#                         simsRL_LTMorig$data[,c('bll','alpha','egs','imag','ans')])
# 
#  
 
 #--------- Integrated model RL to LTM pipe
simsRL_LTMpipe <- fromJSON('./RLLTM_pipe_visual_activation_050720.JSON')

 simsRL_LTMpipe.set3learn <- simsRL_LTMpipe$data$set3_learn %>%
  unlist() %>%
  as.matrix() %>%
  reshape(., 12, nrow(simsRL_LTMpipe$data)) %>%
  t()

simsRL_LTMpipe.set6learn <- simsRL_LTMpipe$data$set6_learn %>% 
  unlist() %>% 
  as.matrix() %>%
  reshape(., 12, nrow(simsRL_LTMpipe$data)) %>%
  t() 

simsRL_LTMpipe.s3s6test.temp <-
  simsRL_LTMpipe$data$set3_test %>%
  cbind(., simsRL_LTMpipe$data$set6_test) %>% 
   rep(., 12) %>%
   as.matrix() %>%
   reshape(., nrow(simsRL_LTMpipe$data) * 12, 2) %>%
   reshape(., nrow(simsRL_LTMpipe$data) *2, 12) 

 RL_LTMpipe.sim.dat <- cbind(simsRL_LTMpipe.set3learn, 
                         simsRL_LTMpipe.set6learn, 
                         simsRL_LTMpipe.s3s6test.temp[1:nrow(simsRL_LTMpipe$data), ], 
                         simsRL_LTMpipe.s3s6test.temp[244 : 486, ],
                         simsRL_LTMpipe$data[,c('bll','alpha','egs','imag','ans')]) %>% 
   data.table()

 
 
 #--------- Integrated model assigned strategy
simsRL_LTMstr <- fromJSON('./RLLTM_str_visual_activation_050720.JSON')

 simsRL_LTMstr.set3learn <- simsRL_LTMstr$data$set3_learn %>%
  unlist() %>%
  as.matrix() %>%
  reshape(., 12, nrow(simsRL_LTMstr$data)) %>%
  t()

simsRL_LTMstr.set6learn <- simsRL_LTMstr$data$set6_learn %>% 
  unlist() %>% 
  as.matrix() %>%
  reshape(., 12, nrow(simsRL_LTMstr$data)) %>%
  t() 

simsRL_LTMstr.s3s6test.temp <-
  simsRL_LTMstr$data$set3_test %>%
  cbind(., simsRL_LTMstr$data$set6_test) %>% 
   rep(., 12) %>%
   as.matrix() %>%
   reshape(., nrow(simsRL_LTMstr$data) * 12, 2) %>%
   reshape(., nrow(simsRL_LTMstr$data) *2, 12) 

 RL_LTMstr.sim.dat <- cbind(simsRL_LTMstr.set3learn, 
                         simsRL_LTMstr.set6learn, 
                         simsRL_LTMstr.s3s6test.temp[1:nrow(simsRL_LTMstr$data), ], 
                         simsRL_LTMstr.s3s6test.temp[973 : 1944, ],
                         simsRL_LTMstr$data[,c('bll','alpha','egs','imag','ans')]) %>% 
   data.table()
 
 

#--------- Reinforcement Learning Model

simsRL <- fromJSON('./outdated_sim_data/RL_sim_data_3lvsparams_050420.JSON')

 simsRL.set3learn <- simsRL$data$set3_learn %>%
  unlist() %>%
  as.matrix() %>%
  reshape(., 12, nrow(simsRL$data)) %>%
  t() 

 
 
simsRL.set6learn <- simsRL$data$set6_learn %>% 
  unlist() %>% 
  as.matrix() %>%
  reshape(., 12, nrow(simsRL$data)) %>%
  t() 

 simsRL.s3s6test.temp <-
  simsRL$data$set3_test %>%
  cbind(., simsRL$data$set6_test) %>% 
   rep(., 12) %>%
   as.matrix() %>%
   reshape(., nrow(simsRL$data)*12, 2) %>%
    reshape(., nrow(simsRL$data)*2, 12) 
 

 RL.sim.dat <- cbind(simsRL.set3learn, 
                     simsRL.set6learn, 
                     simsRL.s3s6test.temp[1:nrow(simsRL$data), ], 
                     simsRL.s3s6test.temp[10:18, ] , 
                     simsRL$data[,c('bll','alpha','egs','imag','ans')]) %>%  
   data.table()

#--------- Longterm Memory/WM/Declarative model 
 
simsLTM    <- fromJSON('LTM_simdata_0708.JSON')#LTM_visual_activation_allparams_evals26.JSON')#('LTM_sim_data_3lvparams_050420.JSON') 

 simsLTM.set3learn <- simsLTM$data$set3_learn %>%
  unlist() %>%
  as.matrix() %>% 
  reshape(., 12, nrow(simsLTM$data)) %>% 
  t()

simsLTM.set6learn <- simsLTM$data$set6_learn %>% 
  unlist() %>% 
  as.matrix() %>%
  reshape(., 12, nrow(simsLTM$data)) %>%
  t()

simsLTM.s3s6test.temp <-  simsLTM$data$set3_test %>%
  cbind(., simsLTM$data$set6_test) %>% 
   rep(., 12) %>% 
   as.matrix() %>% 
   reshape(., 1500, 2) %>% 
   reshape(., nrow(simsLTM$data)*2, 12) #54= nrow(sims.LTM) * 2

 
LTM.sim.dat <- cbind(simsLTM.set3learn, 
                      simsLTM.set6learn, 
                      simsLTM.s3s6test.temp[1:125, ], 
                      simsLTM.s3s6test.temp[126:250, ],
                     simsLTM$data[,c('bll','alpha','egs','imag','ans')])  %>% 
   data.table()


 
 # LTM.sim.dat <- cbind('set3_learn'=simsLTM.set3learn %>% c(), 
  #                    'set6_learn'=simsLTM.set6learn %>% c(),
   #                   'time'=rep(1:12,324/12),
    #                  'set3_test'=simsLTM.s3s6test.temp[1:27, ] %>% c(), 
     #                 'set6_test'=simsLTM.s3s6test.temp[28:54, ] %>% c(), 
      #                simsLTM$data[,c('bll','alpha','egs','imag','ans')]) %>% 
   #data.table()
 
 
 
```


### These plots show how accuracy during learning and test change as parameter values go up:
### RL only on left, LTM only second, RL_LTM meta RL, RL_LTM explicit strategy. 


```{r model description analysis and plots,  message=FALSE, warning=FALSE, fig.height=12,fig.width=12}

#------Descriptive measures: learning rate (beta), accuracy learn & Test, differences between learn3 and learn 6
#--------select data for each level of parameters per model
# RL.params        <- param.influence(RL.sim.dat, 'RL')
# RLLTMpipe.params <- param.influence(RL_LTMpipe.sim.dat, 'RLLTM')
# RLLTMstr.params  <- param.influence(RL_LTMstr.sim.dat, 'RLLTM')
# LTM.params       <- param.influence(LTM.sim.dat, 'LTM')
# 
# tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
# 
# 
# 
# 
# p1 <- RL.params %>% 
#   melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>% 
#   ggplot(aes(level, accuracy, color=variable)) + 
#   geom_point()+
#   geom_line() +
#   facet_grid('parameter')+
#   theme_bw(base_size = 16, base_line_size = 1)+
#    scale_color_manual(values = tmp.color)+
#   ylim(c(.3,1)) +
#  theme(legend.position='none')
#    #scale_colour_brewer( palette = "RdBu", direction = 1) 
# 
# 
# p2 <- LTM.params %>% 
#   melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>% 
#   ggplot(aes(level, accuracy, color=variable)) + 
#   geom_point()+
#   geom_line() +
#    ylim(c(.3,1)) +
#   facet_grid('parameter')+
#   theme_bw(base_size = 16, base_line_size = 1)+
#    scale_color_manual(values = tmp.color)+
#   theme(legend.position='none')
# 
# 
# p3 <- RLLTMpipe.params %>% 
#   melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>% 
#   ggplot(aes(level, accuracy, color=variable)) + 
#   geom_point()+
#   geom_line() +
#    ylim(c(.3,1)) +
#   facet_grid('parameter')+
#   theme_bw(base_size = 16, base_line_size = 1)+
#    scale_color_manual(values = tmp.color)+
#    theme(legend.position='bottom', legend.direction = 'horizontal')
# 
# p4 <- RLLTMstr.params %>% 
#   melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>% 
#   ggplot(aes(level, accuracy, color=variable)) + 
#   geom_point()+
#   geom_line() +
#    ylim(c(.3,1)) +
#   facet_grid('parameter')+
#   theme_bw(base_size = 16, base_line_size = 1)+
#    scale_color_manual(values = tmp.color)+
#   
#   
# 
# grid.arrange(p1,p2,p3, nrow=3)

```

### The Explicit RL_LTM model fits the most people, followed by the LTM model (second from left)


```{r fit model data to subject data, message=FALSE, warning=FALSE}

#(1) Transform RMSE into residual sum of squares by doing RSS = RMSE^2 * n
#11:34
#(2) Calculate BIC as: BIC = n + n log (2*pi) + n log (RSS/n) + log(n) * (k + 1)
#11:36
#In RL, k = 2; in LTM, k = 3; and Integrated, k = 5 or k = 6




Andys_BIC <- function(rmse, k) {
  
  # RSS first
  n = 48 #lean3 + learn 6 + (test3)*12 + (test6)*12
  RSS <- ((rmse)^2) * n
  
  # BIC next
  bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
  
  return(bic)
}


#----- loop through subject data and check for fit against model data using mean squared error. 


mseRL.temp         =c()
mseLTM.temp        =c()
mseRL_LTMorig.temp =c()
mseRL_LTMpipe.temp =c()
mseRL_LTMstr.temp  =c()

for(s in c(1:nrow(sdat.mod))) { # for each subject
 # model 1 
 mseRL.temp     <- rbind(mseRL.temp, apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
                         )
 # model 2
 mseLTM.temp    <- rbind(mseLTM.temp, apply(LTM.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ] )) %>%  sqrt()
                         )
 
 # model 3
 # mseRL_LTMorig.temp <- rbind(mseRL_LTMorig.temp, 
                             # apply(RL_LTMorig.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
                             # )
 # model 3.1
 mseRL_LTMpipe.temp <- rbind(mseRL_LTMpipe.temp, 
                             apply(RL_LTMpipe.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
                             )
 # model 3.2
mseRL_LTMstr.temp  <- rbind(mseRL_LTMstr.temp, 
                            apply(RL_LTMstr.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
                            )
  
}

#------ Exrtact row indices to get parameter set of parameters for best fit model

#------------first find the smallest BIC
RL.bic = Andys_BIC(mseRL.temp, 2)
LTM.bic = Andys_BIC(mseLTM.temp, 3)
RL_LTMpipe.bic = Andys_BIC(mseRL_LTMpipe.temp, 5)
RL_LTMstr.bic = Andys_BIC(mseRL_LTMstr.temp, 6)

RL.fit     = as.matrix(apply(RL.bic , 1, min))   
LTM.fit    = as.matrix(apply(LTM.bic , 1, min))  
# RL_LTMorig.fit = as.matrix(apply(   (mseRL_LTMorig.temp), 1, min))
RL_LTMpipe.fit = as.matrix(apply(RL_LTMpipe.bic, 1, min)) 
RL_LTMstr.fit = as.matrix(apply(RL_LTMstr.bic , 1, min))


#temp <- mdat.3 %>% 
#  data.table() %>% 
#  .[,`:=`(V66 = V3 - mean(V3))]


#-------------second, find actual row number using smallest value


ind.temp.RL <- c()
ind.temp.RL_LTMorig <- c()
ind.temp.RL_LTMstr <- c()
ind.temp.RL_LTMpipe <- c()
ind.temp.LTM <- c()

for ( i in 1:length(RL.fit)) {
  ind.temp.RL <- rbind(ind.temp.RL, which(RL.bic[i,] %in% RL.fit[i]))
  
}

for ( i in 1:length(LTM.fit)) {
  ind.temp.LTM <- rbind(ind.temp.LTM, which(LTM.bic[i,] %in% LTM.fit[i]))
  
}
# for ( i in 1:length(RL_LTMorig.fit)) {
#   ind.temp.RL_LTMorig <- rbind(ind.temp.RL_LTMorig, 
#                                which(mseRL_LTMorig.temp[i,] %in% RL_LTMorig.fit[i]))
#   
# }

for ( i in 1:length(RL_LTMpipe.fit)) {
  ind.temp.RL_LTMpipe <- rbind(ind.temp.RL_LTMpipe, 
                           which(RL_LTMpipe.bic[i,] %in% RL_LTMpipe.fit[i]))
  
}

for ( i in 1:length(RL_LTMstr.fit)) {
  ind.temp.RL_LTMstr <- rbind(ind.temp.RL_LTMstr, which(RL_LTMstr.bic[i,] %in% RL_LTMstr.fit[i]))
  
}


#--------which model fits a participant most?
#1= RL; 2= LTM; 3 = RL_LTMpipe; 4 = RL_LTMstr





#--------------There are no min.col functions? Work around find the max after inverting:
participants.fit=c()
model.fits <- data.frame(RL.fit, LTM.fit, RL_LTMpipe.fit, RL_LTMstr.fit)#, fit.labels)
participant.min <- apply(model.fits, 1, min)
     
for (s in 1:nrow(model.fits)){

       participants.fit = rbind(participants.fit, which(participant.min[s] == model.fits[s,]))
     }
          
```

```{r model fit plots}
#fit plots
#participants.fit %>% 
 # hist(main='Counts of participants by model', xlab = ("1= RL; 2= LTM; 3=RL_LTM"), #lwd=4.3)

fit.labels <- ifelse(participants.fit==2, 'LTM', 
                     ifelse(participants.fit==3, 'RL-LTM',
                            ifelse(participants.fit==4,'RL-LTMexplicit','RL')
                            )
                     )

models.name=c('RL', 'LTM', ' RL-LTM', 'RL-LTM biased')
data.frame('model'= participants.fit)  %>% 
 
   ggplot(aes(factor(model), fill=factor(model))) + 
  geom_bar() +
   ggtitle('Counts of participants by model') +
  theme_minimal(base_size = 20)+
  scale_x_discrete(labels=models.name )+
  xlab("Models")+
   scale_fill_brewer( palette = "Paired")+
theme(legend.position='none') 
  
#theme_pan


model.fits %>% 
  melt() %>% 
  ggplot(aes(y=value,variable, group=variable)) +
  geom_boxplot() + 
  ggtitle('BIC')+
  xlab('model')+
  theme_bw() +
  theme(legend.position='none') +
   scale_colour_brewer( palette = "Set1") 

```


### These plots show mean learning curves for all participants and all parameter combinations -  this should show poor fit since we are collapsing across a lot of variability.
```{r model vs participant plots,  message=FALSE, warning=FALSE, fig.height=18, fig.width=6}
plt.sim.rl <- data.frame('accuracy'= c(RL.sim.dat[,1:12] %>% t() %>% c(), 
                                       sdat[,1:12] %>% t() %>% c(),
                                       RL.sim.dat[,13:24] %>% t() %>% c(),
                                       sdat[,13:24] %>% t() %>% c()),
                         'index'=rep(1:12,184),
                         'condition'=c(rep('set3_model', 12*9),rep('set3_data', 12*83), rep('set6_model',12*9), rep('set6_data', 12*83))
                         ) # the numbers are counts of learn trials for set 3 and 6 along with models

sim.p1 <- plt.sim.rl %>% 
  summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy, color=condition, group=condition))+
   #geom_smooth(aes(color=condition, fill=condition), method = lm, formula = 'y~poly(x,2)', size=2) +
  geom_point() +
  geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
  scale_color_manual(values = tmp.color)+ #scale_colour_brewer( palette = "Set1") +
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
   theme(legend.position='top',legend.direction = 'horizontal')


plt.sim.ltm <- data.frame('accuracy'= c(LTM.sim.dat[,1:12] %>% t() %>% c(),
                                         sdat[,1:12] %>% t() %>% c(),
                                        LTM.sim.dat[,13:24] %>% t() %>% c(),
                                         sdat[,13:24] %>% t() %>% c()), 
                          'index'= rep(1:12,220), 
                          'condition'= c(rep('set3_model', 12*27),rep('set3_data', 12*83), rep('set6_model',12*27), rep('set6_data', 12*83))
                          )

sim.p2 <- plt.sim.ltm %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ # scale_colour_brewer( palette = "Set1") +
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('LTM: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')


 plt.sim.rl_ltmpipe <- data.frame('accuracy'= c(RL_LTMpipe.sim.dat[,1:12] %>% t() %>% c(), 
                                           sdat[,1:12] %>% t() %>% c(),
                                           RL_LTMpipe.sim.dat[,13:24] %>% t() %>% c(),
                                           sdat[,13:24] %>% t() %>% c()),
                             'index'=rep(1:12,652),
                              'condition'= c(rep('set3_model', 12*243),rep('set3_data', 12*83), rep('set6_model',12*243), rep('set6_data', 12*83))
                             )


sim.p3 <- plt.sim.rl_ltmpipe %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ #
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL_LTM pipe: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')


 plt.sim.rl_ltmstr <- data.frame('accuracy'= c(RL_LTMstr.sim.dat[,1:12] %>% t() %>% c(), 
                                           sdat[,1:12] %>% t() %>% c(),
                                           RL_LTMstr.sim.dat[,13:24] %>% t() %>% c(),
                                           sdat[,13:24] %>% t() %>% c()),
                             'index'=rep(1:12,2110),
                              'condition'= c(rep('set3_model', 12*972),rep('set3_data', 12*83), rep('set6_model',12*972), rep('set6_data', 12*83))
                             )


sim.p4 <-plt.sim.rl_ltmstr %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ #
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL_LTM str: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')

grid.arrange(sim.p1, sim.p2, sim.p3, ncol=1)

```


### These are the same plots but filtered for participants who fit that model best. These plots should show good fit....but they don't really. Especially the last model that fit the most people/ I'm planning about two more plots that show variabiltiy in parameters within the model groups. 

```{r model vs fitted participant plots ,  message=FALSE, warning=FALSE, fig.height=18, fig.width=6}
plt.sim.fit.rl <- data.frame('accuracy'= c(RL.sim.dat[,1:12] %>% t() %>% c(), 
                                       sdat[participants.fit==1, 1:12] %>% t() %>% c(),
                                       RL.sim.dat[, 13:24] %>% t() %>% c(),
                                       sdat[participants.fit==1,13:24] %>% t() %>% c()),
                             
                         'index'=rep(1:12, (nrow(RL.sim.dat)+nrow(sdat[participants.fit==1,]))*2),
                        
                          'condition'=c(rep('set3_model', 12*9),
                                       rep('set3_data', 12*sum(participants.fit==1)), 
                                       rep('set6_model',12*9), 
                                       rep('set6_data', 12*sum(participants.fit==1)))
                         ) # the numbers are counts of learn trials for set 3 and 6 along with models

sim.fit.p1 <- plt.sim.fit.rl %>% 
  summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy, color=condition, group=condition))+
   #geom_smooth(aes(color=condition, fill=condition), method = lm, formula = 'y~poly(x,2)', size=2) +
  geom_point() +
  geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
  scale_color_manual(values = tmp.color)+ #scale_colour_brewer( palette = "Set1") +
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
   theme(legend.position='top',legend.direction = 'horizontal')


plt.sim.fit.ltm <- data.frame('accuracy'= c(LTM.sim.dat[,1:12] %>% t() %>% c(),
                                         sdat[participants.fit==2,1:12] %>% t() %>% c(),
                                        LTM.sim.dat[,13:24] %>% t() %>% c(),
                                         sdat[participants.fit==2,13:24] %>% t() %>% c()), 
                              
                          'index'= rep(1:12,(nrow(LTM.sim.dat) + nrow(sdat[participants.fit==2,]))*2), 
                          'condition'= c(rep('set3_model', 12*27),
                                         rep('set3_data', 12*sum(participants.fit==2)), 
                                         rep('set6_model',12*27), 
                                         rep('set6_data', 12*sum(participants.fit==2)))
                          )

sim.fit.p2 <- plt.sim.fit.ltm %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ # scale_colour_brewer( palette = "Set1") +
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('LTM: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')


 plt.sim.fit.rl_ltmpipe <- data.frame('accuracy'= c(RL_LTMpipe.sim.dat[,1:12] %>% t() %>% c(), 
                                           sdat[participants.fit==3,1:12] %>% t() %>% c(),
                                           RL_LTMpipe.sim.dat[,13:24] %>% t() %>% c(),
                                           sdat[participants.fit==3,13:24] %>% t() %>% c()),
                                      
                             'index'=rep(1:12,(nrow(RL_LTMpipe.sim.dat) + nrow(sdat[participants.fit==3,]) )*2),
                              'condition'= c(rep('set3_model', 12*243),
                                             rep('set3_data', 12*sum(participants.fit==3)), 
                                             rep('set6_model',12*243), 
                                             rep('set6_data', 12*sum(participants.fit==3)))
                             )


sim.fit.p3 <- plt.sim.fit.rl_ltmpipe %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ #
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL_LTM pipe: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')


 plt.sim.fit.rl_ltmstr <- data.frame('accuracy'= c(RL_LTMstr.sim.dat[,1:12] %>% t() %>% c(), 
                                           sdat[participants.fit==4,1:12] %>% t() %>% c(),
                                           RL_LTMstr.sim.dat[,13:24] %>% t() %>% c(),
                                           sdat[participants.fit==4,13:24] %>% t() %>% c()),
                                     
                             'index'=rep(1:12,(nrow(RL_LTMstr.sim.dat) + nrow(sdat[participants.fit==4, ]))*2),
                             
                              'condition'= c(rep('set3_model', 12*972),
                                             rep('set3_data', 12*sum(participants.fit==4)),
                                             rep('set6_model',12*972), 
                                             rep('set6_data', 12*sum(participants.fit==4)))
                             )


sim.fit.p4 <-plt.sim.fit.rl_ltmstr %>% 
   summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy,color=condition, group=condition))+
   geom_point() +
   geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_color_manual(values = tmp.color)+ #
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0.2,1))+
  #scale_x_discrete(limits = 1:12,)+
  ggtitle('RL_LTM str: mean performance across parameter sets') +
  theme_bw(base_family = 'Calibri')+
  theme(legend.position='none')

grid.arrange(sim.fit.p1, sim.fit.p2, sim.fit.p3, sim.fit.p4, nrow=4, ncol=1)

```


```{r unique fits}
# unique.RL_LTM.models <- ind.temp.RL_LTM[participants.fit==3] %>% unique()
# unique.LTM.models <- ind.temp.LTM[participants.fit==2] %>% unique()


```



```{r}

# 
#  temp.RL_LTM = cbind((simsRL_LTMpipe$data[ind.temp.RL_LTMpipe[participants.fit==3] %>% unique(), c('alpha','egs','bll','imag','ans')]),  
#          
#                       'index'= c(1:length(unique(ind.temp.RL_LTMpipe[participants.fit==3]))))
# 
# temp.RL_LTM %>%
#   data.table() %>% 
#   melt.data.table(id.vars ='index'#, measure.vars=c('alpha','egs','bll','imag','ans') 
#                   ) %>% 
#   .[,`:=`(nu = (value-mean(value))/sd(value)), by = .(variable)] %>% 
#   # # dplyr::group_by(variable) %>% 
#   # # mutate(value=scale(value)) %>% ungroup() %>% View()
#   ggplot() +
#   geom_point(aes(variable, nu, color= as.factor(index))) +
#   geom_line(aes(variable, nu, color= as.factor(index)))
# 
# 
# 
# simsRL_LTMpipe$data[ind.temp.RL_LTMpipe[participants.fit==3],c('alpha','egs','bll','imag','ans')]   %>%
#   scale() %>% as.data.frame() %>%
#   gather(key='parameter', value = 'value') %>%
#   ggplot(aes(parameter,value, color=parameter)) +
#  # geom_density()+
#   geom_point()+
#   #geom_line()+
#  # facet_grid(aes(color=parameter), facets = 'parameter')+
#   theme_bw() +
#   theme(legend.position='none')
# 
# 
# simsLTM$data[ind.temp.LTM[participants.fit==3],c('bll','imag','ans')]   %>%
#   scale() %>% as.data.frame() %>%
#   gather(key='parameter', value = 'value') %>%
#   ggplot(aes(parameter,value, fill=parameter)) +
#  # geom_density()+
#   geom_point()+
#  # facet_grid(aes(color=parameter), facets = 'parameter')+
#   theme_bw() +
#   theme(legend.position='none')
# 
# 
# 
# 
# 
# 
#   #geom_histogram(aes(fill=parameter), show.legend = FALSE, bins = 5) +
#   #geom_density(show.legend = FALSE) +
#   facet_grid(aes(color=parameter), facets = 'parameter')+
#    theme_bw(base_family = 'Calibri')
# 
# 
# simsLTM$data[ind.temp.LTM[participants.fit==2],c('bll','imag','ans')]   %>%
#   scale(center=FALSE) %>% as.data.frame() %>%
#   gather(key='parameter', value = 'value') %>% zz
# 
# 
#   hlp %>%
#    melt(id.vars = c('sub')) %>%
#   ggplot(aes(value)) +
#   #geom_histogram(aes(fill=variable), show.legend = FALSE, bins = 5 ) +
#     geom_col(aes(as.factor(variable), value, fill = variable)) +
#              #geom_density(show.legen#zzd = FALSE) +
#     facet_wrap(.~sub)+
#   #facet_grid( .~sub)+
#    theme_classic(base_family = 'Calibri') +
#     the

```




```{r function for model plotting, warning=FALSE, message=FALSE, echo=FALSE, fig.height=18, fig.width=6}

plot_model  <- function(model.id, model.dat){
  
  
  if (model.id==1) { temp.model.index =unique(ind.temp.RL)}
  if (model.id==2) {temp.model.index =unique(ind.temp.LTM)}
  if (model.id==3) {temp.model.index = unique(ind.temp.RL_LTMpipe)}
  if (model.id==4) {temp.model.index = unique(ind.temp.RL_LTMstr)}
  
  
  
temp.dat.frame <- data.frame('accuracy'= c( sdat[, 1:12] %>% t() %>% c(),
                                           sdat[ ,13:24] %>% t() %>% c()),
                             
                         'index'=rep(1:12, (nrow(sdat[]))*2),
                        
                          'condition'=c( rep('set 3', 12 * 83), 
                                       rep('set 6', 12* 83))
                         ) # the numbers are counts of learn trials for set 3 and 6 along with models

 temp.dat.frame %>% 
  summarySE( measurevar = "accuracy", groupvars = c("index", "condition")) %>% 
  ggplot(aes(factor(index), accuracy, color=condition, group=condition))+
   #geom_smooth(aes(color=condition, fill=condition), method = lm, formula = 'y~poly(x,2)', size=2) +
  geom_point() +
  geom_line() +
   geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) +
   scale_colour_brewer( palette = "Set1") +#scale_color_manual(values = tmp.color)+
  ylab('Accuracy') + 
  xlab('Number of stimulus presentations') +
  xlim(as.character(1:12) )+
  ylim(c(0,1))+
  #scale_x_discrete(limits = 1:12,)+
  #ggtitle('RL: mean performance across parameter sets') +
   
   theme_minimal(base_size = 20)+
  theme(legend.position='bottom',legend.direction = 'horizontal') +
   ggtitle('Learning phase')
  

}




plot_test <- function(model.id, model,dat){
  
  
    if (model.id==1) { temp.model.index =unique(ind.temp.RL)}
  if (model.id==2) {temp.model.index =unique(ind.temp.LTM)}
  if (model.id==3) {temp.model.index = unique(ind.temp.RL_LTMpipe)}
  if (model.id==4) {temp.model.index = unique(ind.temp.RL_LTMstr)}
  
  
  
temp.dat.frame <- data.frame('accuracy'= c(model.dat[temp.model.index, 1:12] %>% t() %>% c(), 
                                       sdat[, 1:12] %>% t() %>% c(),
                                       model.dat[temp.model.index, 13:24] %>% t() %>% c(),
                                       sdat[ ,13:24] %>% t() %>% c()),
                             
                         'index'=rep(1:12, (length(temp.model.index) + nrow(sdat[]))*2),
                        
                          'condition'=c(rep('set3_model', 12 * length(temp.model.index)),
                                       rep('set3_data', 12 * 83), 
                                       rep('set6_model',12 * length(temp.model.index)), 
                                       rep('set6_data', 12* 83))
                         ) 
  
  
}



ggarrange(plot_model(1,RL.sim.dat), 
             plot_model(2,LTM.sim.dat), 
             plot_model(3,RL_LTMpipe.sim.dat), 
           
              ncol=1, common.legend = TRUE)

# grid.arrange(plot_model(1,RL.sim.dat), 
#              plot_model(2,LTM.sim.dat), 
#              plot_model(3,RL_LTMpipe.sim.dat), 
#              plot_model(4,RL_LTMstr.sim.dat),
#              nrow=4, ncol=1)

```



