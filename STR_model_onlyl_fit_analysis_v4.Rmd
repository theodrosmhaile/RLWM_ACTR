---
title: "RLWM ACT-R Fitting STR-learning model only"
author: "Theodros H."
date: "03/2023"
output:
  html_document:
    code_folding: hide
    toc: no
  word_document:
    toc: no
editor_options:
  chunk_output_type: console
---

```{css, echo=FALSE} 

 p{ 

   font-size: 18px;

 }
 
 img{
 max-width: 100%
}
body{
  : 0px
}

``` 

```{r set up, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

library(MASS)
library(ggpubr)
library(matlab)
library(MLmetrics)
library(jsonlite)
library(knitr)
library(Rmisc)
library(magrittr)
library(data.table)
library(skimr)
library(tidyverse)
knitr::opts_chunk$set(
  comment = "#>", echo = FALSE, warning = FALSE, 
  message = FALSE, dpi = 300
 
)
theme_set(theme_pubclean(base_size = 12)) 

```

# Results

```{r SUBJECTS: import  data}
# sdat contains data fro 83 participants (columns), 
# rows 1:12 learn accuracy set 3; 
# rows 13:24 learn accuracy set 6;
# row 25 test set 3 accuracy;
# row 26 test set 6 accuracy;
splitDat=FALSE

subjects = read.csv("./RLWM_data/wmo_subjects_across_studies_031820.csv", header = F)
colnames(subjects)='subjects'
sdat.temp = fread('./RLWM_data/all_subject_n83_learn_test_data.csv', header = T) %>% t()

sdat <- cbind(
  sdat.temp[ ,1:12],
                   matrix(sdat.temp[ ,25],
                          nrow = numel(sdat.temp[ ,25]), ncol = 12),
                   sdat.temp[ ,13:24],
                  matrix(sdat.temp[ ,26],nrow = numel(sdat.temp[ ,25]), ncol = 12) )

colnames(sdat) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12)))



if(splitDat){

sdat.h1 = read.csv('./RLWM_data/Half1_all_subject_n83_learn_test_data.csv',header = T) 
h1.subjects <-  sdat.h1$V1
sdat.h1 <- sdat.h1[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h1 <- cbind(
  sdat.h1[ ,1:12],
                   matrix(sdat.h1[ ,25],
                          nrow = numel(sdat.h1[ ,25]), ncol = 12),
                   sdat.h1[ ,13:24],
                  matrix(sdat.h1[ ,26],nrow = numel(sdat.h1[ ,25]), ncol = 12) )

colnames(sdat.repl.h1) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12)))

sdat.h2 = read.csv('./RLWM_data/Half2_all_subject_n83_learn_test_data.csv', header = T) 

h2.subjects <-  sdat.h2$V1
sdat.h2 <- sdat.h2[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h2 <- cbind(sdat.h2[ ,1:12],
                   matrix(sdat.h2[ ,25],
                          nrow = numel(sdat.h2[ ,25]), ncol = 12),
                   sdat.h2[ ,13:24],
                  matrix(sdat.h2[ ,26],
                         nrow = numel(sdat.h2[ ,25]), ncol = 12) )

colnames(sdat.repl.h2) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12))
                          )



#  "model"     "index"     "subjects"  "name"      "condition" "iteration" "accuracy"  "type"     
subject.dat <- 
  sdat.repl.h1 %>% 
  dplyr::mutate(half ='half1', 
                subjects = h1.subjects) %>% 
  rbind(sdat.repl.h2 %>% 
          mutate(half='half2', 
                 subjects= h1.subjects))
  
  subject.dat %<>%   
  dplyr::mutate(
         'type' = 'behavioral' 
        # ,'parameter' = NA, 
      #   'param_vals'= NA
        ) %>% 
  pivot_longer(cols = -c(half,type, subjects), names_to = 'temp_condition', values_to = 'accuracy') %>% #, parameter, param_vals
  separate(temp_condition, into = c('condition','iteration'), sep = '[/.]')
  }
```

```{r MODELS: import  data}
STR.sim <- fromJSON('./simulated_data/strategy_model/STR_sim_data_032021.JSON')$data %>% 
  dplyr::mutate(bias = str_remove_all(strtg, "[:alpha:]") %>% as.numeric()/100, .keep=c('unused'))
RL.sim <- fromJSON('./simulated_data/RL_model/RL_sim_data_07_12_2022.JSON')$data %>% 
  dplyr::mutate(bias = 0)
LTM.sim <- fromJSON('./simulated_data/LTM_model/LTM_sim_data_02202021.JSON')$data %>% 
  dplyr::mutate(bias = 0 )
META.sim <- fromJSON('./simulated_data/pipe_model/pipe_sim_data_032021.JSON')$data %>% 
   dplyr::mutate(bias = strtg,
          bias3 = strtg3,
          bias6 = strtg6, .keep='unused')

```

```{r functions}

#(1) Transform RMSE into residual sum of squares by doing RSS = RMSE^2 * n
#11:34
#(2) Calculate BIC as: BIC = n + n log (2*pi) + n log (RSS/n) + log(n) * (k + 1)
#11:36
#In RL, k = 2; in LTM, k = 3; and Integrated, k = 5 or k = 6

#MAP 
Andys_BIC <- function(rmse, k, n) {
  # RSS first
  #n = 48 #lean3 + learn 6 + (test3)*12 + (test6)*12
  RSS <- ((rmse)^2) * n
  # BIC next
  bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
  
  return(bic)
}


fit.subject <- function(behav.dat, model.dat){

apply(model.dat, 1, function(x,y) MSE(x, behav.dat)) %>% sqrt()
   
}

fit.models.unsplit <- function(model,dat, params, BIC.only) {
  
  #select model
  if (model == 'RL') {
    sim.mod = RL.sim
  }
  if (model == 'LTM') {
    sim.mod = LTM.sim
  }
  if (model == 'STR') {
    sim.mod = STR.sim
  }
  if (model == 'META') {
    sim.mod = META.sim
  }
  #select half
  # if (half == 1) {
  #   sdat = sdat.repl.h1
  # } 
  # if(half == 2) {
  #   sdat = sdat.repl.h2
  # }

  sdat = dat
  
sim.learn = sim.mod$set3_learn %>% 
    reduce(rbind) %>%  
  cbind(sim.mod$set6_learn %>% reduce(rbind)) 
                      
  
  sim.test =  matrix(
                sim.mod$set3_test,
              nrow = numel(sim.mod$set3_test),
              ncol = 12) %>% 
    cbind(matrix(
                sim.mod$set6_test,
              nrow = numel(sim.mod$set6_test),
              ncol = 12))
  
  if (BIC.only){
  apply( sdat, 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 48)
  }
  
  else {
    apply( sdat, 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) 
    
  }
}

fit.models <- function(model, half, setsize, params) {
  #select model
  # if (model == 'RL') {
  #   model = RL.sim
  # }
  # if (model == 'LTM') {
  #   model = LTM.sim
  # }
  # if (model == 'STR') {
  #   model = STR.sim
  # }
  # if (model == 'META') {
  #   model = META.sim
  # }
  # 
  # select subject data
  if (half == 1) {
    sdat = sdat.repl.h1
  } 
  if(half ==2) {
    sdat = sdat.repl.h2
  }
 
  # select setsize
  
  if (setsize == 3) {
    ns = 1:24
    n_size = 'set3_'
  } 
  
  if(setsize == 6){
    ns = 25:48
  
    n_size='set6_'
  }
 
  
  sim.learn = eval(
      parse(text=paste0(model,'.sim$',n_size, 'learn')
                                 )
                           ) %>% 
    reduce(rbind)
                      
  
  sim.test =  matrix(
              eval(
                parse(text=paste0(model,'.sim$',n_size, 'test'))),
              nrow = numel(eval(parse(text=paste0(model,'.sim$',n_size, 'test')))),
              ncol = 12)
 
  
  apply( sdat[, ns], 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 24)
  
}


get_data = function(data, data_name){
  bind_rows(
    c('set3_learn','set6_learn') %>% 
      map(~
            #column is measurement at T, record is simulation
            data %>% 
            .[[.x]] %>% 
            reduce(rbind) %>% 
            data.frame() %>% 
            mutate(condition = .x, 
                   model_index= c(1:nrow(data))
            )
      ) %>% 
      reduce(bind_rows) %>% 
      pivot_longer(cols = starts_with('x')
                   ,values_to = 'accuracy', names_to = 'iteration'),
    
      ####### implemented fix to out of sync model_id and iteration numbers TMH 07/31/2023
    
    c('set3_test', 'set6_test') %>% #, 'bias' 'alpha','egs', 'bll', 'imag','ans'
      map (~
             {
               temp = data %>% 
                 .[[.x]] 
               
               data.frame(
                  model_index= c(1:nrow(data)),
                 condition=.x, 
                 iteration= paste0('X',matrix(1:12,12, nrow(data)) %>% t() %>% c()), 
                 accuracy=rep(temp, 12)
               )
               
             }
      )
  
  ) %>%  
    mutate(data_source = data_name)
}






```

# PART I

In this section, learning data were split into first half and second half and fit separately. The two set-sizes were fit together. Are learning outcomes for the 2 halves correlated?



```{r PART I: fit subjects with models}
if (splitDat){
  ##########--------RL fits----------------############

RL.BIC.H1 <-  fit.models.unsplit(model = 'RL', half = 1, 2)
RL.BIC.H2 <-  fit.models.unsplit(model = 'RL', half = 2, 2)

##########---------LTM FITS ----------------############

LTM.BIC.H1 <- fit.models.unsplit('LTM', half = 1, 3)
LTM.BIC.H2 <- fit.models.unsplit('LTM', half = 2, 3)

##########---------RL-LTMstr FITS ----------------############

STR.BIC.H1 <- fit.models.unsplit('STR', half = 1, 6)
STR.BIC.H2 <- fit.models.unsplit('STR', half = 2, 6)
}
##########---------RL-LTMmeta FITS ----------------############

STR.BIC <- fit.models.unsplit('STR', sdat, 6, TRUE) %>%
  as_tibble() %>%
  mutate(model='STR', model.id=c(1:nrow(STR.sim)) ) 
  
STR.rmse <- 
  fit.models.unsplit('STR', sdat, 6, FALSE) %>%
  as_tibble() %>% 
    mutate( model.id=c(1:nrow(STR.sim)) ) 
```

```{r PART1 select best fits}


best.fits <-
   STR.BIC %>%
  select(-model, -model.id) %>% 
  apply(., 2, which.min) %>%
   as_tibble() %>% 
  mutate(model = value, 
         subjects, 
         .keep='unused')
#### RMSE comparison


best.fits.rmse <-
  STR.rmse %>%
  rename(model=model.id) %>% 
  pivot_longer(cols = -model, names_to = 'subid', values_to = 'RMSE') %>%
  inner_join(best.fits %>%
               mutate(sub.order = paste0('V', 1:83)), by='model') %>%
  mutate(Picks = subid==sub.order) %>%
  filter(Picks) %>%
   select(-subid, -sub.order, -Picks, -model) %>%
   rename(RMSE.STR = RMSE)

#write_csv(best.fits.rmse, 'STR_only_fit_RMSE_stag_2023.csv')

  
```



```{r part B join model-behavioral data}


all_sims = list(list( STR.sim), #, STR.sim, META.sim remvoed the two combined models
     list("STR")) %>%  #, "STR", "META" Removed the two combined models
  pmap(get_data) %>%  
  reduce(bind_rows) %>% 
  mutate(iteration = str_remove_all(iteration, "[:alpha:]") %>%  
           as.numeric(), 
         type ='model' )

best.fits.temp <- best.fits %>% rename(model_index = model)  

index_search <- all_sims %>% 
  inner_join(best.fits.temp, by='model_index')


######### make subject.dat 
subject.dat <- 
  sdat %>% 
  cbind(subjects) %>% 
  pivot_longer(cols = -subjects, 
               names_to = 'condition', values_to = 'accuracy') %>% 
  separate('condition', into = c('condition', 'iteration'), sep = "[/.]") %>% 
    mutate(type='behavioral') %>% 
  inner_join(best.fits, by='subjects') %>% 
  rename(model_index = model)

  
  
melted.p.behav.model <-
  rbind(subject.dat, index_search %>% select(-data_source))




parameter.dat <- 
  STR.sim %>% 
  select(index, 'alpha','egs', 'bll', 'imag','ans', 'bias') %>%
  rename(model_index=index) %>% 
  inner_join(best.fits %>% rename(model_index=model))


 
  
  
  
  
```


```{r comparison for Ex1 and Ex2}
ex1.fits = read_csv('RMSE_fit_model_dat_07_2022.csv') %>%
  select(subjects, model, bias)



ex1.ex2.comp <-
  best.fits %>%
  rename(model_index=model) %>%
  inner_join(ex1.fits %>% rename('bestFit_bias' = bias), by = 'subjects') %>%
  inner_join(parameter.dat, by=c('subjects', 'model_index')) %>%
  pivot_longer(cols = c(alpha:bias), names_to = 'parameter', values_to = 'value') %>%
  rename('STR_index'= model_index)


ex1.ex2.comp %>%
  group_by(model, parameter) %>%

  summarise(m = mean(value),
            n=n(),
            se = std(value)/sqrt(n)) %>% 
  filter(parameter=='bias') %>%
  ggplot(aes(y=m, ymax=m+se, ymin=m-se, x=model, color=parameter))+
  geom_point() +
  geom_errorbar(width=.3)



```

## Overview of modelfitting results

### Learning curves

```{r plot group data, fig.width=18, fig.height=14, dpi=300}
tmp.color = c('#ca0020','#0571b0','#fd8d3c' ,'#006d2c')

melted.p.behav.model %>% 
  group_by(type, model_index, condition, iteration) %>% 
  summarize(mean_acc = mean(accuracy), 
            n=n(), 
            se = std(accuracy)/sqrt(n)) %>% 
  separate(condition, into = c('setsize', 'condition')) %>% 
  
  unite(col = 'data_type',c(type, setsize) ) %>% 
  filter(condition=='learn') %>% 
  
  ggplot(aes(x=as.numeric(iteration), y= mean_acc, 
            ymax=mean_acc+se, ymin=mean_acc - se, 
            group=data_type, color=data_type
            )
        ) +
  geom_point() +
  geom_line() +
  geom_errorbar() +
  facet_wrap(vars(model_index)) +
  scale_color_manual(values = tmp.color) +
  theme_pubclean(base_size = 18)
  


melted.p.behav.model %>% 
  #filter(subjects %in% c( 28306, 15014, 28328, 6217) )%>% # 15014, 28306, 28328)6217, 15014,
   separate(condition, into = c('setsize', 'condition')) %>% 
#  filter(condition=='learn') %>% 
  #arrange(as.numeric(iteration)) %>% 
  
 # pivot_wider(id_cols = c(subjects, setsize, condition, type, model_index), 
       #       names_from = iteration, values_from = accuracy) %>% View
 # filter(subjects==6217) %>% 

  
  unite(col = 'data_type',c(type, setsize) ) %>% 
  filter(condition=='test') %>% 
  
  ggplot(aes(x=as.numeric(iteration), y= accuracy, 
            group=data_type, color=data_type
            )
        ) +
  geom_point() +
  geom_line() +
  facet_wrap(vars(subjects)) +
  scale_color_manual(values = tmp.color) +
  theme_pubclean(base_size = 18)
  


```



```{r}
# melted.p.behav.model %>%
#   group_by(type, model_index, condition, iteration) %>%
#   summarize(mean_acc = mean(accuracy),
#             n=n(),
#             se = std(accuracy)/sqrt(n)) %>%
#   separate(condition, into = c('setsize', 'condition')) %>%
# 
#   unite(col = 'data_type',c(type, setsize) ) %>%
#   filter( iteration=='12') %>% head
# 
#   ggplot(aes(x=condition, y= mean_acc,
#             ymax=mean_acc+se, ymin=mean_acc - se,
#             group=data_type, color=data_type
#             )
#         ) +
#   geom_point() +
#   geom_line() +
#   geom_errorbar() +
#   facet_wrap(vars(model_index)) +
#   scale_color_manual(values = tmp.color) +
#   theme_pubclean(base_size = 18)
```



```{r RMSE comparison: perform all fits}
##########--------RL fits----------------############

RL.BIC <-  fit.models.unsplit('RL', sdat, 2, TRUE) %>%
  as_tibble() %>%
  mutate(model='RL', model.id=c(1:nrow(RL.sim)) ) 

RL.all.rmse <- fit.models.unsplit('RL', sdat, 2, FALSE) %>%
  as_tibble() %>%
  mutate(model='RL', model.id=c(1:nrow(RL.sim)) ) 

##########---------LTM FITS ----------------############

LTM.BIC <- fit.models.unsplit('LTM', sdat, 3, TRUE) %>%
  as_tibble() %>%
  mutate(model='LTM', model.id=c(1:nrow(LTM.sim)) ) 

LTM.all.rmse <- fit.models.unsplit('LTM', sdat, 3, FALSE) %>%
  as_tibble() %>%
  mutate(model='LTM', model.id=c(1:nrow(LTM.sim)) ) 

##########---------RL-LTMstr FITS ----------------############

STR.BIC <- fit.models.unsplit('STR', sdat, 6, TRUE) %>%
  as_tibble() %>%
  mutate(model='STR', model.id=c(1:nrow(STR.sim)) ) 

STR.all.rmse <- fit.models.unsplit('STR', sdat, 6, FALSE) %>%
  as_tibble() %>%
  mutate(model='STR', model.id=c(1:nrow(STR.sim)) ) 
##########---------RL-LTMmeta FITS ----------------############

META.BIC <- fit.models.unsplit('META', sdat, 5, TRUE) %>%
  as_tibble() %>%
  mutate(model='META', model.id=c(1:nrow(META.sim)) )

META.all.rmse <- fit.models.unsplit('META', sdat, 5, FALSE) %>%
  as_tibble() %>%
  mutate(model='META', model.id=c(1:nrow(META.sim)) )


##### compare BICs
all.models <- 
  rbind(
    RL.BIC %>% 
      as_tibble() %>% 
      mutate(model='RL', model.id=c(1:nrow(RL.sim))), 
    LTM.BIC %>% 
      as_tibble() %>% 
      mutate(model='LTM',model.id=c(1:nrow(LTM.sim)) ),
    STR.BIC %>% 
      as_tibble() %>%
      mutate(model='STR', model.id=c(1:nrow(STR.sim)) ),
    META.BIC %>% as_tibble() %>%
      mutate(model='META', model.id=c(1:nrow(META.sim)) )
)  
  

best.fits.all <- 
    all.models$model[all.models %>% 
                       select(-contains('model')) %>% 
                       apply(., 2, which.min)
                     ] %>% 
    as_data_frame() %>% 
  mutate(model = value,
    subjects, 
    .keep='unused') 

  
best.fit.idx <- 
    all.models$model.id[all.models %>% 
                       select(-contains('model')) %>% 
                       apply(., 2, which.min) 
                     ] %>% 
  as_data_frame() %>% 
  mutate(index = value,
         subjects, 
         .keep = 'unused')

all.bestfits <- 
  inner_join(best.fits.all, best.fit.idx, by='subjects')







```


```{r RMSE comparison:}
tmp.color = c('#ca0020','#0571b0','#fd8d3c' ,'#006d2c')
META.RMSE <- read_csv('./META_only_Fit_RMSE_stag_2023.csv')
STR.RMSE <- read_csv('./STR_only_fit_RMSE_stag_2023.csv')
bestFit.RMSE <- read_csv('bestFit_model_RMSE.csv') %>% 
  rename(RMSE.ZS = RMSE)

mod_names= c('META', 'Biased', 'Best_Fit')

STR_vs_META_vs_BS <- 
  META.RMSE %>% 
  inner_join(STR.RMSE, by='subjects') %>%
  inner_join(bestFit.RMSE, by = 'subjects') %>% 
  pivot_longer(cols = -subjects, names_to = 'model', values_to = 'RMSE')


STR_vs_META_vs_BS %>% 
  lm(RMSE ~ model, data=.) %>% 
  anova



STR_vs_META_vs_BS %>% 
  group_by(model) %>% 
  summarise(m=mean(RMSE), 
            n=n(), 
            se = std(RMSE)/sqrt(n)) %>% 
  ggplot(aes(y=m, x=model, ymax=m+se, ymin=m-se, fill=model)) +
  geom_bar(stat = 'identity', width = .7) +
  geom_errorbar( width=.7, size=1) +
  scale_x_discrete(labels= mod_names) +
  theme_pubclean(base_size = 16)

STR_vs_META_vs_BS %>% 
  ggplot(aes(y = RMSE, x=model)) +
  
 #geom_point(alpha=.7)+
  #
# geom_line(aes(group=subjects), alpha=.4) +
  geom_boxplot(aes(color=model, group=model)) +
  geom_jitter(width = .1, height = 0)+
scale_x_discrete(labels= mod_names)  +
theme_pubclean(base_size = 16)+
    theme(legend.position='none', 
      ) 





```
