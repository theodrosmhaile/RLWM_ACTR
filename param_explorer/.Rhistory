subjects <- segment.dat$subject
if (0) {
# Import EEG resting state data for alpha band in channels O1 and O2. Turn on only if changing anything in the following code
EEG.data <- read_excel('../AllSubj_AcrossCohorts_AllEEG_8.7.19.xlsx')
EEG.data.alpha <- EEG.data[ , c(1,2,4,172,173,178,179,1412, 1413, 1418,1419)]
uclimb.psychometrics <- EEG.data[ , c(1,76, 115,119,125)]
write.csv(EEG.data.alpha, '~/google-drive/CCDL Shared/Shared/Savannah/staem_analysis/processed/alpha_only_EEG_data.csv', row.names = F)
write.csv(uclimb.psychometrics, '~/google-drive/CCDL Shared/Shared/Savannah/staem_analysis/processed/uclimb_wm_ravens_data.csv', row.names = F)
}
EEG.data.alpha <- read.csv('./processed/alpha_only_EEG_data.csv')
index.subjects  = !is.na(match(as.numeric(EEG.data.alpha$OLCTS.Expt..), subjects)) |
!is.na(match(as.numeric(EEG.data.alpha$Python.Expt..), subjects))
uclimb.psychometrics <- read.csv('./processed/uclimb_wm_ravens_data.csv')[index.subjects,3:6 ]
uclimb.psychometrics$compositeWM <- rowMeans(uclimb.psychometrics[,2:4])
uclimb.psychometrics$subject <- subjects
# range  = c("A1:B55","FP1:FQ55", "FV1:FW55", "BBH1:BBI55", "BBK1:BBL55"))
#'FS1:FS55','BBE1:BBE55',
alpha.dat <- cbind(O1_IAF_power_closed = rowMeans(EEG.data.alpha[index.subjects, c("O1_IAF_Power_OLCTS_StandardBand_Closed",
"O1_IAF_Power_Python_StandardBand_Closed")], na.rm = T),
O2_IAF_power_closed = rowMeans(EEG.data.alpha[index.subjects, c("O2_IAF_Power_OLCTS_StandardBand_Closed",
"O2_IAF_Power_Python_StandardBand_Closed")], na.rm = T),
O1_IAF_closed = rowMeans(EEG.data.alpha[index.subjects, c("O1_IAF_OLCTS_StandardBand_Closed",
"O1_IAF_Python_StandardBand_Closed")], na.rm = T),
O2_IAF_closed = rowMeans(EEG.data.alpha[index.subjects, c("O2_IAF_OLCTS_StandardBand_Closed",
"O2_IAF_Python_StandardBand_Closed")], na.rm = T))
over.segment = ifelse(scale(segment.dat[,2:4]) > 1,1,0 )
under.segment = ifelse(scale(segment.dat[,2:4]) < -1,-1,0 )
segmenter = over.segment + under.segment
norm.segmenter.p = 1-(rowSums(segmenter!=0) / 3)
# assign probability of a participant being normal segmenter or over/under segmenter
alpha_and_seg <- cbind(segment.dat, age = EEG.data.alpha$Age[index.subjects], alpha.dat, norm.segmenter.p) #this contains the segmentation and alpha in one table
#save data to text file
if (0){
write.csv(cbind(segment.dat, EEG.data.alpha[index.subjects, 3:9 ]),'./processed/segmentation_EEG_data.csv', row.names = F)
}
seg.ratio <- (21-colSums(segmenter!=0)) / (colSums(segmenter!=0))
seg.ratio.tot <- sum(21-colSums(segmenter!=0)) / sum(colSums(segmenter!=0))
d.table1=describe(segment.dat[,2:4], fast=T)
d.table1[, 2:length(d.table1)] %>% kable(.)
#segment.dat %>%  melt(id.vars='subject') %>% ggplot(aes(variable, value, fill=variable)) + geom_bar(stat=average) +
# scale_fill_brewer(palette = "Set2", ) + theme_classic(base_size = 18)
segmenter.cons <- corr.test(segment.dat[,2:4], method = 'spearman', adjust = 'holm')
segmenter.cons$r %>% as.data.frame() %>% kable(.)
segmenter.cons$p %>% as.data.frame() %>% kable(.)
#histogram of segmentation per video
alpha_and_seg[, 1:4]%>% scale() %>% as.data.frame() %>%  melt(id.vars = 'subject' ) %>% ggplot(aes(value, fill=variable)) +
geom_density(alpha = 0.7) +
# geom_density(aes(V.2, fill='Video2'), alpha = 0.7) +
#  geom_density(aes(V.3, fill ='Video3'), alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of segmenting behavior') +
# scale_fill_discrete(name = 'Video') +
geom_vline(aes(xintercept = 1), linetype ='dashed') +
geom_vline(aes(xintercept = -1), linetype ='dashed') +
annotate("text", x=1.9, y=0.5, label= "Over\nsegmenters ->", alpha=.7) +
annotate("text", x = -1.9, y=.45, label = " Under\n<-segmenters", alpha=.7) +
scale_fill_brewer(palette = "Set2", name = 'Video') + theme_classic(base_size = 18)
#color over and under segmenters on histogram and provide counts
rowSums(alpha_and_seg[, 2:4]) %>% scale() %>% as.data.frame() %>%
ggplot(aes(V1, fill=V1)) +  geom_histogram(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of total number of segments') +
scale_fill_discrete(name = 'Video') +
geom_vline(aes(xintercept = 1), linetype ='dashed') +
geom_vline(aes(xintercept = -1), linetype ='dashed') +
annotate("text", x=2.3, y=2.5, label= "Over\nsegmenters", alpha=.7) +
annotate("text", x = -2.3, y=2.5, label = " Under\nsegmenters", alpha=.7) +
scale_fill_brewer(palette = "Set2", name = 'Video') + theme_classic(base_size = 18)
d.table2=describe(uclimb.psychometrics[1:5], fast = T )
d.table2[,2:length(d.table2)] %>% kable(.)
uclimb.psychometrics[, c(1,5,6)]  %>% scale() %>% as.data.frame() %>% melt(id.vars='subject') %>%
ggplot(aes(value, fill=variable)) + geom_density(alpha=0.7) +
xlim(c(-4,4)) + xlab('z-score of performance') +
scale_fill_brewer(palette = "RdBu", guide =F) + theme_classic(base_size = 18 ) + facet_grid(variable ~ .)
cbind(uclimb.psychometrics, tot.seg=rowSums(segment.dat[,2:4]) )%>%
scale() %>% as.data.frame() %>%
ggplot(aes(tot.seg,Ravens.Score)) +
geom_point() + geom_smooth(method = 'rlm') +
xlab('Z-scored total number of segments')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 )
cbind(uclimb.psychometrics, tot.seg=rowSums(segment.dat[,2:4]) )%>%
scale() %>% as.data.frame() %>%
ggplot(aes(compositeWM,Ravens.Score)) +
geom_point() + geom_smooth(method = 'rlm') +
xlab('Composite WM (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 )
uclimb.psychometrics
cor(uclimb.psychometrics[,1], uclimb.psychometrics[, 5])
cor(uclimb.psychometrics[,1], uclimb.psychometrics[, 51], method = 'spearman')
cor(uclimb.psychometrics[,1], uclimb.psychometrics[, 5], method = 'spearman')
ravens.wm.seg <- cbind(uclimb.psychometrics[,c(1,5)], total.segments=rowSums(segment.dat[,2:4]) )%>%
corr.test(., method = 'spearman', adjust = 'holm')
ravens.wm.seg$r %>% as.data.frame() %>% kable(.)
ravens.wm.seg$p %>% as.data.frame() %>% kable(.)
over.segment.tot = ifelse(scale(rowSums(segment.dat[,2:4])) > 1, 1, 0 )
under.segment.tot = ifelse(scale(rowSums(segment.dat[,2:4])) < -1, -1, 0 )
segmenter.tot.temp = over.segment.tot + under.segment.tot
segmenter.tot = segmenter.tot.temp
segmenter.tot[segmenter.tot.temp > 0] <- 'Over'
segmenter.tot[segmenter.tot.temp == 0] <- 'Normative'
segmenter.tot[segmenter.tot.temp < 0] <- 'Under'
cbind(IAFo1o2 = rowMeans(alpha_and_seg[, c(8,9)]),tot.seg=rowSums(alpha_and_seg[, 2:4]))  %>%
scale() %>% as.data.frame() %>% cbind(subjects= alpha_and_seg[,1], seg.ID = segmenter.tot) %>%
ggplot(aes(IAFo1o2, fill=factor(seg.ID))) +  geom_density(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of IAF') +
scale_fill_brewer(palette = "Set2", name = 'Segmenter') + theme_classic(base_size = 18)
cbind(IAFo1o2 = rowMeans(alpha_and_seg[, c(6,7)]),tot.seg=rowSums(alpha_and_seg[, 2:4]))  %>%
scale() %>% as.data.frame() %>% cbind(subjects= alpha_and_seg[,1], seg.ID = segmenter.tot) %>%
ggplot(aes(IAFo1o2, fill=factor(seg.ID))) +  geom_density(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of IAF power') +
scale_fill_brewer(palette = "Set2", name = 'Segmenter') + theme_classic(base_size = 18)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),tot.seg=rowSums(alpha_and_seg[, 2:4]))  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = 'tot.seg' ) %>%
ggplot(aes(tot.seg,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
uclimb.psychometrics[,c(1,5)
)
uclimb.psychometrics[,c(1,5)]
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = 'subjects' )
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5,6)])
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = 'subject' )
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('subject', 'Ravens.score' ))
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('subject', 'Ravens.Score' ))
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('subject' )) %>%
ggplot(aes(tot.seg,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('subject' ))
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Raven.Score' )) %>%
ggplot(aes(Raven.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Raven.Score' ))
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,6)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,1])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,1])
uclimb.psychometrics
uclimb.psychometrics[,1]
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5)])
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),uclimb.psychometrics[,c(1,5)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score','compositeWM' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),Ravens.Score=uclimb.psychometrics[,c(1)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Ravens Score (z-scored)')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),Ravens.Score=uclimb.psychometrics[,c(1)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Ravens Score (z-scored)')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
)
#pdf_document:
#    df_print: kable
#    fig_caption: yes
#ouput: html_document
rm(list = ls())
library(readxl)
#library(tidyverse)
library(ggplot2)
library(stringr)
library(psych)
library(tibble)
library(knitr)
library(reshape2)
library(MASS)
segment.dat <- read.csv('./processed/results/segmentation_by_subject.csv')
subjects <- segment.dat$subject
if (0) {
# Import EEG resting state data for alpha band in channels O1 and O2. Turn on only if changing anything in the following code
EEG.data <- read_excel('../AllSubj_AcrossCohorts_AllEEG_8.7.19.xlsx')
EEG.data.alpha <- EEG.data[ , c(1,2,4,172,173,178,179,1412, 1413, 1418,1419)]
uclimb.psychometrics <- EEG.data[ , c(1,76, 115,119,125)]
write.csv(EEG.data.alpha, '~/google-drive/CCDL Shared/Shared/Savannah/staem_analysis/processed/alpha_only_EEG_data.csv', row.names = F)
write.csv(uclimb.psychometrics, '~/google-drive/CCDL Shared/Shared/Savannah/staem_analysis/processed/uclimb_wm_ravens_data.csv', row.names = F)
}
EEG.data.alpha <- read.csv('./processed/alpha_only_EEG_data.csv')
index.subjects  = !is.na(match(as.numeric(EEG.data.alpha$OLCTS.Expt..), subjects)) |
!is.na(match(as.numeric(EEG.data.alpha$Python.Expt..), subjects))
uclimb.psychometrics <- read.csv('./processed/uclimb_wm_ravens_data.csv')[index.subjects,3:6 ]
uclimb.psychometrics$compositeWM <- rowMeans(uclimb.psychometrics[,2:4])
uclimb.psychometrics$subject <- subjects
# range  = c("A1:B55","FP1:FQ55", "FV1:FW55", "BBH1:BBI55", "BBK1:BBL55"))
#'FS1:FS55','BBE1:BBE55',
alpha.dat <- cbind(O1_IAF_power_closed = rowMeans(EEG.data.alpha[index.subjects, c("O1_IAF_Power_OLCTS_StandardBand_Closed",
"O1_IAF_Power_Python_StandardBand_Closed")], na.rm = T),
O2_IAF_power_closed = rowMeans(EEG.data.alpha[index.subjects, c("O2_IAF_Power_OLCTS_StandardBand_Closed",
"O2_IAF_Power_Python_StandardBand_Closed")], na.rm = T),
O1_IAF_closed = rowMeans(EEG.data.alpha[index.subjects, c("O1_IAF_OLCTS_StandardBand_Closed",
"O1_IAF_Python_StandardBand_Closed")], na.rm = T),
O2_IAF_closed = rowMeans(EEG.data.alpha[index.subjects, c("O2_IAF_OLCTS_StandardBand_Closed",
"O2_IAF_Python_StandardBand_Closed")], na.rm = T))
over.segment = ifelse(scale(segment.dat[,2:4]) > 1,1,0 )
under.segment = ifelse(scale(segment.dat[,2:4]) < -1,-1,0 )
segmenter = over.segment + under.segment
norm.segmenter.p = 1-(rowSums(segmenter!=0) / 3)
# assign probability of a participant being normal segmenter or over/under segmenter
alpha_and_seg <- cbind(segment.dat, age = EEG.data.alpha$Age[index.subjects], alpha.dat, norm.segmenter.p) #this contains the segmentation and alpha in one table
#save data to text file
if (0){
write.csv(cbind(segment.dat, EEG.data.alpha[index.subjects, 3:9 ]),'./processed/segmentation_EEG_data.csv', row.names = F)
}
seg.ratio <- (21-colSums(segmenter!=0)) / (colSums(segmenter!=0))
seg.ratio.tot <- sum(21-colSums(segmenter!=0)) / sum(colSums(segmenter!=0))
d.table1=describe(segment.dat[,2:4], fast=T)
d.table1[, 2:length(d.table1)] %>% kable(.)
#segment.dat %>%  melt(id.vars='subject') %>% ggplot(aes(variable, value, fill=variable)) + geom_bar(stat=average) +
# scale_fill_brewer(palette = "Set2", ) + theme_classic(base_size = 18)
segmenter.cons <- corr.test(segment.dat[,2:4], method = 'spearman', adjust = 'holm')
segmenter.cons$r %>% as.data.frame() %>% kable(.)
segmenter.cons$p %>% as.data.frame() %>% kable(.)
#histogram of segmentation per video
alpha_and_seg[, 1:4]%>% scale() %>% as.data.frame() %>%  melt(id.vars = 'subject' ) %>% ggplot(aes(value, fill=variable)) +
geom_density(alpha = 0.7) +
# geom_density(aes(V.2, fill='Video2'), alpha = 0.7) +
#  geom_density(aes(V.3, fill ='Video3'), alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of segmenting behavior') +
# scale_fill_discrete(name = 'Video') +
geom_vline(aes(xintercept = 1), linetype ='dashed') +
geom_vline(aes(xintercept = -1), linetype ='dashed') +
annotate("text", x=1.9, y=0.5, label= "Over\nsegmenters ->", alpha=.7) +
annotate("text", x = -1.9, y=.45, label = " Under\n<-segmenters", alpha=.7) +
scale_fill_brewer(palette = "Set2", name = 'Video') + theme_classic(base_size = 18)
#color over and under segmenters on histogram and provide counts
rowSums(alpha_and_seg[, 2:4]) %>% scale() %>% as.data.frame() %>%
ggplot(aes(V1, fill=V1)) +  geom_histogram(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of total number of segments') +
scale_fill_discrete(name = 'Video') +
geom_vline(aes(xintercept = 1), linetype ='dashed') +
geom_vline(aes(xintercept = -1), linetype ='dashed') +
annotate("text", x=2.3, y=2.5, label= "Over\nsegmenters", alpha=.7) +
annotate("text", x = -2.3, y=2.5, label = " Under\nsegmenters", alpha=.7) +
scale_fill_brewer(palette = "Set2", name = 'Video') + theme_classic(base_size = 18)
d.table2=describe(uclimb.psychometrics[1:5], fast = T )
d.table2[,2:length(d.table2)] %>% kable(.)
uclimb.psychometrics[, c(1,5,6)]  %>% scale() %>% as.data.frame() %>% melt(id.vars='subject') %>%
ggplot(aes(value, fill=variable)) + geom_density(alpha=0.7) +
xlim(c(-4,4)) + xlab('z-score of performance') +
scale_fill_brewer(palette = "RdBu", guide =F) + theme_classic(base_size = 18 ) + facet_grid(variable ~ .)
cbind(uclimb.psychometrics, tot.seg=rowSums(segment.dat[,2:4]) )%>%
scale() %>% as.data.frame() %>%
ggplot(aes(compositeWM,Ravens.Score)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Composite WM (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 )
cbind(uclimb.psychometrics, tot.seg=rowSums(segment.dat[,2:4]) )%>%
scale() %>% as.data.frame() %>%
ggplot(aes(tot.seg,Ravens.Score)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 )
cbind(uclimb.psychometrics, tot.seg=rowSums(segment.dat[,2:4]) )%>%
scale() %>% as.data.frame() %>%
ggplot(aes(tot.seg,compositeWM)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Z-scored total number of segments')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 )
ravens.wm.seg <- cbind(uclimb.psychometrics[,c(1,5)], total.segments=rowSums(segment.dat[,2:4]) )%>%
corr.test(., method = 'spearman', adjust = 'holm')
ravens.wm.seg$r %>% as.data.frame() %>% kable(.)
ravens.wm.seg$p %>% as.data.frame() %>% kable(.)
over.segment.tot = ifelse(scale(rowSums(segment.dat[,2:4])) > 1, 1, 0 )
under.segment.tot = ifelse(scale(rowSums(segment.dat[,2:4])) < -1, -1, 0 )
segmenter.tot.temp = over.segment.tot + under.segment.tot
segmenter.tot = segmenter.tot.temp
segmenter.tot[segmenter.tot.temp > 0] <- 'Over'
segmenter.tot[segmenter.tot.temp == 0] <- 'Normative'
segmenter.tot[segmenter.tot.temp < 0] <- 'Under'
cbind(IAFo1o2 = rowMeans(alpha_and_seg[, c(8,9)]),tot.seg=rowSums(alpha_and_seg[, 2:4]))  %>%
scale() %>% as.data.frame() %>% cbind(subjects= alpha_and_seg[,1], seg.ID = segmenter.tot) %>%
ggplot(aes(IAFo1o2, fill=factor(seg.ID))) +  geom_density(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of IAF') +
scale_fill_brewer(palette = "Set2", name = 'Segmenter') + theme_classic(base_size = 18)
cbind(IAFo1o2 = rowMeans(alpha_and_seg[, c(6,7)]),tot.seg=rowSums(alpha_and_seg[, 2:4]))  %>%
scale() %>% as.data.frame() %>% cbind(subjects= alpha_and_seg[,1], seg.ID = segmenter.tot) %>%
ggplot(aes(IAFo1o2, fill=factor(seg.ID))) +  geom_density(alpha = 0.7) +
xlim(c(-4,4)) +
xlab('z.score of IAF power') +
scale_fill_brewer(palette = "Set2", name = 'Segmenter') + theme_classic(base_size = 18)
cbind(IAF_power = rowMeans(alpha_and_seg[, c(6,7)]), IAF = rowMeans(alpha_and_seg[, c(8,9)]),Ravens.Score=uclimb.psychometrics[,c(1)])  %>%
scale() %>% as.data.frame() %>%   melt(id.vars = c('Ravens.Score' )) %>%
ggplot(aes(Ravens.Score,value, group=variable)) +
geom_point() + geom_smooth(method = 'lm') +
xlab('Ravens Score (z-scored)')+
ylab('Frequency (z-scored)')+
#geom_tile(('Correlation of total segmentation vs ravens score') ) +
theme_classic(base_size = 18 ) + facet_grid(cols = vars(variable))#variable,variable ~ .)
shiny::runApp('RLWM_ACTR/param_explorer')
runApp('RLWM_ACTR/param_explorer')
dat
dat
dat <- fromJSON('../sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
setwd('RLWM_ACTR/')
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
setwd('~/RLWM_ACTR/param_explorer/')
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
runApp()
plot(iter.n,
dat$set3_learn[
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
]$`0`,
col = '#e41a1c',
cex = 1,
lwd = 2,
pch = 19,
xlab ='Stimulus presentations',
ylab ='Accuracy'
)
runApp()
plot(iter.n,
dat$set3_learn[
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
]$`0`,
col = '#e41a1c',
cex = 1,
lwd = 2,
pch = 19,
xlab ='Stimulus presentations',
ylab ='Accuracy'
)
iter.n <- c(1:12)
iter.n
plot(iter.n,
dat$set3_learn[
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
]$`0`,
col = '#e41a1c',
cex = 1,
lwd = 2,
pch = 19,
xlab ='Stimulus presentations',
ylab ='Accuracy'
)
input= data.frame('al' = 0.5, 'b'=0.3,'an'= 0.1, 'e'=0.1, 'i'= 1 )
input
plot(iter.n,
dat$set3_learn[
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
]$`0`,
col = '#e41a1c',
cex = 1,
lwd = 2,
pch = 19,
xlab ='Stimulus presentations',
ylab ='Accuracy'
)
dat$set3_learn[
+          dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
+          ]$`0`
dat$set3_learn[dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i]$`0`
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
dat$alpha==input$al
sum(dat$alpha==input$al)
dat$alpha
input
min(dat$alpha)
min(as.numeric(dat$alpha))
input$al=0.05
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
sum(dat$alpha==input$al)
input
sum(dat$bll==input$b)
sum(dat$alpha==input$al & dat$bll==input$b )
sum(dat$ans == input$an)
sum(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an)
sum(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e)
sum(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0'
plot(iter.n,
dat$set3_learn[
dat$alpha==input$al & dat$bll==input$b & dat$ans==input$an & dat$input$egs==input$e & dat$imag == input$i
]$`0`,
col = '#e41a1c',
cex = 1,
lwd = 2,
pch = 19,
xlab ='Stimulus presentations',
ylab ='Accuracy'
)
plot(iter.n, dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0' )
plot(iter.n, dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0',col = '#e41a1c', cex = 1, lwd = 2, pch = 19, xlab ='Stimulus presentations',ylab ='Accuracy')
plot(iter.n,
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0',
col = '#e41a1c',
cex = 1, lwd = 2,
pch = 19, xlab ='Stimulus presentations',ylab ='Accuracy')
plot(iter.n,
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0',
col = '#e41a1c',
cex = 1, lwd = 2,
pch = 19, xlab ='Stimulus presentations',ylab ='Accuracy')
input
runApp()
runApp()
runApp()
dat
head(dat)
max(dat$imag)
max(as.numeric(dat$imag))
max(as.numeric(dat$ans))
max(as.numeric(dat$al))
max(as.numeric(dat$an))
runApp()
max(as.numeric(dat$b))
runApp()
who
whos
ls()
rm(list = ls())
runApp()
runApp()
input= data.frame('al' = 0.1, 'b'=0.4,'an'= 0.2, 'e'=0.2, 'i'= 2 )
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
dat <- fromJSON('sim_data_first_half_param_space_030620_integr_model100sTEST.JSON')
set3.dat <- dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0'
set6.dat <- dat$set6_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0'
set3.dat
sum(as.numeric(dat$alpha==input$al))
sum(as.numeric(dat$ans==input$an))
sum(as.numeric(dat$egs==input$e))
sum(as.numeric(dat$imag==input$i))
sum(as.numeric(dat$bll==input$b))
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]$'0'
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]
runApp()
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]
dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]
flatten(dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)])
hh=dat$set3_learn[(dat$alpha==input$al & dat$bll==input$b & dat$ans == input$an & dat$egs == input$e & dat$imag == input$i)]
hh
hh[]
hh[:]
hh[all]
vector(hh)
vector(as.numeric(hh))
unlist(hh)
runApp()
