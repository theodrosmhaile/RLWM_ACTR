---
title: "RLWM ACT-R RMSE model fitting and outcome analysis for split-half data"
author: "Theodros H."
date: "10/2022"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_float: yes
  word_document:
    toc: no
editor_options:
  chunk_output_type: console
---

<!-- ```{css, echo=FALSE} -->

<!-- p{ -->

<!--   font-size: 18px; -->

<!-- } -->

<!-- ``` -->

```{r set up, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}
rm(list = ls())
library(MASS)
library(ggpubr)
library(matlab)
library(MLmetrics)
library(jsonlite)
library(knitr)
library(Rmisc)
library(magrittr)
library(data.table)
library(skimr)
library(tidyverse)
knitr::opts_chunk$set(
  comment = "#>", echo = FALSE, warning = FALSE, 
  message = FALSE, dpi = 300
 
)
theme_set(theme_pubclean(base_size = 12)) 

```

# Results
# setup 
```{r SUBJECTS: import  data}
# sdat contains data fro 83 participants (columns), 
# rows 1:12 learn accuracy set 3 ; 
# rows 13:24 learn accuracy set 6 ;
# row 25 test set 3 accuracy ;
# row 26 test set 6 accuracy ;

#### Full data set
subjects = read.csv("./RLWM_data/wmo_subjects_across_studies_031820.csv", header = F)
colnames(subjects)='subjects'
sdat.temp = fread('./RLWM_data/all_subject_n83_learn_test_data.csv', header = T) %>% t()

sdat.full <- cbind(
  sdat.temp[ ,1:12],
                   matrix(sdat.temp[ ,25],
                          nrow = numel(sdat.temp[ ,25]), ncol = 12),
                   sdat.temp[ ,13:24],
                  matrix(sdat.temp[ ,26],nrow = numel(sdat.temp[ ,25]), ncol = 12) )

colnames(sdat.full) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12)))

####### Half dataset


sdat.h1 = read.csv('./RLWM_data/Half1_all_subject_n83_learn_test_data.csv',header = T) 
h1.subjects <-  sdat.h1$V1
sdat.h1 <- sdat.h1[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h1 <- cbind(
  sdat.h1[ ,1:12],
                   matrix(sdat.h1[ ,25],
                          nrow = numel(sdat.h1[ ,25]), ncol = 12),
                   sdat.h1[ ,13:24],
                  matrix(sdat.h1[ ,26],nrow = numel(sdat.h1[ ,25]), ncol = 12) )

colnames(sdat.repl.h1) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12)))

sdat.h2 = read.csv('./RLWM_data/Half2_all_subject_n83_learn_test_data.csv', header = T) 

h2.subjects <-  sdat.h2$V1
sdat.h2 <- sdat.h2[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h2 <- cbind(sdat.h2[ ,1:12],
                   matrix(sdat.h2[ ,25],
                          nrow = numel(sdat.h2[ ,25]), ncol = 12),
                   sdat.h2[ ,13:24],
                  matrix(sdat.h2[ ,26],
                         nrow = numel(sdat.h2[ ,25]), ncol = 12) )

colnames(sdat.repl.h2) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12))
                          )



#  "model"     "index"     "subjects"  "name"      "condition" "iteration" "accuracy"  "type"     
subject.dat <- 
  sdat.repl.h1 %>% 
  dplyr::mutate(half ='half1', 
                subjects = h1.subjects) %>% 
  rbind(sdat.repl.h2 %>% 
          mutate(half='half2', 
                 subjects= h1.subjects))
  
  subject.dat %<>%   
  dplyr::mutate(
         'type' = 'behavioral' 
        # ,'parameter' = NA, 
      #   'param_vals'= NA
        ) %>% 
  pivot_longer(cols = -c(half,type, subjects), names_to = 'temp_condition', values_to = 'accuracy') %>% #, parameter, param_vals
  separate(temp_condition, into = c('condition','iteration'), sep = '[/.]')
  
  
  
subject.dat.full <- 
  sdat.full %>%
    as.data.frame() %>% 
  mutate(subjects, 
         type='behavioral') %>% 
  pivot_longer(cols=-c(type, subjects), 
               names_to = 'temp_condition',
               values_to = 'accuracy') %>% 
     separate(temp_condition, into = c('condition','iteration'), sep = '[/.]')
  
```

```{r MODELS: import  data}
RL.sim <- fromJSON('./simulated_data/RL_model/RL_sim_data_07_12_2022.JSON')$data %>% 
  dplyr::mutate(bias = 0)

# RL.sim$set3_test <- matrix(
#               RL.sim$set3_test,
#               nrow = numel( RL.sim$set3_test),
#               ncol = 12 )
# RL.sim$set6_test <- matrix(
#               RL.sim$set6_test,
#               nrow = numel( RL.sim$set6_test),
#               ncol = 12 )
LTM.sim <- fromJSON('./simulated_data/LTM_model/LTM_sim_data_02202021.JSON')$data %>% 
  dplyr::mutate(bias = 0 )
# LTM.sim$set3_test <- matrix(
#               LTM.sim$set3_test,
#               nrow = numel( LTM.sim$set3_test),
#               ncol = 12 )



STR.sim <- fromJSON('./simulated_data/strategy_model/STR_sim_data_032021.JSON')$data %>% 
  dplyr::mutate(bias = str_remove_all(strtg, "[:alpha:]") %>% as.numeric()/100, .keep=c('unused'))

META.sim <- fromJSON('./simulated_data/pipe_model/pipe_sim_data_032021.JSON')$data %>% 
   dplyr::mutate(bias = strtg,
          bias3 = strtg3,
          bias6 = strtg6, .keep='unused')

```

```{r custom functions}

#(1) Transform RMSE into residual sum of squares by doing RSS = RMSE^2 * n
#11:34
#(2) Calculate BIC as: BIC = n + n log (2*pi) + n log (RSS/n) + log(n) * (k + 1)
#11:36
#In RL, k = 2; in LTM, k = 3; and Integrated, k = 5 or k = 6

#MAP 
Andys_BIC <- function(rmse, k, n) {
  # RSS first
  #n = 48 #lean3 + learn 6 + (test3)*12 + (test6)*12
  RSS <- ((rmse)^2) * n
  # BIC next
  bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
  
  return(bic)
}


fit.subject <- function(behav.dat, model.dat){

apply(model.dat, 1, function(x,y) MSE(x, behav.dat)) %>% sqrt()
   
}

#### Part 1 function
fit.models.unsplit <- function(model,half, params) {
  
  #select model
  if (model == 'RL') {
    sim.mod = RL.sim
  }
  if (model == 'LTM') {
    sim.mod = LTM.sim
  }
  if (model == 'STR') {
    sim.mod = STR.sim
  }
  if (model == 'META') {
    sim.mod = META.sim
  }
  #select half
  if (half == 1) {
    sdat = sdat.repl.h1
  } 
  if(half == 2) {
    sdat = sdat.repl.h2
  }
  
  
sim.learn = sim.mod$set3_learn %>% 
    reduce(rbind) %>%  
  cbind(sim.mod$set6_learn %>% reduce(rbind)) 
                      
  
  sim.test =  matrix(
                sim.mod$set3_test,
              nrow = numel(sim.mod$set3_test),
              ncol = 12) %>% 
    cbind(matrix(
                sim.mod$set6_test,
              nrow = numel(sim.mod$set6_test),
              ncol = 12))
  
  apply( sdat, 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 48)
  
}

#### Part 3 function
fit.models <- function(model, half, setsize, params) {
  #select model
  # if (model == 'RL') {
  #   model = RL.sim
  # }
  # if (model == 'LTM') {
  #   model = LTM.sim
  # }
  # if (model == 'STR') {
  #   model = STR.sim
  # }
  # if (model == 'META') {
  #   model = META.sim
  # }
  # 
  # select subject data
  if (half == 1) {
    sdat = sdat.repl.h1
  } 
  if(half ==2) {
    sdat = sdat.repl.h2
  }
 
  # select setsize
  
  if (setsize == 3) {
    ns = 1:24
    n_size = 'set3_'
  } 
  
  if(setsize == 6){
    ns = 25:48
  
    n_size='set6_'
  }
 
  
  sim.learn = eval(
      parse(text=paste0(model,'.sim$',n_size, 'learn')
                                 )
                           ) %>% 
    reduce(rbind)
                      
  
  sim.test =  matrix(
              eval(
                parse(text=paste0(model,'.sim$',n_size, 'test'))),
              nrow = numel(eval(parse(text=paste0(model,'.sim$',n_size, 'test')))),
              ncol = 12)
 
  
  apply( sdat[, ns], 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 24)
  
}

#### Part 2 function
fit.models.setsize <- function(model,  setsize, params) {
  #select model
  # if (model == 'RL') {
  #   model = RL.sim
  # }
  # if (model == 'LTM') {
  #   model = LTM.sim
  # }
  # if (model == 'STR') {
  #   model = STR.sim
  # }
  # if (model == 'META') {
  #   model = META.sim
  # }
  # 
  # select subject data
 sdat =  sdat.full
 
  # select setsize
  
  if (setsize == 3) {
    ns = 1:24
    n_size = 'set3_'
  } 
  
  if(setsize == 6){
    ns = 25:48
  
    n_size='set6_'
  }
 
  
  sim.learn = eval(
      parse(text=paste0(model,'.sim$',n_size, 'learn')
                                 )
                           ) %>% 
    reduce(rbind)
                      
  
  sim.test =  matrix(
              eval(
                parse(text=paste0(model,'.sim$',n_size, 'test'))),
              nrow = numel(eval(parse(text=paste0(model,'.sim$',n_size, 'test')))),
              ncol = 12)
 
  
  apply( sdat[, ns], 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(sim.learn, sim.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 24)
  
}



get_data = function(data, data_name){
  bind_rows(
    c('set3_learn','set6_learn') %>% 
      map(~
            #column is measurement at T, record is simulation
            data %>% 
            .[[.x]] %>% 
            reduce(rbind) %>% 
            data.frame() %>% 
            mutate(condition = .x, 
                   model_index= c(1:nrow(data))
            )
      ) %>% 
      reduce(bind_rows) %>% 
      pivot_longer(cols = starts_with('x')
                   ,values_to = 'accuracy', names_to = 'iteration'),
    
    c('set3_test', 'set6_test') %>% #, 'bias' 'alpha','egs', 'bll', 'imag','ans'
      map (~
             {
               temp = data %>% 
                 .[[.x]]
               
               data.frame(
                  model_index= c(1:nrow(data)),
                 condition=.x, 
                 iteration=paste0('X', rep(c(1:12), nrow(data))), 
                 accuracy=rep(temp, 12)
               )
               
             }
      )
  
  ) %>%  
    mutate(data_source = data_name)
}

```

# PART I

In this section, learning data were split into first half and second half and fit separately. The two set-sizes were fit together. Are learning outcomes for the 2 halves correlated?

```{r correlation of accuracy, fig.height=3, fig.width=4}

cor.acc.half = subject.dat %>% 
  filter(iteration == c(9,10,11,12)) %>% 
  pivot_wider( names_from = 'iteration', values_from = 'accuracy') %>% 
  dplyr::mutate(mean.acc =(`9` + `10` + `11` + `12` )/4) %>% 
         select(half, condition, mean.acc, subjects) 

cor.acc.half %>% 
  pivot_wider(names_from = 'half', values_from = 'mean.acc' ) %>% 
 ggplot(aes(x = half1, y=half2)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(vars(condition))
  

#stat test
cor.acc.half %>% 
  lm(mean.acc ~ half *condition, data=.) %>% 
  anova

    
 cor.acc.half %>% 
  pivot_wider(names_from = 'half', values_from = 'mean.acc' ) %>% 
   group_by(condition) %>% 
   summarise(r = cor.test(half1,half2)$estimate, 
             p.val = cor.test(half1,half2)$p.value) %>% 
   knitr::kable(caption = "Correlation between First half and second half of learning outcomes", format = 'pipe', digits=3 
                    )

  
  
```

### Are test accuracies higher in half2 compared to half1?

```{r}
cor.acc.half %>% 
  group_by(subjects, half) %>% 

  summarize(diffs_s3 = mean.acc[condition=='set3_learn'] - mean.acc[condition=='set3_test'], 
            diffs_s6 = mean.acc[condition=='set6_learn'] - mean.acc[condition=='set6_test']) %>% 
  group_by(half) %>%
  summarize(s3=mean(diffs_s3), 
            s6=mean(diffs_s6))
```


```{r correlation of learning rate for the 2 halves}
cor.slope.half <- 
  subject.dat %>% 
  filter(iteration == c(1,2,3,4), condition=='set3_learn' | condition=='set6_learn') %>% 


   dplyr::group_by(half, subjects, condition) %>% 

   do( broom::tidy(lm(accuracy~as.numeric(iteration), data=.))[2,2] ) %>% 
  pivot_wider(names_from = 'half', values_from = 'estimate')

cor.slope.half %>% 
  
  ggplot(aes(x=half1, y=half2, )) +
   geom_point() +
  geom_smooth(method = 'lm', color='red') +
  facet_wrap(vars(condition)) +
 coord_fixed()

cor.slope.half %>% 
   group_by(condition) %>% 
   summarise(n=n(),
     r = cor.test(half1,half2)$estimate, 
             p.val = cor.test(half1,half2)$p.value) %>% 
   knitr::kable(caption = "Correlation between First half and second half of learning rate", format = 'pipe', digits=3 
                    )

# subject.dat %>% 
#   filter(iteration == c(1,2,3,4),  condition=='set3_learn' | condition=='set6_learn') %>% 
#   ggplot(aes(x=iteration, y=accuracy, group=as.factor(subjects), color=as.factor(subjects)))+
#   geom_point() +
#   geom_line() +
#   facet_wrap(vars(half, condition))


```

```{r PART I: fit subjects with models}
##########--------RL fits----------------############

RL.BIC.H1 <-  fit.models.unsplit(model = 'RL', half = 1, 2)
RL.BIC.H2 <-  fit.models.unsplit(model = 'RL', half = 2, 2)

##########---------LTM FITS ----------------############

LTM.BIC.H1 <- fit.models.unsplit('LTM', half = 1, 3)
LTM.BIC.H2 <- fit.models.unsplit('LTM', half = 2, 3)

##########---------RL-LTMstr FITS ----------------############

STR.BIC.H1 <- fit.models.unsplit('STR', half = 1, 6)
STR.BIC.H2 <- fit.models.unsplit('STR', half = 2, 6)

##########---------RL-LTMmeta FITS ----------------############

META.BIC.H1 <- fit.models.unsplit('META', half = 1, 5)
META.BIC.H2 <- fit.models.unsplit('META', half = 2, 5)


```

```{r PART1 select best fits}
all.models <- 
  rbind(
    RL.BIC.H1 %>% 
      as_tibble() %>% 
      mutate(half = 'half1', model='RL', model.id=c(1:nrow(RL.sim))),
    RL.BIC.H2 %>% 
      as_tibble() %>% 
      mutate(half = 'half2', model='RL', model.id=c(1:nrow(RL.sim))),
    LTM.BIC.H1 %>% 
      as_tibble() %>% 
      mutate(half = 'half1', model='LTM',model.id=c(1:nrow(LTM.sim)) ),
    LTM.BIC.H2 %>% 
      as_tibble() %>% 
      mutate(half = 'half2', model='LTM',model.id=c(1:nrow(LTM.sim)) ),
    STR.BIC.H1 %>% 
      as_tibble() %>%
      mutate(half = 'half1', model='STR', model.id=c(1:nrow(STR.sim)) ),
    STR.BIC.H2 %>% 
      as_tibble() %>%
      mutate(half = 'half2', model='STR', model.id=c(1:nrow(STR.sim)) ),
    META.BIC.H1 %>% as_tibble() %>%
      mutate(half = 'half1', model='META', model.id=c(1:nrow(META.sim)) ),
    META.BIC.H2 %>% as_tibble() %>%
      mutate(half = 'half2', model='META', model.id=c(1:nrow(META.sim)) )
)  
  

best.fits.uns <- 
    
  rbind(all.models$model[all.models %>% 
                       filter(half=='half1') %>% 
                       select(-contains('model'), -half) %>% 
                       apply(., 2, which.min)
                     ] %>% 
    as_data_frame() %>% 
  mutate(model = value,
         half = 'half1',
    subjects = h1.subjects, 
    .keep='unused'),
  all.models$model[all.models %>% 
                       filter(half=='half2') %>% 
                       select(-contains('model'), -half) %>% 
                       apply(., 2, which.min)
                     ] %>% 
    as_data_frame() %>% 
  mutate(model = value,
         half = 'half2',
    subjects = h1.subjects, 
    .keep='unused'))


best.fit.idx.uns <- 
  rbind(
    all.models$model.id[all.models %>%
                        filter(half=='half1') %>%  
                       select(-contains('model'), -half) %>% 
                       apply(., 2, which.min) 
                     ] %>% 
  as_data_frame() %>% 
  mutate(index = value,
         half='half1',
         subjects = h1.subjects, 
         .keep = 'unused'),

    all.models$model.id[all.models %>%
                        filter(half=='half2') %>%  
                       select(-contains('model'), -half) %>% 
                       apply(., 2, which.min) 
                     ] %>% 
  as_data_frame() %>% 
  mutate(index = value,
         half='half2',
         subjects = h1.subjects, 
         .keep = 'unused')
  )
```

```{r comparison for Ex1 and Ex2}
ex1.fits = read_csv('RMSE_fit_model_dat_07_2022.csv') %>% 
  select(subjects, model)

ex1.ex2.comp <- 
  best.fits.uns %>% 
  pivot_wider(names_from = 'half', values_from = 'model' ) %>% 
  
  inner_join(ex1.fits, by = 'subjects') %>% 
  mutate(compH1 = half1 == model, 
         compH2 = half2 == model, 
         H1H2 = compH1 & compH2, 
         H1orH2 = compH1 | compH2, 
         h1vh2 = half1==half2) 

both_halves_fit_Ex1 = mean(ex1.ex2.comp$H1H2) %>% 
  round(3)*100

H1_or_H2 = mean(ex1.ex2.comp$H1orH2)%>% 
  round(3)*100
H1_fit_Ex1 = mean(ex1.ex2.comp$compH1) %>% 
  round(3)*100
H2_fit_Ex1 = mean(ex1.ex2.comp$compH2) %>% 
  round(3)*100


### for subset of those who don't fit the same models for both as in Ex1
sub_H1_fit_Ex1 = ex1.ex2.comp %>% filter(H1H2==F) %>% summarize(mean(compH1) * 100)
sub_H2_fit_Ex1 = ex1.ex2.comp %>% filter(H1H2==F) %>% summarize(mean(compH2) * 100)
```

### How many participants have both halves fit the same model as Experiment 1?

We find that `r both_halves_fit_Ex1`% of participants have halves 1 and 2 that fit the same model as in experiment 1. For `r H1_fit_Ex1`% of participants, the first half fit the same model as in Ex1, and, `r H2_fit_Ex1`% for the second half.

```{r PART 1: overview of results}
best.fits.uns %>% 
  group_by(half, model) %>% 
  count() %>% 
  ggplot(aes(y=n, x=half,fill=model)) +
  geom_bar(stat = 'identity') +
 # facet_wrap(vars(name)) +
  scale_fill_brewer(palette = 'Reds')+
  ylab('Frequency')+
  theme_pubclean(base_size = 12) 

```

### How many participants fit different models in the two halves?

```{r compare dynamics in H1 and H2}
H1vsH2 <- 
  best.fits.uns %>% 
  pivot_wider(names_from = 'half', values_from = 'model' ) %>% 
   mutate(comp = half1==half2)

percent_diff <- 
  mean(H1vsH2$comp) %>% 
 round(4)*100

percent_diff_by_model <- 
  H1vsH2 %>% 
  group_by(half1) %>% 
  summarize(mean.n = mean(comp))

half_counts <- 
  best.fits.uns %>% 
  group_by()
  count
```

Comparing the first half with the second half, `r percent_diff`% of participants fit the same models in the second half. This means that....**[think]**.

```{r}
half_counts <-
  H1vsH2 %>% 
  mutate(toRL = half2 =="RL", 
         toLTM = half2 =="LTM" 
         ,toSTR = half2 =="STR", 
         toMETA = half2=="META"
        
         ) %>% 
  dplyr::group_by( half1) %>% 
  dplyr::summarise(RL = mean(toRL), 
                   LTM = mean(toLTM), 
                 n=n()
                 ,STR = mean(toSTR), 
                   META =mean(toMETA) 
                   )  %>% 
   pivot_longer(cols = c(RL, LTM, STR, META), names_to = 'half2', values_to = 'percent') %>% 
     dplyr::group_by( half1,half2, n, percent) %>% 
     dplyr::summarise( prop = n*percent) 
    
 # pivot_longer(cols = c(contains('prop')), names_to = 'count_c', values_to = 'n') 
 
H1vsH2 %>% 
  pivot_longer(cols = c(half1, half2), names_to='Half', values_to = 'model') %>% 
  group_by(Half) %>% 
  count(model) %>% 
  ggplot(aes(x=Half, y=n, group=model, color=model)) +
    geom_point()+
    geom_line() +
  ylab('frequency')+
    scale_color_brewer(palette = 'Set1')




half_counts %>% 
   ggplot(aes(x=half1, y=half2, fill=percent*100)) +
  geom_tile()  +
   geom_text(aes(label= round(percent,2)*100) ,size=7,
               show.legend = F) +
  scale_fill_gradient(limits=c(0,100),
                          low='white',
                           high = '#66af62',
                           #'#377eb8',
    
                          guide='colorbar',
                          aesthetics = 'fill',
                          breaks= c(0,25,50,75,100) 
                       ) +
 # facet_wrap(vars(condition))+
  xlab('Half-1') +
  ylab('Half-2') +
theme_pubclean(base_size = 20) #+
  ggtitle("count of fit changes from H1 to H2")


```

### For those participants who fit different models in the two halves, were learning outcomes affected?

```{r PART 1: join Behavioral data with model data}
acc.half.model <- 
  cor.acc.half %>% 
  inner_join(best.fits.uns, 
             by=c('subjects', 'half')) %>%
  pivot_wider(id_cols = c(subjects,condition), names_from = 'half', values_from = 'model' ) %>% 
   mutate(comp = half1==half2) %>% 
  pivot_longer(cols = c(half1, half2),names_to = 'half', values_to = 'model') %>%  
  inner_join(cor.acc.half, 
             by=c('half', 'subjects', 'condition'))
```

These scatter plots show the differences in the distributions for learning outcomes for subjects who fit the same models for H1 and H2 and different
```{r PART 1: Plots of outcomes for stable TvsF, fig.height=4, fig.width=4}

mean.acc.half.model <- 
acc.half.model %>% 
filter(comp==F) %>% 
  group_by(comp,condition, half) %>% #
  summarize(acc.mean = mean(mean.acc), 
            n=n(),
            acc.se = std(mean.acc)/sqrt(n()), 
            ) 
mean2.acc.half.model <- 
acc.half.model %>% 
filter(comp==T) %>% 
  group_by(comp,condition, half) %>% #
  summarize(acc.mean = mean(mean.acc), 
            n=n(),
            acc.se = std(mean.acc)/sqrt(n()), 
            ) 


## plot of learning outcomes for participants who did not fit the same models for half 1 and half 2
mean.acc.half.model %>% 
  
  ggplot(aes(x=half, y=acc.mean, group=1)) + 
  geom_jitter(data= acc.half.model %>% 
                filter(comp==F), 
              aes(x=half, y=mean.acc, group=half,
                  color=half),width = .2, height = 0,
              alpha=.2)+
  geom_line(size=.55)+
  geom_errorbar(aes(ymax=acc.mean+acc.se,ymin=acc.mean-acc.se, x=half,color=half ), width=.7, size=.55)+
  geom_point(size=2.5, aes( color=half))+
  facet_wrap(vars(condition)) +
  scale_color_brewer(palette = 'Dark2') +
  ylab('Mean accuracy')+
  ggtitle("Acc for participants H1=/= H2")
  

## t.test for comparisons
acc.half.model %>% 
  #filter(comp==F) %>% 
  group_by(condition) %>% 
  summarize(t_val = t.test(mean.acc[half=='half1'],mean.acc[half=='half2'])$statistic, 
            p_val= t.test(mean.acc[half=='half1'],mean.acc[half=='half2'])$p.value)
  

#### does accuracy matter interms of which model fit participants in half for TEST
accPLTDIFFTEST <- 
  acc.half.model %>% 
  filter( condition=='set3_test' | condition=='set6_test') %>% 
  pivot_wider(id_cols=c(subjects, condition, comp), names_from = half, values_from = mean.acc) %>% 
  mutate(acc_diff= half2 - half1, .keep = 'unused') %>% 
  inner_join(acc.half.model %>% 
              filter( condition=='set3_test' | condition=='set6_test') %>% 
               pivot_wider(id_cols=c(subjects, condition), names_from = half, values_from = model), 
             by = c('subjects', 'condition')) %>% 
  group_by(comp, condition, half2) %>% 
  summarize(means = mean(acc_diff),
            n=n(),
             se = std(acc_diff)/sqrt(n)
            ) %>% 
  ggplot(aes(x=half2, y=means, ymax=means+se, ymin=means-se, fill=comp, group=comp)) +
  geom_bar(stat = 'identity', position = position_dodge()) +
  #geom_text(aes(label=n), nudge_y = .1)+
  geom_errorbar(stat = 'identity', position = position_dodge(width = .9), width=.6)+
  facet_wrap(vars(condition)) +
  ylab("Change in accuracy Half-1 to Half-2") +
  xlab('Best fit model in Half-2') +
  theme_pubclean(base_size = 24) +
    scale_fill_brewer(palette = 'Set2')+
  ylim(c(-0.3, 0.3))


### does accuracy matter interms of which model fit participants in half for LEARN
accPLTDIFFLEARN <- acc.half.model %>% 
  filter(comp==F, condition=='set3_learn' | condition=='set6_learn') %>% 
  pivot_wider(id_cols=c(subjects, condition), names_from = half, values_from = mean.acc) %>% 
  mutate(acc_diff= half2 - half1, .keep = 'unused') %>% 
  inner_join(acc.half.model %>% 
              filter(comp==F, condition=='set3_learn' | condition=='set6_learn') %>% 
               pivot_wider(id_cols=c(subjects, condition), names_from = half, values_from = model), 
             by = c('subjects', 'condition')) %>% 
  group_by(condition, half2) %>% 
  summarize(means = mean(acc_diff),
            n=n(),
             se = std(acc_diff)/sqrt(n)
            ) %>% 
  ggplot(aes(x=half2, y=means, ymax=means+se, ymin=means-se)) +
  geom_bar(stat = 'identity', position = 'dodge', fill='#756bb1') +
  #geom_text(aes(label=n), nudge_y = .1)+
  geom_errorbar(stat = 'identity', position = 'dodge', width=.7)+
  facet_wrap(vars(condition)) +
  ylab("mean difference in accuracy for the two halves") +
  xlab('Best fit model in Half-2') +
  theme_pubclean(base_size = 18) +
    ylim(c(-0.3, 0.3))
ggarrange(accPLTDIFFLEARN, accPLTDIFFTEST, ncol = 1, labels = 'AUTO')

## plot of learning outcomes for participants who fit the same models for half 1 and half 2
mean2.acc.half.model %>% 
  
  ggplot(aes(x=half, y=acc.mean, group=1)) + 
  geom_jitter(data= acc.half.model %>% 
                filter(comp==T), 
              aes(x=half, y=mean.acc, group=half,
                  color=half),width = .2, height = 0,
              alpha=.2)+
  geom_line(size=.7)+
  geom_errorbar(aes(ymax=acc.mean+acc.se,ymin=acc.mean-acc.se, x=half,color=half ), width=.7, size=.7)+
  geom_point(size=3, aes( color=half))+
  facet_wrap(vars(condition)) +
  scale_color_brewer(palette = 'Dark2') +
  ggtitle("Acc for participants H1 = H2") +
  theme_pubclean(base_size = 18)

## t.test for comparisons
acc.half.model %>% 
  filter(comp==T) %>% 
  group_by(condition) %>% 
  summarize(t_val = t.test(mean.acc[half=='half1'],mean.acc[half=='half2'])$statistic, 
            p_val= t.test(mean.acc[half=='half1'],mean.acc[half=='half2'])$p.value)
  


acc.half.model %>% 

  group_by(condition, half,  comp) %>% #model,
  summarize(acc.mean = mean(mean.acc), 
            acc.se = std(mean.acc)/sqrt(n()), 
            ) %>% 
    #filter(comp==F) %>% 
  ggplot(aes(x=half, y=acc.mean, group=comp, fill=comp)) +
  geom_bar(stat = 'identity', position = 'dodge')+
  geom_errorbar(aes(ymin=acc.mean - acc.se, ymax=acc.mean + acc.se), position = 'dodge')+
  facet_wrap(vars(condition))  +
  ggtitle('comparing stable vs unstable learning outcomes for both halves')

acc.half.model %>% 
  lm(mean.acc ~ condition * comp * half, data=. ) %>% 
  anova
```


```{r PART 1: learn outcome compare, fig.width=4, fig.height=4}
acc.half.model %>% 
filter(comp==F) %>% 
  group_by(condition, half) %>% #
  summarize(acc.mean = mean(mean.acc), 
            acc.se = std(mean.acc)/sqrt(n()), 
            ) %>% 
    #filter(comp==F) %>% 
  ggplot(aes(x=half, y=acc.mean, group=half, fill=half)) +
  geom_point()+
  #geom_bar(stat = 'identity', position = 'dodge')+
 ylim(c(.5,1))+
  geom_errorbar(aes(ymin=acc.mean - acc.se, ymax=acc.mean + acc.se), position = 'dodge', width=.5)+
  facet_wrap(vars(condition)) +
  ylab('mean accuracy') +
  scale_fill_brewer(palette = 'Set2')

acc.half.model %>% 
filter(comp==F) %>% 
  group_by(condition, half) %>% #
  summarize(acc.mean = mean(mean.acc), 
            acc.se = std(mean.acc)/sqrt(n()), 
            ) %>% 
    #filter(comp==F) %>% 
  ggplot(aes(x=half, y=acc.mean, group=half, fill=half)) +
  geom_col(stat = 'identity', position = 'dodge', width=.5)+
  geom_errorbar(aes(ymin=acc.mean - acc.se, ymax=acc.mean + acc.se), position = 'dodge', width=.5)+
  facet_wrap(vars(condition)) +
  coord_cartesian(ylim=c(.5, 1))+
  
  ylab('mean accuracy') +
  scale_fill_brewer(palette = 'Set2')







```


```{r}

```


# PART II
In this section we will fit the two set-sizes separately. We aim to see if different strategies/models reliably explain the different tax demands while using the entire task. 

```{r PART II: fit subjects with models}
##########--------RL fits----------------############

RL.BIC.S3 <-  fit.models.setsize(model = 'RL', setsize = 3, 2)
RL.BIC.S6 <-  fit.models.setsize(model = 'RL', setsize = 6, 2)

##########---------LTM FITS ----------------############

LTM.BIC.S3 <-  fit.models.setsize(model = 'LTM', setsize = 3, 2)
LTM.BIC.S6 <-  fit.models.setsize(model = 'LTM', setsize = 6, 2)


##########---------RL-LTMstr FITS ----------------############

STR.BIC.S3 <-  fit.models.setsize(model = 'STR', setsize = 3, 2)
STR.BIC.S6 <-  fit.models.setsize(model = 'STR', setsize = 6, 2)


##########---------RL-LTMmeta FITS ----------------############
META.BIC.S3 <-  fit.models.setsize(model = 'META', setsize = 3, 2)
META.BIC.S6 <-  fit.models.setsize(model = 'META', setsize = 6, 2)



```


```{r PART II: SELECT BEST FITS}

all.models.ss <- 
  rbind(
    RL.BIC.S3 %>% 
      as_tibble() %>% 
      mutate(setsize = 'N3', model='RL', model.id=c(1:nrow(RL.sim))),
    RL.BIC.S6 %>% 
      as_tibble() %>% 
      mutate(setsize = 'N6', model='RL', model.id=c(1:nrow(RL.sim))),
    LTM.BIC.S3 %>% 
      as_tibble() %>% 
      mutate(setsize = 'N3', model='LTM',model.id=c(1:nrow(LTM.sim)) ),
    LTM.BIC.S6 %>% 
      as_tibble() %>% 
      mutate(setsize = 'N6', model='LTM',model.id=c(1:nrow(LTM.sim)) ),
    STR.BIC.S3 %>% 
      as_tibble() %>%
      mutate(setsize = 'N3', model='STR', model.id=c(1:nrow(STR.sim)) ),
    STR.BIC.S6 %>% 
      as_tibble() %>%
      mutate(setsize = 'N6', model='STR', model.id=c(1:nrow(STR.sim)) ),
    META.BIC.S3 %>% as_tibble() %>%
      mutate(setsize = 'N3', model='META', model.id=c(1:nrow(META.sim)) ),
    META.BIC.S6 %>% as_tibble() %>%
      mutate(setsize = 'N6', model='META', model.id=c(1:nrow(META.sim)) )
)  
  

best.fits.ss <- 
    
  rbind(all.models.ss$model[all.models.ss %>% 
                       filter(setsize=='N3') %>% 
                       select(-contains('model'), -setsize) %>% 
                       apply(., 2, which.min)
                     ] %>% 
    as_data_frame() %>% 
  mutate(model = value,
         setsize = 'N3',
    subjects , 
    .keep='unused'),
  all.models.ss$model[all.models.ss %>% 
                       filter(setsize=='N6') %>% 
                       select(-contains('model'), -setsize) %>% 
                       apply(., 2, which.min)
                     ] %>% 
    as_data_frame() %>% 
  mutate(model = value,
         setsize = 'N6',
    subjects, 
    .keep='unused'))


best.fit.idx.ss <- 
  rbind(
    all.models.ss$model.id[all.models.ss %>%
                        filter(setsize=='N3') %>%  
                       select(-contains('model'), -setsize) %>% 
                       apply(., 2, which.min) 
                     ] %>% 
  as_data_frame() %>% 
  mutate(index = value,
         setsize='N3',
         subjects, 
         .keep = 'unused'),

    all.models.ss$model.id[all.models.ss %>%
                        filter(setsize=='N6') %>%  
                       select(-contains('model'), -setsize) %>% 
                       apply(., 2, which.min) 
                     ] %>% 
  as_data_frame() %>% 
  mutate(index = value,
         setsize='N6',
         subjects, 
         .keep = 'unused')
  )

```

```{r differences in setsize model fits}
best.fit.counts.ss <- best.fits.ss %>%
  
  pivot_wider(id_cols = subjects,
              names_from = setsize,
              values_from = model) %>% 
  group_by(N6,N3) %>% 
  
 summarize(counts=n()) %>% 
  inner_join(best.fits.ss %>%
  pivot_wider(id_cols = subjects,
              names_from = setsize,
              values_from = model) %>% 
  group_by(N3) %>% 
count(), by='N3') %>% 
  mutate(percent = (counts/n)*100)

best.fit.counts.ss %>% 

  ggplot(aes(x=N3, y=N6, fill=percent, label=round(percent,2))) +
  geom_tile() +
  geom_text(color='black')+
  scale_fill_gradient(limits=c(0,100),
                          low='white',
                           high = '#d9191c',
                           #'#377eb8',
    
                          guide='colorbar',
                          aesthetics = 'fill' 
                       )+
  theme_pubclean(base_size = 18) 
  




```

### Fit counts
 Firstly, 56% of participants who fit LTM for set-size 3 also fit LTM for set-size 3, the remaining minority fit the Biased model. For those who fit the Biased model best for set-size 3, nearly 60% of them also fit the Biased model for set-size 6. The remainder fit the LTM model. For the 8 participants who fit the RL model for set-size 3, all but one fit the LTM model best for the set-size 6 condition. This pattern is slightly different from what we have seen before -  LTM is not the clear winner as before, as close to 20% of participants fit the Biased model for both set-sizes. Additionally, there seems to be a close to 40-60% split in between the two set-sizes. This suggests that changing task conditions influence strategy choice. ***** How does this compare to what we have learned before?****
 
## Do changes in strategy between set-sizes result in better performance? 


```{r PART II: join behavioral and model data}


all_sims.ss =list(list(RL.sim, LTM.sim, STR.sim, META.sim), #, STR.sim, META.sim remvoed the two combined models
     list("RL", "LTM",  "STR", "META")) %>%  #, Removed the two combined models
  pmap(get_data) %>%  
  reduce(bind_rows) %>% 
  mutate(iteration = str_remove_all(iteration, "[:alpha:]") %>%  
           as.numeric(), 
         type ='model' )

  
# separate out parameters and set them into their own long form column
all_sims.ss %<>% 
  unite(col = 'mod.id', c('data_source','model_index'), sep = '_', remove = F ) 
# join all sims with index for best fitting model - index search

index_search.ss = inner_join(
  best.fits.ss
  ,best.fit.idx.ss
  ,by = c('subjects', 'setsize')
) 

# This subset contains the best fit model data for all participants conditions
#all.p.model.dat = 
#trial 1-column multi index
index_search.ss %<>%
  mutate(condition = case_when(str_detect(setsize,'N3') ~ 'set3_learn',
                               TRUE ~ 'set6_learn' )
         ) %>% 
  rbind(index_search.ss %>%
          mutate(condition = case_when(str_detect(setsize,'N3') ~ 'set3_test',
                               TRUE ~ 'set6_test' )
                 )
        ) %>% 
  unite(col = 'mod.id', c('model','index'), sep = '_', remove = F ) 



 p.model.dat.ss <- 
   all_sims.ss %>% 
 inner_join(index_search.ss,  
    by = c('condition','mod.id')
    ) 
  
 

######### use subject.dat from above
  
# last bit -  add model identity must join by half subject and condition
  mod.id.temp.ss <-
     all_sims.ss %>%
 inner_join(index_search.ss,
    by = c('condition','mod.id')
    ) %>%
     select(c(subjects, condition, model))
  
  melted.p.behav.model.ss <- 
  rbind(subject.dat.full,
        p.model.dat.ss %>% 
          select(-c(index, data_source,
                    model_index, mod.id, 
                    model, setsize))) %>% 
  inner_join(mod.id.temp.ss,
 by=c('subjects', 'condition')
 ) %>% 
    separate(col = condition, 
             into = c('condition', 'phase'),
             remove = T )

```

```{r plot model and behavioral data}
plot.temp <- melted.p.behav.model.ss %>% 
  unique() %>% 
  select(-accuracy) %>% 
pivot_wider(id_cols = c(subjects,phase, type, iteration), names_from = condition, values_from = model) %>% 
  inner_join(melted.p.behav.model.ss %>% 
               unique() %>% 
               select(subjects,phase, type, iteration, accuracy), 
             by = c('subjects','phase', 'type', 'iteration')
             )  %>% drop_na() 

 temp.model.identity <- 
   melted.p.behav.model.ss %>% 
  unique() %>% 
  filter(iteration==12, type=='behavioral') %>% 
  select(-iteration, -type) %>% 
  pivot_wider(id_cols = c(subjects, phase), names_from = condition, values_from = model) 
  
 
temp.condition.acc <-  
  melted.p.behav.model.ss %>% 
  unique() %>% 
  filter(iteration==12, type=='behavioral') %>% 
  select(-iteration, -type) %>% 
   pivot_wider(id_cols = c(subjects, phase), names_from = condition, values_from = accuracy) %>% 
   mutate(acc.diff= set3-set6) %>% 
  select(-set3, -set6)
 
 
diff.data <- 
  inner_join(temp.model.identity, temp.condition.acc, by=c('subjects', 'phase')) %>% 
  mutate(stable=set3==set6)


diff.data %>% 
  group_by(stable, phase) %>% 
  summarise(mean.diff.accuracy = mean(acc.diff), 
            n=n(), 
            se = sd(acc.diff)/sqrt(n)
            ) %>% 
  ggplot(aes(x=stable, y=mean.diff.accuracy,
             ymax=mean.diff.accuracy+se, 
             ymin =mean.diff.accuracy-se, 
             group=stable, fill=stable)
         ) +
  geom_bar(stat = 'identity', position = position_dodge()) +
  geom_errorbar( stat='identity', position = position_dodge())+
  theme_pubclean(base_size = 18) +
  facet_wrap(vars(phase))

diff.data %>% 
  group_by(stable, phase, set3, set6) %>% 
summarise(mean.diff.accuracy = mean(acc.diff), 
            n=n(), 
            se = sd(acc.diff)/sqrt(n)) %>% 
  ggplot(aes(x=set3, y=mean.diff.accuracy,
             ymax=mean.diff.accuracy+se, 
             ymin =mean.diff.accuracy-se, 
             group=stable, fill=stable)
         ) +
  geom_bar(stat = 'identity', position = position_dodge()) +
  geom_errorbar( stat='identity', position = position_dodge())+
  theme_pubclean(base_size = 18)+
  facet_wrap(vars(phase)) +
  ggtitle('Split up by set3 models')




plot.temp %>% 
  group_by(set3, set6,iteration, phase, type ) %>% 
  summarise(mean.accuracy = mean(accuracy), 
            n=n(), 
            se = sd(accuracy)/sqrt(n)) %>% 
  mutate(stable= set3==set6) 
  pivot_longer(cols = c(set3,set6), names_to = 'condition', values_to = 'model' ) %>% 
  filter(iteration==12, type=='behavioral') %>% 
ggplot(aes(y=mean.accuracy,x=condition, 
           ymax = mean.accuracy + se, 
           ymin = mean.accuracy - se, 
           group=stable, fill=stable)
       ) +
 # geom_jitter(width = .2, alpha=.5, size=3)+
 geom_bar(stat = 'identity', position = position_dodge()) +
  geom_errorbar( stat='identity', position = position_dodge())+
  theme_pubclean(base_size = 18)+
  facet_wrap(vars(phase, model))
  
  
  
  
  
```

```{r subtract switchers from non switchers}
temp.switch.identity <- 
  temp.model.identity %>% 
   mutate(stable=set3==set6) %>% 
  select(-set3, -set6)


temp.acc.ss <- 
   melted.p.behav.model.ss %>% 
  unique() %>% 
  filter(iteration==12, type=='behavioral') %>% 
  select(-iteration, -type)


switchersvsnon <-  inner_join(temp.switch.identity,temp.acc.ss, by=c('subjects', 'phase') ) %>% 
  pivot_wider(id_cols = -subjects, names_from = stable, values_from = accuracy)

```

# PART III

As described above, learning data for all participants were split into the first 6 stimulus iterations and the last 6 before model fitting. Additionally, the two conditions, set-size 3 and set-size 6 were also fit separately.

```{r PART III: fit subjects with models}


  
##########--------RL fits----------------############

RL.BIC.half1.N3 <-  fit.models(model = 'RL', half = 1, setsize = 3, 2)
RL.BIC.half1.N6 <- fit.models('RL',1,6,2)
RL.BIC.half2.N3 <-  fit.models('RL',2,3,2)
RL.BIC.half2.N6 <-  fit.models('RL',2,6,2)
##########---------LTM FITS ----------------############

LTM.BIC.half1.N3 <- fit.models('LTM',1,3,3)
LTM.BIC.half1.N6 <- fit.models('LTM',1,6,3) 
LTM.BIC.half2.N3 <- fit.models('LTM',2,3,3)
LTM.BIC.half2.N6 <- fit.models('LTM',2,6,3)

##########---------RL-LTMstr FITS ----------------############
if(1){
STR.BIC.half1.N3.learn <- fit.models('STR',1,3,6)


STR.BIC.half1.N6.learn <- fit.models('STR',1,6,6)

 
STR.BIC.half2.N3.learn <- fit.models('STR',2,3,6)
STR.BIC.half2.N6.learn <- fit.models('STR',2,6,6)


##########---------RL-LTMmeta FITS ----------------############

META.BIC.half1.N3 <- fit.models('META',1,3,5)
META.BIC.half1.N6 <- fit.models('META',1,6,5)
META.BIC.half2.N3 <- fit.models('META',2,3,5)
META.BIC.half2.N6 <- fit.models('META',2,6,5)
}
```

```{r PART III: aggregate model fits}
# generate model id and parameter set ids and concat all sets

half1.N3 <- rbind(
  RL.BIC.half1.N3 %>% 
    as_tibble() %>% 
    mutate(model='RL', model.id=c(1:nrow(RL.sim))), 
  LTM.BIC.half1.N3 %>% 
    as_tibble() %>% 
    mutate(model='LTM',model.id=c(1:nrow(LTM.sim)) )
  ,STR.BIC.half1.N3.learn %>%
    as_tibble() %>%
    mutate(model='STR', model.id=c(1:nrow(STR.sim)) ),
  META.BIC.half1.N3 %>% as_tibble() %>% mutate(model='META',
                                               model.id=c(1:nrow(META.sim)) )
)

half1.N6 <- rbind(RL.BIC.half1.N6 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half1.N6 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  ,STR.BIC.half1.N6.learn %>% as_tibble() %>% mutate(model='STR',
                                                                    model.id=c(1:nrow(STR.sim))),
                  META.BIC.half1.N6 %>% as_tibble() %>% mutate(model='META',
                                                               model.id=c(1:nrow(META.sim)))
                  )
half2.N3 <- rbind(RL.BIC.half2.N3 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half2.N3 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  ,STR.BIC.half2.N3.learn %>% as_tibble() %>% mutate(model='STR',
                                                                    model.id=c(1:nrow(STR.sim))),
                  META.BIC.half2.N3 %>% as_tibble() %>% mutate(model='META',
                                                               model.id=c(1:nrow(META.sim)))
                  )
half2.N6 <- rbind(RL.BIC.half2.N6 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half2.N6 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  ,STR.BIC.half2.N6.learn %>% as_tibble() %>% mutate(model='STR',
                                                                    model.id=c(1:nrow(STR.sim))),
                  META.BIC.half2.N6 %>% as_tibble() %>% mutate(model='META',
                                                               model.id=c(1:nrow(META.sim)))
                  )




best.fits <- tibble('half1_N3' = half1.N3$model[half1.N3 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half1_N6' = half1.N6$model[half1.N6 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half2_N3' = half2.N3$model[half2.N3 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half2_N6' = half2.N6$model[half2.N6 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)]) %>% 
  data.frame() %>% 
  mutate(type = "model.id", 
         subjects = h1.subjects) %>%  
  pivot_longer(cols = starts_with("half"), 
               values_to = "model")


best.fit.idx <- tibble('half1_N3' = half1.N3$model.id[half1.N3 %>% select(-contains('model')) %>% apply(., 2, which.min)],
                       'half1_N6'=  half1.N6$model.id[half1.N6 %>% select(-contains('model')) %>% apply(., 2, which.min)], 
                       'half2_N3'= half2.N3$model.id[half2.N3 %>% select(-contains('model')) %>% apply(., 2, which.min)], 
                       'half2_N6'= half2.N6$model.id[half2.N6 %>% select(-contains('model')) %>% apply(., 2, which.min)]
) %>%  
  data.frame() %>%
  mutate(type = "index", 
         subjects = h1.subjects) %>%  
  pivot_longer(cols = starts_with("half"), 
               values_to = "index")

```

```{r part IIIA join model-behavioral data}
#subjects model model_id half type setsize iteration accuracy parameter parameter value 

# Function reduces the lists of simulations to long-form dataframes.

getParam <- function(data, data_name){
   c('alpha','egs', 'bll', 'imag','ans') %>% #, 'bias' 
      map (~
             {
               temp = data %>% 
                 .[[.x]]
               
               data.frame(
                  model_index= c(1:nrow(data)),
                 condition=.x, 
                 accuracy=rep(temp, 12)
               )
               
             }
      )
  
  }
  

```

```{r part IIIB join model-behavioral data}


all_sims =list(list(RL.sim, LTM.sim), #, STR.sim, META.sim remvoed the two combined models
     list("RL", "LTM")) %>%  #, "STR", "META" Removed the two combined models
  pmap(get_data) %>%  
  reduce(bind_rows) %>% 
  mutate(iteration = str_remove_all(iteration, "[:alpha:]") %>%  
           as.numeric(), 
         type ='model' )

  
# separate out parameters and set them into their own long form column
all_sims %<>% 
  # filter(!str_detect(condition, 'set')) %>% 
  # select(condition, accuracy, data_source, model_index) %>% 
  # unique %>% 
  # pivot_wider( values_from = accuracy, names_from = condition) %>% 
  # inner_join(all_sims %>% 
  #              filter(str_detect(condition, 'set')),
  #            by = c('data_source','model_index')) %>% 
  # mutate('alpha' = scale(alpha), 
  #        'egs' = scale(egs) ,
  #        'bll' = scale(bll),
  #        'imag' = scale(imag),
  #        'ans' = scale(ans) ) %>% 
  # pivot_longer(cols = c('alpha', 'egs', 'bll','imag','ans'), names_to = 'parameter', values_to = 'param_vals') %>% 
  unite(col = 'mod.id', c('data_source','model_index'), sep = '_', remove = F ) 



# join all sims with index for best fitting model - index search

index_search = merge(
  best.fits
  ,best.fit.idx
  ,by = c('subjects', 'name')
) %>%  
  select(!contains("type"))

# This subset contains the best fit model data for all participants conditions
#all.p.model.dat = 
#trial 1-column multi index
index_search %<>%
  mutate(condition = case_when(str_detect(name,'N3') ~ 'set3_learn',
                               TRUE ~ 'set6_learn' )
         ) %>% 
  rbind(index_search %>%
          mutate(condition = case_when(str_detect(name,'N3') ~ 'set3_test',
                               TRUE ~ 'set6_test' )
                 )
        ) %>% 
  unite(col = 'mod.id', c('model','index'), sep = '_', remove = F ) 




# hlp=  index_search %>% 
#  # sample_n(2) %>% 
#   base::merge(all_sims
#      #   ,by.x = c("model", "index")
#     #    ,by.y = c("data_source", "model")
#     ,by ='mod.id'
#       #  ,all.x = T
#     )

 p.model.dat <- 
   all_sims %>% 
 inner_join(index_search,  
    by = c('condition','mod.id')
    ) %>% 
     dplyr::mutate('half' = name, .keep ='unused') %>%
     select(-c(model, data_source, model_index, index, mod.id)) %>% 
    mutate(half= str_remove_all(half, pattern = "_N."))
 # arrange(condition) %>% 
  
 

######### use subject.dat from above
  
# last bit -  add model identity must join by half subject and condition
  mod.id.temp <- 
     all_sims %>% 
 inner_join(index_search,  
    by = c('condition','mod.id')
    ) %>% 
     dplyr::mutate('half' = name, .keep ='unused') %>%
     select(c(subjects, condition, model, half)) %>% ## can add model_index here if that information is needed
    mutate(half= str_remove_all(half, pattern = "_N."))
  
  melted.p.behav.model <- 
  rbind(subject.dat, p.model.dat) %>% 
  inner_join(mod.id.temp,
 by=c('subjects', 'half', 'condition')
 ) %>% 
    separate(col = condition, into = c('condition', 'phase'), remove = T )

parameter.dat <- 
  inner_join(index_search %>% 
               filter(condition=='set3_learn' |condition=='set6_learn' ), 
             rbind(data.frame(scale(RL.sim[,c('alpha','egs', 'bll', 'imag','ans')]), 
                              model='RL', index=c(1:nrow(RL.sim))),
                   data.frame(scale(LTM.sim[,c('alpha','egs', 'bll', 'imag','ans')]), 
                              model='LTM', index=c(1:nrow(LTM.sim)))
                   ),
             by = c('index', 'model')
             ) %>% 
  pivot_longer(cols = c('alpha','egs', 'bll', 'imag','ans'),
               names_to = 'parameter',
               values_to = 'param_vals')

#parameter.dat[(parameter.dat$param_vals==0), 'param_vals'] = NA

# parameter.dat %<>% 
#   dplyr::mutate(param_vals_sc=scale(param_vals))  
parameter.dat %>% filter(subjects==6209) 
  
  
  
  
```


## Overview of modelfitting results

```{r, fig.cap='Figure x', fig.width=3.4, fig.height=3.2, dpi=300}

best.fits %>% 
  group_by(name, model) %>% 
  count() %>% 
  ggplot(aes(y=n, x=name,fill=model)) +
  geom_bar(stat = 'identity') +
 # facet_wrap(vars(name)) +
  scale_fill_brewer(palette = 'Reds')+
  ylab('Frequency')+
  #geom_text( aes(y=c(5), label=n, size=6, fill='red'), check_overlap = T, parse = T) +
  theme_pubclean(base_size = 12) 
  
counts.half <- 
  best.fits %>% 
  dplyr::group_by(name, model) %>% 
  count() %>% 
  separate(col = name, into = c('half','condition')) %>% 
  dplyr::group_by(half, model) %>% 
  dplyr::summarise(m=mean(n))

counts.condition <- 
  best.fits %>% 
  dplyr::group_by(name, model) %>% 
  count() %>% 
  separate(col = name, into = c('half','condition')) %>% 
  dplyr::group_by(condition, model) %>% 
  dplyr::summarise(m=mean(n))

counts.both <-
  best.fits %>% 
  dplyr::group_by(name, model) %>% 
  count() %>% 
  separate(col = name, into = c('half','condition')) %>% 
  dplyr::group_by(half, condition, model) %>% 
  dplyr::summarise(m=mean(n))
  

```

We found that the LTM model still fit more subjects in both halves (first half- LTM: M = `r counts.half$m[1]`, RL: M = `r counts.half$m[3]`, META: M = `r counts.half$m[2]`, STR: `r M = counts.half$m[4]` ; second half- LTM: M = `r counts.half$m[5]`, RL: M = `r counts.half$m[7]`, META: M = `r counts.half$m[6]`, STR: `r M = counts.half$m[8]` ), and conditions (set-size 3 - LTM: M = `r counts.condition$m[1]`, RL: M = `r counts.condition$m[3]`, META: M = `r counts.condition$m[2]`, STR: M = `r counts.condition$m[4]`; set-size 6 - LTM: M = `r counts.condition$m[5]`, RL: M = `r counts.condition$m[7]`, META: M = `r counts.condition$m[6]`, STR: M = `r counts.condition$m[8]`) much like the results obtained through the model fitting procedure in experiment 1 (Figure 1). Furthermore, more subjects fit the LTM model in the set-size 3 condition compared to the set-size 6 condition (more in the first half than in the second half, for both), which means, for those subjects that fit the RL model, higher numbers of subjects fit RL model for set-size 6 conditions than set-size 3 (more in the second half than in the first half for both conditions). This trend aligns more with Collins (2018) findings but these results do not take into account individual dynamics (covered in detail below).

```{r fit tests, fig.width=4.2, fig.height=3.2,dpi=300}

  counts.both %>% 
  ggplot(aes(x=half, y=m, color=model, group=model)) +
  geom_point()+
  geom_line() +
  scale_color_brewer(palette = 'Set1') +
  facet_wrap(vars(condition)) +
  theme_pubclean(base_size = 12) +
  theme(legend.position = 'right')

```

### If you look at the 2nd half, what % of people have the same model for 3 and 6, and how many fit different models?

```{r how many people fit same model in h2, fig.width=4, fig.height=4}


 # filter(half=='half2') %>% 
 count.cond.fits <-  best.fits %>% 
  separate(col = name, into = c('half','condition')) %>% 
  pivot_wider(names_from = condition, values_from = model ) %>% 
  mutate(stable= N3==N6) 

count.cond.fits %>% 
  dplyr::group_by(half) %>%
  count(stable) %>% 
  ggplot(aes(x=stable, y=n, group=half, fill=half)) +
  geom_bar(stat='identity', position = 'dodge') +
  scale_fill_brewer(palette = 'Set2')
 

set_size_fits <- 
  best.fits %>% 
  select(-type) %>% 
 #filter(subjects==6202) %>% 
  separate(col = name, into = c('half','setsize')) %>% 
  mutate(set_size= case_when(setsize=='N3' ~ 'set3',
                             setsize=='N6' ~ 'set6')) %>% 
  
  inner_join(acc.half.model %>% 
               select(-comp, -model) %>% 
            #   filter(subjects==6202) %>% 
               separate(condition, into = c('set_size','condition' )), 
             by=c('subjects', 'half','set_size' ))


set_size_fits_comp <- 
set_size_fits %>% 
  select(-setsize) %>% 
   pivot_wider(id_cols = c(subjects, half, condition), names_from = set_size, values_from = model ) %>% 
  mutate(stable= set3==set6) %>%
  pivot_longer(cols = c(set3, set6),names_to = 'set_size', values_to = 'model') %>%  
  inner_join(set_size_fits %>% select(-setsize), 
             by=c('half', 'subjects', 'condition', 'set_size', 'model'))
   

set_size_fits_comp2 <- 
set_size_fits_comp %>% 
  #unite(col='stable_half', half, stable, remove = F) %>% 
 pivot_wider(id_cols = c(subjects, condition, set_size), names_from = half, values_from = stable) %>% 
  inner_join(set_size_fits_comp %>% 
               select(subjects, condition, set_size, mean.acc, half), 
             by=c('subjects', 'condition', 'set_size')) %>% 
 group_by(half, half1,half2, set_size,condition) %>% 
  summarize(accuracy = mean(mean.acc),
            n=n(),
            se= std(mean.acc)/sqrt(n())) 

### 'acc for: H1 same and H2 diff '
set_size_fits_comp2 %>% 
  filter(half1==T & half2==F) %>% 
  ggplot(aes(x=set_size, y=accuracy, group=half, fill=half)) +
  geom_bar(stat='identity', position='dodge') +
  geom_errorbar(aes(ymin = accuracy-se, ymax=accuracy+se), position='dodge') +
  ggtitle('acc for: H1 same and H2 diff ') +
  facet_wrap(vars(condition)) +
  coord_cartesian(ylim=c(.5, 1)) +
   scale_fill_brewer(palette = 'Set2')

  
  

### 'acc for: H1 same and H2 same'
set_size_fits_comp2 %>% 
  filter(half1==T & half2==T) %>% 
  ggplot(aes(x=set_size, y=accuracy, group=half, fill=half)) +
  geom_bar(stat='identity', position='dodge') +
  geom_errorbar(aes(ymin = accuracy-se, ymax=accuracy+se), position='dodge') +
  ggtitle('acc for: H1 same and H2 same ') +
  facet_wrap(vars(condition)) +
  coord_cartesian(ylim=c(.5, 1)) +
   scale_fill_brewer(palette = 'Set2')
#### 'acc for: H1 diff and H2 same'

set_size_fits_comp2 %>% 
   filter(half1==F & half2==T) %>% 
   ggplot(aes(x=condition, y=accuracy, group=set_size, fill=set_size)) +
  geom_bar(stat='identity', position='dodge') +
  geom_errorbar(aes(ymin = accuracy-se, ymax=accuracy+se), position='dodge') +
  ggtitle('acc for: H1 diff and H2 same') +
  facet_wrap(vars(half)) +
  coord_cartesian(ylim=c(.5, 1))
  
```

```{r stat tests for H1 same vs H2 different folks}

 ## stat tests
set_size_fits_comp %>% 
  #unite(col='stable_half', half, stable, remove = F) %>% 
 pivot_wider(id_cols = c(subjects, condition, set_size), names_from = half, values_from = stable) %>% 
  inner_join(set_size_fits_comp %>% 
               select(subjects, condition, set_size, mean.acc, half), 
             by=c('subjects', 'condition', 'set_size')) %>% 
   filter(half1==T & half2==F) %>% 
 group_by(set_size,condition) %>% 
  summarize(t_stat = t.test(mean.acc[half=='half1'], mean.acc[half=='half2'])$statistic,
            p.val = t.test(mean.acc[half=='half1'], mean.acc[half=='half2'])$p.value )
```

### for the group that swithced, what model fit them best in the second half for set3 and 6?

```{r}

temp.count <- 
set_size_fits_comp %>% 
  select(-mean.acc) %>% 
   pivot_wider(id_cols = c(subjects, condition, set_size), names_from = half, values_from = stable) %>% 
  inner_join(set_size_fits_comp %>% 
               select(subjects, condition, set_size, half, model), 
             by=c('subjects', 'condition', 'set_size')) %>% 
  pivot_wider(names_from = set_size, values_from = model) %>% 
  select(-condition) %>% 
  unique() %>% 
  filter(half1==T & half2==F) %>% 
  select( -half1, -half2) %>% 
  mutate(model = set3, 
         Half=half) %>% 
  pivot_wider(names_from = Half, values_from = model) 


temp.count %>% 
  select(half, subjects, set3, set6) %>% 
  filter(half=='half2') %>% 
  inner_join( temp.count %>% 
                select(subjects,half1) %>% 
                drop_na(), 
              by = 'subjects') %>% 
  pivot_longer(cols = c(set3, set6), names_to = 'set_size', values_to = 'half2_models') %>% 
  
  group_by(set_size, half1, half2_models) %>% 

  summarize(n=n()) %>% 
   ungroup() %>% 
  
  inner_join( temp.count %>% 
  select(half, subjects, set3, set6) %>% 
  filter(half=='half2') %>% 
  inner_join( temp.count %>% 
                select(subjects,half1) %>% 
                drop_na(), 
              by = 'subjects') %>% 
  pivot_longer(cols = c(set3, set6), names_to = 'set_size', values_to = 'half2_models') %>% 
  
  group_by(set_size, half1, half2_models) %>% 

  summarize(n=n()) %>% 
   ungroup() %>% 
                group_by(set_size, half1) %>% 
  summarise(total=sum(n)),
  by=c('set_size', 'half1')) %>% 
  mutate(percent = n/total) %>% 


   ggplot(aes(x=half1, y=half2_models, fill=percent)) +
   geom_tile()+
  
 # geom_bar(stat = 'identity', position = 'dodge') +
 #  geom_text() +
  facet_wrap (vars(set_size)) +
  ylab('Half 2 model counts')+
  scale_fill_brewer(palette = 'Set1')

## what was the effect on learning outcomes?

  set_size_fits_comp %>% 
    filter(stable==F, half=='half2') %>% 
    group_by(model, set_size, condition) %>% 
 summarise(mean_accuracy =mean(mean.acc), 
           n=n(), 
           se= std(mean.acc)/sqrt(n)) %>% 
    ggplot(aes(x=condition, y=mean_accuracy, 
               ymax=mean_accuracy+se, ymin=mean_accuracy-se,
               fill=model, group=model))+
    geom_bar(stat = 'identity', position = 'dodge') +
    geom_errorbar(position = 'dodge')+
    facet_wrap(vars(set_size)) +
    scale_fill_brewer(palette = 'Set1') +
    ggtitle('For non-stable - learning outcomes by model')
    
  ### how do those people who were stable work?
  set_size_fits_comp %>% 
    filter(stable==T, half=='half2') %>% 
    group_by(model, set_size, condition) %>% 
 summarise(mean_accuracy =mean(mean.acc), 
           n=n(), 
           se= std(mean.acc)/sqrt(n)) %>% 
    ggplot(aes(x=condition, y=mean_accuracy, 
               ymax=mean_accuracy+se, ymin=mean_accuracy-se,
               fill=model, group=model))+
    geom_bar(stat = 'identity', position = 'dodge') +
    geom_errorbar(position = 'dodge')+
    facet_wrap(vars(set_size)) +
    scale_fill_brewer(palette = 'Set1') +
    ggtitle('For stable - learning outcomes by model')
    
```
