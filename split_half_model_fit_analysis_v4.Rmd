---
title: "RLWM ACT-R RMSE model fitting and outcome analysis for split-half data"
author: "Theodros H."
date: "05/2022"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_float: yes
editor_options:
  chunk_output_type: console
---

# Results
### Model fits

```{r set up, echo=FALSE, warning=FALSE, message=FALSE}
rm(list = ls())
library(tidyverse)
library(ggpubr)
library(matlab)
library(MLmetrics)
library(jsonlite)
library(knitr)
library(Rmisc)
library(magrittr)
library(data.table)
library(skimr)

knitr::opts_chunk$set(
  comment = "#>", echo = FALSE, warning = FALSE, 
  message = FALSE 
 
)
theme_set(theme_pubclean(base_size = 12)) 

```


```{r import  data}
# sdat contains data fro 83 participants (columns), 
# rows 1:12 learn accuracy set 3 ; 
# rows 13:24 learn accuracy set 6 ;
# row 25 test set 3 accuracy ;
# row 26 test set 6 accuracy ;

sdat.h1 = read.csv('./RLWM_data/Half1_all_subject_n83_learn_test_data.csv',header = T) 
h1.subjects <-  sdat.h1$V1
sdat.h1 <- sdat.h1[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h1 <- cbind(
  sdat.h1[ ,1:12],
                   matrix(sdat.h1[ ,25],
                          nrow = numel(sdat.h1[ ,25]), ncol = 12),
                   sdat.h1[ ,13:24],
                  matrix(sdat.h1[ ,26],nrow = numel(sdat.h1[ ,25]), ncol = 12) )

sdat.h2 = read.csv('./RLWM_data/Half2_all_subject_n83_learn_test_data.csv', header = T) 

h2.subjects <-  sdat.h2$V1
sdat.h2 <- sdat.h2[, 2:27] # exclude the subjects column
#modify sdat to balance learn and test data points by replicating test datapoint into 12
sdat.repl.h2 <- cbind(sdat.h2[ ,1:12],
                   matrix(sdat.h2[ ,25],
                          nrow = numel(sdat.h2[ ,25]), ncol = 12),
                   sdat.h2[ ,13:24],
                  matrix(sdat.h2[ ,26],
                         nrow = numel(sdat.h2[ ,25]), ncol = 12) )


RL.sim <- fromJSON('./simulated_data/RL_model/RL_sim_data_07_12_2022.JSON')$data %>% 
  dplyr::mutate(bias = 0)

# RL.sim$set3_test <- matrix(
#               RL.sim$set3_test,
#               nrow = numel( RL.sim$set3_test),
#               ncol = 12 )
# RL.sim$set6_test <- matrix(
#               RL.sim$set6_test,
#               nrow = numel( RL.sim$set6_test),
#               ncol = 12 )
LTM.sim <- fromJSON('./simulated_data/LTM_model/LTM_sim_data_02202021.JSON')$data %>% 
  dplyr::mutate(bias = 0 )
# LTM.sim$set3_test <- matrix(
#               LTM.sim$set3_test,
#               nrow = numel( LTM.sim$set3_test),
#               ncol = 12 )



STR.sim <- fromJSON('./simulated_data/strategy_model/STR_sim_data_032021.JSON')$data %>% 
  dplyr::mutate(bias = str_remove_all(strtg, "[:alpha:]") %>% as.numeric()/100, .keep=c('unused'))

META.sim <- fromJSON('./simulated_data/pipe_model/pipe_sim_data_032021.JSON')$data %>% 
   dplyr::mutate(bias = strtg,
          bias3 = strtg3,
          bias6 = strtg6, .keep='unused')

```


```{r fit subjects with models}

#(1) Transform RMSE into residual sum of squares by doing RSS = RMSE^2 * n
#11:34
#(2) Calculate BIC as: BIC = n + n log (2*pi) + n log (RSS/n) + log(n) * (k + 1)
#11:36
#In RL, k = 2; in LTM, k = 3; and Integrated, k = 5 or k = 6

#MAP 
Andys_BIC <- function(rmse, k, n) {
  # RSS first
  #n = 48 #lean3 + learn 6 + (test3)*12 + (test6)*12
  RSS <- ((rmse)^2) * n
  # BIC next
  bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
  
  return(bic)
}


fit.subject <- function(behav.dat, model.dat){

apply(model.dat, 1, function(x,y) MSE(x, behav.dat)) %>% sqrt()
   
}


fit.models <- function(model, half, setsize, params) {
  #select model
  # if (model == 'RL') {
  #   model = RL.sim
  # }
  # if (model == 'LTM') {
  #   model = LTM.sim
  # }
  # if (model == 'STR') {
  #   model = STR.sim
  # }
  # if (model == 'META') {
  #   model = META.sim
  # }
  # 
  # select subject data
  if (half == 1) {
    sdat = sdat.repl.h1
  } 
  if(half ==2) {
    sdat = sdat.repl.h2
  }
 
  # select setsize
  
  if (setsize == 3) {
    ns = 1:24
    n_size = 'set3_'
  } 
  
  if(setsize == 6){
    ns = 25:48
  
    n_size='set6_'
  }
 
  
  dat.learn = eval(
      parse(text=paste0(model,'.sim$',n_size, 'learn')
                                 )
                           ) %>% 
    reduce(rbind)
                      
  
  dat.test =  matrix(
              eval(
                parse(text=paste0(model,'.sim$',n_size, 'test'))),
              nrow = numel(eval(parse(text=paste0(model,'.sim$',n_size, 'test')))),
              ncol = 12)
 
  
  apply( sdat[, ns], 1,
        function(x, y)
          fit.subject(x, 
                      (cbind(dat.learn, dat.test)
                       )
                      )) %>%
    Andys_BIC(k = params, n = 24)
  
}
  
##########--------RL fits----------------############

RL.BIC.half1.N3 <-  fit.models(model = 'RL',half = 1, setsize = 3, 2)
RL.BIC.half1.N6 <- fit.models('RL',1,6,2)
RL.BIC.half2.N3 <-  fit.models('RL',2,3,2)
RL.BIC.half2.N6 <-  fit.models('RL',2,6,2)
##########---------LTM FITS ----------------############

LTM.BIC.half1.N3 <- fit.models('LTM',1,3,3)
LTM.BIC.half1.N6 <- fit.models('LTM',1,6,3) 
LTM.BIC.half2.N3 <- fit.models('LTM',2,3,3)
LTM.BIC.half2.N6 <- fit.models('LTM',2,6,3)

##########---------RL-LTMstr FITS ----------------############
if(0){
STR.BIC.half1.N3.learn <- fit.models('STR',1,3,6)


STR.BIC.half1.N6.learn <- fit.models('STR',1,6,6)

 
STR.BIC.half2.N3.learn <- fit.models('STR',2,3,6)
STR.BIC.half2.N6.learn <- fit.models('STR',2,6,6)


##########---------RL-LTMmeta FITS ----------------############

META.BIC.half1.N3 <- fit.models('META',1,3,5)
META.BIC.half1.N6 <- fit.models('META',1,6,5)
META.BIC.half2.N3 <- fit.models('META',2,3,5)
META.BIC.half2.N6 <- fit.models('META',2,6,5)
}
```

```{r}
# generate model id and parameter set ids and concat all sets

half1.N3 <- rbind(
  RL.BIC.half1.N3 %>% 
    as_tibble() %>% 
    mutate(model='RL', model.id=c(1:nrow(RL.sim))), 
  LTM.BIC.half1.N3 %>% 
    as_tibble() %>% 
    mutate(model='LTM',model.id=c(1:nrow(LTM.sim)) )
  # ,STR.BIC.half1.N3.learn %>% 
  #   as_tibble() %>% 
  #   mutate(model='STR', model.id=c(1:nrow(STR.sim)) ),
  # META.BIC.half1.N3 %>% as_tibble() %>% mutate(model='META',
  #                                              model.id=c(1:nrow(META.sim)) )
)
half1.N6 <- rbind(RL.BIC.half1.N6 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half1.N6 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  # ,STR.BIC.half1.N6.learn %>% as_tibble() %>% mutate(model='STR',
                  #                                                   model.id=c(1:nrow(STR.sim))),
                  # META.BIC.half1.N6 %>% as_tibble() %>% mutate(model='META',
                  #                                              model.id=c(1:nrow(META.sim)))
                  )
half2.N3 <- rbind(RL.BIC.half2.N3 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half2.N3 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  # ,STR.BIC.half2.N3.learn %>% as_tibble() %>% mutate(model='STR',
                  #                                                   model.id=c(1:nrow(STR.sim))),
                  # META.BIC.half2.N3 %>% as_tibble() %>% mutate(model='META',
                  #                                              model.id=c(1:nrow(META.sim)))
                  )
half2.N6 <- rbind(RL.BIC.half2.N6 %>% as_tibble() %>% mutate(model='RL',
                                                             model.id=c(1:nrow(RL.sim))), 
                  LTM.BIC.half2.N6 %>% as_tibble() %>% mutate(model='LTM',
                                                              model.id=c(1:nrow(LTM.sim)))
                  # ,STR.BIC.half2.N6.learn %>% as_tibble() %>% mutate(model='STR',
                  #                                                   model.id=c(1:nrow(STR.sim))),
                  # META.BIC.half2.N6 %>% as_tibble() %>% mutate(model='META',
                  #                                              model.id=c(1:nrow(META.sim)))
                  )




best.fits <- tibble('half1_N3' = half1.N3$model[half1.N3 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half1_N6' = half1.N6$model[half1.N6 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half2_N3' = half2.N3$model[half2.N3 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)],
                    'half2_N6' = half2.N6$model[half2.N6 %>% select(-contains('model')) %>% 
                                                      apply(., 2, which.min)]) %>% 
  data.frame() %>% 
  mutate(type = "index", 
         subjects = h1.subjects) %>%  
  pivot_longer(cols = starts_with("half"), 
               values_to = "model")


best.fit.idx <- tibble('half1_N3' = half1.N3$model.id[half1.N3 %>% select(-contains('model')) %>% apply(., 2, which.min)],
                       'half1_N6'=  half1.N6$model.id[half1.N6 %>% select(-contains('model')) %>% apply(., 2, which.min)], 
                       'half2_N3'= half2.N3$model.id[half2.N3 %>% select(-contains('model')) %>% apply(., 2, which.min)], 
                       'half2_N6'= half2.N6$model.id[half2.N6 %>% select(-contains('model')) %>% apply(., 2, which.min)]
) %>%  
  data.frame() %>%
  mutate(type = "index", 
         subjects = h1.subjects) %>%  
  pivot_longer(cols = starts_with("half"), 
               values_to = "index")

```

```{r}
best.fits %>% 
  group_by(name, model) %>% 
  count(c('model', 'name'))


best.fits %>% 
  group_by(name, model) %>% 
  count(c('model', 'name')) %>% 
  ggplot(aes(y=freq, x=name,fill=model)) +
  geom_bar(stat = 'identity') +
 # facet_wrap(vars(name)) +
  scale_fill_brewer(palette = 'Reds')+
  #geom_text( aes(y=c(5), label=freq, size=6, fill='red'), check_overlap = T, parse = T) +
  theme_pubclean(base_size = 18) 
  

```
 
```{r part 1 join model-behavioral data}
#subjects model model_id half type setsize iteration accuracy parameter parameter value 

# Function reduces the lists of simulations to long-form dataframes.
get_data = function(data, data_name){
  bind_rows(
    c('set3_learn','set6_learn') %>% 
      map(~
            #column is measurement at T, record is simulation
            data %>% 
            .[[.x]] %>% 
            reduce(rbind) %>% 
            data.frame() %>% 
            mutate(condition = .x, 
                   model_index= c(1:nrow(data))
            )
      ) %>% 
      reduce(bind_rows) %>% 
      pivot_longer(cols = starts_with('x')
                   ,values_to = 'accuracy', names_to = 'iteration'),
    
    c('set3_test', 'set6_test','alpha','egs', 'bll', 'imag','ans', 'bias') %>%
      map (~
             {
               temp = data %>% 
                 .[[.x]]
               
               data.frame(
                  model_index= c(1:nrow(data)),
                 condition=.x, 
                 iteration=paste0('X', rep(c(1:12), nrow(data))), 
                 accuracy=rep(temp, 12)
               )
               
             }
      )
  
  ) %>%  
    mutate(data_source = data_name)
}


```

```{r part 2 join model-behavioral data}


all_sims =list(list(RL.sim, LTM.sim), #, STR.sim, META.sim remvoed the two combined models
     list("RL", "LTM")) %>%  #, "STR", "META" Removed the two combined models
  pmap(get_data) %>%  
  reduce(bind_rows) %>% 
  mutate(iteration = str_remove_all(iteration, "[:alpha:]") %>%  
           as.numeric(), 
         type ='model' )

  
# separate out parameters and set them into their own long form column
all_sims %<>% 
  filter(!str_detect(condition, 'set')) %>% 
  select(condition, accuracy, data_source, model_index) %>% 
  unique %>% 
  pivot_wider( values_from = accuracy, names_from = condition) %>% 
  inner_join(all_sims %>% 
               filter(str_detect(condition, 'set')),
             by = c('data_source','model_index')) %>% 
  pivot_longer(cols = c('alpha', 'egs', 'bll','imag','ans', 'bias'), names_to = 'parameter', values_to = 'param_vals') %>% 
  unite(col = 'mod.id', c('data_source','model_index'), sep = '_', remove = F ) 




  



# join all sims with index for best fitting model - index search

index_search = merge(
  best.fits
  ,best.fit.idx
  ,by = c('subjects', 'name')
) %>%  
  select(!contains("type"))

# This subset contains the best fit model data for all participants conditions
#all.p.model.dat = 
#trial 1-column multi index
index_search %<>%
  mutate(condition = case_when(str_detect(name,'N3') ~ 'set3_learn',
                               TRUE ~ 'set6_learn' )
         ) %>% 
  rbind(index_search %>%
          mutate(condition = case_when(str_detect(name,'N3') ~ 'set3_test',
                               TRUE ~ 'set6_test' )
                 )
        ) %>% 
  unite(col = 'mod.id', c('model','index'), sep = '_', remove = F ) 




# hlp=  index_search %>% 
#  # sample_n(2) %>% 
#   base::merge(all_sims
#      #   ,by.x = c("model", "index")
#     #    ,by.y = c("data_source", "model")
#     ,by ='mod.id'
#       #  ,all.x = T
#     )

 p.model.dat <- 
   all_sims %>% 
 inner_join(index_search,  
    by = c('condition','mod.id')
    ) %>% 
     dplyr::mutate('half' = name, .keep ='unused') %>%
     select(-c(model, data_source, model_index, index, mod.id)) %>% 
    mutate(half= str_remove_all(half, pattern = "_N."))
 # arrange(condition) %>% 
  

#  "model"     "index"     "subjects"  "name"      "condition" "iteration" "accuracy"  "type"     
subject.dat <- 
  sdat.repl.h1 %>% 
  mutate(half='half1', 
        subjects= h1.subjects) %>% 
  rbind(sdat.repl.h2 %>% 
          mutate(half='half2', 
                 subjects= h1.subjects))
  
colnames(subject.dat) = c(paste0('set3_learn.', c(1:12)),
                          paste0('set3_test.', c(1:12)),
                          paste0('set6_learn.', c(1:12)),
                          paste0('set6_test.', c(1:12)), 
                          'half',
                          'subjects'
                          )

  subject.dat %<>%   
  dplyr::mutate(
         'type' = 'behavioral', 
         'parameter' = NA, 
         'param_vals'= NA) %>% 
  pivot_longer(cols = -c(half,type, subjects, parameter, param_vals), names_to = 'temp_condition', values_to = 'accuracy') %>% 
  separate(temp_condition, into = c('condition','iteration'), sep = '[/.]') 
  
  
# last bit -  add model identity must join by half subject and condition
  mod.id.temp <- 
     all_sims %>% 
 inner_join(index_search,  
    by = c('condition','mod.id')
    ) %>% 
     dplyr::mutate('half' = name, .keep ='unused') %>%
     select(c(subjects, condition, model, half)) %>% ## can add model_index here if that information is needed
    mutate(half= str_remove_all(half, pattern = "_N."))
  
  melted.p.behav.model <- 
  rbind(subject.dat, p.model.dat) %>% 
  inner_join(mod.id.temp,
 by=c('subjects', 'half', 'condition')
 ) %>% 
    separate(col = condition, into = c('condition', 'phase'), remove = T )

```

```{r model + behavior plot, fig.height=12, fig.width=12}
melted.p.behav.model %>% 
  filter(phase!='test') %>% 
unite(col='cond.model', c( 'half','condition', 'type'),remove = F) %>% 
  dplyr::group_by(type, half, condition, model,  iteration, cond.model) %>%  #,
 dplyr::summarize (
                    n_subjects = numel(accuracy)/12,
                   acc=mean(accuracy),
                   se = sd(accuracy, na.rm = T)/sqrt((n_subjects)) # divide by the number of iterations to get the correct number of samples
 )%>%
  
  
  ggplot(aes(as.numeric(iteration),acc, group=cond.model,color=cond.model)) +
  geom_point(size=1.5) +
  geom_line(size=1) +
  geom_errorbar(aes(ymin=acc-se,ymax=acc+se),width=.25, size=.75, width=.25, size=.75)+  
  facet_wrap(vars( model), ncol = 2) +
 # scale_color_viridis_d()+

#virid
 scale_color_brewer(palette = "Paired") +
  theme_pubclean(base_size = 24) +
    xlab('stimulus iteration')

```

```{r}
melted.p.behav.model %>% 
  filter(type=='model', phase=='learn', iteration==1) %>% 
  select(subjects, half, model, condition) %>% 
  unique() %>% 
  dplyr::group_by(half, condition, model) %>% 
  dplyr::summarise(length(subjects))

```


## Dynamics

### Does the best fit model change from 1st half to second half and between the two set-sizes?

```{r set-size confusion,  fig.width=12, fig.height=6.2}
melted.p.behav.model %>% 
  filter(type=='model', phase=='learn', iteration==1, parameter=='alpha') %>% 
    unique() %>% 
  pivot_wider(id_cols = c(subjects,half), names_from = condition, values_from = model) %>% 
  mutate(toRL = set6 =="RL", 
         toLTM = set6 =="LTM" 
         #,toSTR = set6 =="STR", 
        # toMETA = set6=="META"
         ) %>% 
  dplyr::group_by(half, set3) %>% 
  dplyr::summarise(RL = mean(toRL), 
                   LTM = mean(toLTM) 
                  # ,STR = mean(toSTR), 
                  # META =mean(toMETA) 
                   ) %>% 
  pivot_longer(cols = -c(half, set3), names_to = 'set6', values_to = 'prop') %>% 
 
   ggplot(aes(x=set3, y=set6, fill=prop)) +
  geom_tile()  +
    geom_text(aes(label= round(prop,2) 
                                ),
              size=4,
                  show.legend = F) +
  scale_fill_gradient(limits=c(0,1),
                          low='white',
                           high = '#d7191c',
                           #'#377eb8',
                    #   midpoint = 0,
                          guide='colorbar',
                          aesthetics = 'fill',
                          breaks= c(0,.25,.5,.75,1) 
                       ) +
  facet_wrap(vars(half))+
theme_classic(base_size = 18) 

  
```

```{r half confusion,  fig.width=12, fig.height=6.2}
melted.p.behav.model %>% 
  filter(type=='model', phase=='learn', iteration==1, parameter=='alpha') %>% 
    unique() %>% 
  pivot_wider(id_cols = c(subjects,condition), names_from = half, values_from = model) %>% 
  mutate(toRL = half2 =="RL", 
         toLTM = half2 =="LTM", 
         toSTR = half2 =="STR", 
         toMETA = half2=="META") %>% 
  dplyr::group_by(condition, half1) %>% 
  dplyr::summarise(RL = mean(toRL), 
                   LTM = mean(toLTM) 
                  # ,STR = mean(toSTR), 
                 #  META =mean(toMETA) 
                   ) %>% 
  pivot_longer(cols = -c(condition, half1), names_to = 'half2', values_to = 'prop') %>% 
 
   ggplot(aes(x=half1, y=half2, fill=prop)) +
  geom_tile()  +
    geom_text(aes(label= paste0(round(prop,2)) 
                                ),
              size=4,
              
                  show.legend = F) +
  scale_fill_gradient(limits=c(0,1),
                          low='white',
                           high = '#d7191c',
                           #'#377eb8',
    
                          guide='colorbar',
                          aesthetics = 'fill',
                          breaks= c(0,.25,.5,.75,1) 
                       ) +
  facet_wrap(vars(condition))+
theme_classic(base_size = 18) 

  
```

## Are the parameter values largely different for each half and set-size? 

## Individual plots

```{r individual plots plotter, fig.width=12, fig.height= 125}

#plot.indiv <- function(this.subject, title, columns) {
 if (TRUE){
  melted.p.behav.model %>% 
  filter(phase!='test') %>% 
unite(col='cond.model', c( 'condition', 'type'),remove = F) %>% 
   #(subjects == 6200) %>% 
    ggplot(aes(as.numeric(iteration), accuracy, color=cond.model, group=cond.model)) + 
    geom_point() +
    geom_line(size=1) +
    facet_wrap(vars(subjects), scales = 'free')+
    scale_color_brewer(palette = "Paired")+
 # geom_text(aes(label= model),check_overlap = F, inherit.aes = T, nudge_x = .2, nudge_y = .02)+
    theme_pubr(base_size = 16) +
  facet_wrap(vars(subjects, half), ncol = 4) +
    ggtitle('title')
  
#}
}

```

 

















