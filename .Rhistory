aes( as.factor(iteration), accuracy, color=setSize, group=setSize))
# Chunk 14: stats for differneces in RLWM task for the 4 groups
#---- measures for RLWM:  T THESE SHOULD BE EDITED TO SHOW BOTH MODEL AND BEHAVIORAL DATA
#------Learning accuracy (12th iteration, done)
#  melted.p.behav.model %>%
#  filter(iteration==12) %>% #Grab only the 12th iteration
#  summarySE( measurevar = "accuracy", groupvars = c( "model","cond.model")) %>%
#   ggplot(aes(x=model,weight=accuracy,ymin=accuracy-se, ymax=accuracy+se, group=cond.model,  color=cond.model)) +
#  #geom_jitter(height = 0, width = 0.1) +
# #geom_bar(position =position_dodge(), aes(y=accuracy), stat = 'identity')+
#  geom_errorbar(position=position_dodge(width = 0.75), width=.55, size=2) +
#  geom_point(position =position_dodge(width = 0.75), aes(y=accuracy, color=cond.model), size=4) +
#   scale_color_brewer(palette = "Paired") +
#  ylim(c(0.25,1))+
# # xlab('stimulus iteration') +
# theme_pubr(base_size = 24)
#  # facet_wrap(vars(model))
#------Test accuracy
# melted.p.behav.model %>%
#    filter(iteration == c(13)) %>%
#   summarySE( measurevar = "accuracy", groupvars = c("iteration", "condition", "cond.model", "model")) %>%# View()
#   ggplot(aes(x=model,weight=accuracy,ymin=accuracy-se, ymax=accuracy+se, group=cond.model,  color=cond.model)) +
#   #geom_jitter(height = 0, width = 0.1) +
#  #geom_bar(position =position_dodge(), aes(y=accuracy), stat = 'identity')+
#   geom_errorbar(position=position_dodge(width = 0.75), width=.55, size=2) +
#   geom_point(position =position_dodge(width = 0.75), aes(y=accuracy, color=cond.model), size=4) +
#    scale_color_brewer(palette = "Paired") +
#   ylim(c(0.25,1))+
#  # xlab('stimulus iteration') +
#  theme_pubr(base_size = 24, legend = 'none')
#   # facet_wrap(vars(model))
# Chunk 15: Learning and test combined plot
#------Learning and test combined
melted.p.behav.model %>%
filter(iteration>=12) %>% #Grab both the 12th iteration and test
summarySE( measurevar = "accuracy", groupvars = c( "model","cond.model", "iteration")) %>%
ggplot(aes(x=as.factor(iteration),weight=accuracy,ymin=accuracy-se, ymax=accuracy+se, group=cond.model,  color=cond.model)) +
geom_errorbar(position=position_dodge(width = 0.1), width=.25, size=1.5) +
geom_point(position =position_dodge(width = 0.1), aes(y=accuracy, color=cond.model), size=2) +
geom_line(position =position_dodge(width = 0.1), aes(y=accuracy, color=cond.model), size=1) +
scale_color_brewer(palette = "Paired") +
ylim(c(0.25,1))+
xlab('condition') +
theme_pubclean(base_size = 24)  +
scale_x_discrete(labels=c("learn","test"))+
facet_wrap(vars(model))
#stats
melted.p.behav.model %>%
filter(type=='behav', iteration==12 | iteration==13) %>%
select(setSize, accuracy, iteration) %>%
ggplot(aes(accuracy, fill=factor(iteration))) +
geom_density(alpha=.4) +
facet_wrap(vars(setSize))
melted.p.behav.model %>%
filter(type=='behav', iteration==12 | iteration==13) %>%
select(setSize, accuracy, iteration) %>%
lm(accuracy ~ setSize * iteration, data=.) %>%
anova() %>%
broom::tidy() %>% kable()
dat4.t.test <- melted.p.behav.model %>%
filter(type=='behav', iteration==12) %>%
select(subjects,setSize, accuracy) %>%
dcast(subjects ~ setSize,value.var = 'accuracy' )
t.test(dat4.t.test$s3,dat4.t.test$s6)
wilcox.test(dat4.t.test$s3,dat4.t.test$s6)
# Chunk 16: Learning rate 1
#------Learning rate(number of trials to 90%)
matcher <- function(ths){ #wrap up match function to make it easier to use with apply function
return(
match(TRUE, ths)
)
}
acc.level = .84
learning.Rate <-
cbind(subjects,
"model"= p.behav.model$model,
's3_behav'= apply(sdat[,1:12]>acc.level, 1, matcher) %>%
as.numeric(),
's6_behav'= apply(sdat[,13:24]>acc.level, 1, matcher) %>%
as.numeric(),
's3_model'= apply(join.model.dat[,3:14]>acc.level, 1, matcher) %>%
as.numeric(),
's6_model'= apply(join.model.dat[,15:26]>acc.level, 1, matcher) %>%
as.numeric()
) %>% as.data.frame()
learning.Rate %>%
reshape2::melt(id.vars = c("subjects","model"), value.name="learning.rate") %>%
separate("variable", into = c('setSize','type'), remove = FALSE, convert = TRUE) %>%
dplyr::group_by(setSize, model, type) %>%
dplyr::summarise('mean'=mean(learning.rate,na.rm=T),
'SD'= sd(learning.rate, na.rm = T),
'se'= sd(learning.rate, na.rm = T) / sqrt(sum(!is.na(learning.rate))),
'n'= sum(!is.na(learning.rate))
) %>%
ggplot(aes(mean,x=setSize, group=type, color=type)) +
#geom_histogram(stat = 'count') +
geom_point(size=2)+
geom_errorbar(aes(ymax=mean+se,ymin=mean-se), width=.25, size=1.5)+
scale_color_brewer(palette = "Paired") +
theme_pubclean(base_size = 24)+
facet_wrap(vars(model))+
ggtitle('rate: n trials to 85%')
# Chunk 17: alternative learning rate
#----- Alternative learning rate
fit.lr <-  melted.p.behav.model %>%
filter(iteration<7 & iteration!=13) %>% # get the first 6 learning trials to model
dplyr::group_by(subjects,setSize, type,model) %>%
do( broom::tidy(lm(accuracy~iteration, data=.))[2] %>%
as_data_frame()) %>%
cbind('estimate.type'= rep(c('y-int','slope'), 83*2*2))
fit.lr %>%
filter(estimate.type=='slope') %>%
group_by(setSize,type, model) %>%
dplyr::summarize('mean'= mean(estimate),
'se' = sd(estimate, na.rm = T) / sqrt(sum(!is.na(estimate)))) %>%
ggplot(aes(mean,x=setSize, group=type, color=type)) +
#geom_histogram(stat = 'count') +
geom_point(size=2)+
geom_errorbar(aes(ymax=mean+se,ymin=mean-se), width=.25, size=1.5)+
scale_color_brewer(palette = "Paired") +
theme_pubclean(base_size = 24)+
facet_wrap(vars(model)) +
ylab("slope") +
ggtitle("learning rate: slope estimate of first 6 iterations")
#Some stats for report
fit.lr %>%
dplyr::filter(type=='behav', estimate.type=='slope') %>%
select(setSize, estimate) %>%
group_by(setSize) %>% summarize(mean(estimate), median(estimate)) %>% kable()
fit.lr %>%
dplyr::filter(type=='behav', estimate.type=='slope') %>%
select(setSize, estimate) %>%
ggplot(aes(estimate, fill=setSize)) + geom_density(alpha=.4)
temp4t.test= fit.lr %>%
ungroup() %>%
dplyr::filter(type=='behav', estimate.type=='slope') %>%
select(subjects,setSize, estimate) %>%
dcast(subjects ~ setSize, value.var = 'estimate') %>%
select(-subjects)
t.test(temp4t.test$s3,temp4t.test$s6, method='student') %>%
broom::tidy() %>%
kable()
fit.lr %>%
filter(estimate.type=='slope') %>%
group_by(setSize,type, model) %>%
dplyr::summarize('mean'= mean(estimate),
'se' = sd(estimate, na.rm = T) / sqrt(sum(!is.na(estimate))))
# mean differences
fit.lr %>%
ungroup() %>%
filter(estimate.type=='slope') %>%
dcast(subjects + model + type ~ setSize ,value.var = 'estimate') %>%
group_by(model, type) %>%
dplyr::summarize('meanS3'= mean(s3),
'meanS6'= mean(s6),
'mean_diff'= mean(s3) - mean(s6)
) %>% kable()
# Chunk 18: Analysis of separation between the curves
#------Separation between the curves (done)
s3s6Diff <-
melted.p.behav.model %>%
filter(iteration!=13) %>% # get everything but test , type=='behav'
select(c('subjects','model', 'accuracy','iteration', 'setSize', 'type')) %>%
reshape2::dcast(setSize ~ iteration + subjects + model + type , value.var = 'accuracy') %>% #change in to wide form to subrtract b/n s3 and s6
select(-setSize) %>% #not needed
as.matrix() %>% #required to use diff() function
diff.default() %>%  #take the difference b/n the set sizes
#  abs() %>% #take the absolute value (I guess it doesn't matter if s3 is higher than s6 or viceversa)
reshape2::melt() %>%
select(-Var1) %>%
separate("Var2", into = c('iteration', "subjects","model","type"), remove = T, convert = TRUE) %>%
summarySE(measurevar = "value", groupvars = c("subjects", "model", "type")) %>%
select(subjects,type, model,"learnDiff"= value)
s3s6Diff %>%
summarySE(measurevar = 'learnDiff', groupvars = c('model','type')) %>%
ggplot(aes(model, learnDiff, group=type, color=type)) +
geom_point(size=2) +
geom_errorbar(aes(ymax=learnDiff+se, ymin=learnDiff-se), size=1.5,width=.25) +
theme_pubclean(base_size = 24) +
ggtitle("separation of the learning curves")+
scale_color_brewer(palette = "Paired") +
ylab('mean difference')
# ylim(c(0,.3))
#--stats
s3s6Diff %>%
filter(type=='behav') %>%
ggplot(aes(learnDiff, fill=model)) +
geom_density(alpha=.4) +
facet_wrap(vars(model))
# These don't look like normal distros
s3s6Diff %>%
filter(type=='behav') %>%
lm(learnDiff ~ model, data=. ) %>%
anova()
#---perhaps a K-W rank sum test is prefered
temp.datKW <- s3s6Diff %>%
filter(type=='behav', model!='RL') %>%
select(learnDiff,model)
kruskal.test(temp.datKW$learnDiff,temp.datKW$model) %>%
broom::tidy() %>%
kable()
pairwise.t.test(temp.datKW$learnDiff,temp.datKW$model,p.adjust.method = 'bonferroni') %>%
broom::tidy() %>%
kable()
# Chunk 19: Change from learning to test
#---------Change from learning to test
learnTestDiff <-
melted.p.behav.model %>%
filter( iteration>= 12) %>%
select(c('subjects','model', 'accuracy','iteration', 'setSize','type')) %>%
reshape2::dcast(iteration ~ setSize + subjects + model + type, value.var = 'accuracy') %>%
select(-iteration) %>% #not needed
as.matrix() %>% #required to use diff() function
diff.default() %>%
# abs() %>%#take the difference b/n the learn and test
reshape2::melt() %>%
select(-Var1) %>%
separate("Var2", into = c('setSize', "subjects","model","type"), remove = T, convert = TRUE)
learnTestDiff  %>%
unite("cond.model", c(setSize,type), remove = FALSE) %>%
summarySE(measurevar = "value", groupvars = c( "model", "cond.model")) %>%
ggplot(aes(model, value, color=cond.model, group=cond.model)) +
geom_point(position=position_dodge(width = 0.4),size=2) +
geom_errorbar(position=position_dodge(width = 0.4),aes(ymax=value+se, ymin=value-se), size=1,width=.75) +
theme_pubclean(base_size = 24) +
ggtitle("Change from training to test: test - learn")+
scale_color_brewer(palette = "Paired") +
theme(legend.position = 'none')+
ylab("mean difference")
#  ylim(c(-0.6,0))
# Chunk 20: summarize extracted parameters
param.spread <-
p.behav.model %>%
select('alpha','egs','bll','imag','ans','bias') %>%
reshape2::melt(value.name = 'unscaled.vals')  %>%
data.frame('scaled.vals' =p.behav.model %>% select('alpha','egs','bll','imag','ans','bias') %>% scale() %>% reshape2::melt()  %>% select(value) ) %>%
dplyr::group_by(unscaled.vals, variable, value) %>%
tally()
param.spread %>%
filter(!is.na(unscaled.vals)) %>%
ggplot(aes(x=value, variable,size=n, color=variable)) +
geom_point(alpha=.35)+
#  facet_wrap(vars(model)) +
#geom_text(aes(label=round(unscaled.vals,2), size=2,color='blue'), check_overlap = T)+
theme_classic2(base_size = 24)+
theme(legend.position = 'top')+
scale_size(range = c(1, 30), name='count', breaks = c(5,10,15,20)) +
# theme(legend.position='top') +
ylab('parameter')+
xlab('scaled value')
# param.spread %>%
#   dplyr::group_by(model,variable) %>%
#   dplyr::summarise(mean=mean(unscaled.vals, na.rm = T),
#                    median=median(unscaled.vals, na.rm=T))
#
# Chunk 21: effects of individual parameters on outcomes
temp4join1 <-
fit.lr %>%
dplyr::filter(estimate.type=='slope') %>%
reshape2::dcast(subjects  + model ~ setSize + estimate.type + type, value.var = 'estimate')
temp4join2 <-
learnTestDiff %>%
select(-model) %>%
data.frame('param'='TestForgetting') %>%
reshape2::dcast(subjects  ~ setSize +param +type, value.var = 'value')
temp4join3 <-
s3s6Diff %>%
select(-model) %>%
data.frame('param'='s3s6_learnDiff') %>%
reshape2::dcast(subjects ~ param + type, value.var = 'learnDiff')
main4join <-
p.behav.model %>%
select(s3.12.behav, s3.12.model, s6.12.behav, s6.12.model,s3.13.behav,
s3.13.model, s6.13.behav, s6.13.model) %>%
scale() %>%
data.frame( p.behav.model %>%
select('alpha','egs','bll','imag','ans','bias') %>%
scale(),
'subjects'= p.behav.model$subjects
)
p.param.outcomes <-
merge(main4join,
temp4join1, by = c("subjects"), sort=FALSE) %>%
merge(temp4join2, by = c("subjects"), sort = FALSE ) %>%
merge(temp4join3, by = c("subjects"), sort = FALSE )
# p.param.outcomes %>%
#   select(-model,-subjects,-ends_with('model')) %>%
#   GGally::ggpairs() +
#   theme_pubclean() + theme(axis.text.y = element_text( angle=45))
molt.param.out <- p.param.outcomes %>%
reshape2::melt(id.vars=c('model','subjects','alpha','egs','bll','imag','ans','bias'),
variable.name='measures', value.name="measure_vals")  %>%
reshape2::melt(id.vars=c('model','subjects', 'measures','measure_vals'),
variable.name='params',value.name='param_vals') %>%
separate("measures", into = c('setSize', "condition","type"), remove = FALSE, convert = TRUE)
#
# molt.param.out %>%
#   filter(condition=='13', model=='LTM') %>%
#   ggplot(aes(x=param_vals,y=measure_vals, color=params, group=params)) +
#   geom_point(alpha=.4)+
#   geom_smooth(method = 'lm', se=F) +
#   theme_pubclean()+
#   facet_wrap(vars(measures))
#   scale_fill_brewer('Paired')
all_dat_cors <-
molt.param.out %>%
filter( type=='behav') %>%
dplyr::group_by(condition, setSize, params) %>%
dplyr::summarise(cor.pearson=cor(param_vals,measure_vals, use="complete.obs"),
cor.spearman=cor(param_vals,measure_vals, use="complete.obs", method = 'spearman')
)
all_dat_cors %>%
ggplot(aes(params, condition, fill=cor.spearman)) +
geom_tile() +
facet_wrap(vars(setSize))+
theme_pubclean(base_size = 18) +
scale_fill_gradient2(limits=c(-0.7,0.7),
low='#2b83ba',
high = '#d7191c',
mid = 'white',
midpoint = 0,
guide='colorbar',
aesthetics = 'fill',
breaks= c(-.5,-.25,0,.25,.5)
) +
# scale_fill_distiller(palette = 'Spectral', guide='colorbar') +
theme(legend.position = 'right')
all_dat_cors %>%
ggplot(aes(params, condition, fill=cor.pearson)) +
geom_tile() +
geom_text(aes(label=round(cor.pearson,2), size=.5), show.legend = F)+
facet_wrap(vars(setSize))+
theme_pubclean(base_size = 18) +
scale_fill_gradient2(limits=c(-0.7,0.7),
low='#2b83ba',
high = '#d7191c',
mid = 'white',
midpoint = 0,
guide='colorbar',
aesthetics = 'fill',
breaks= c(-.5,-.25,0,.25,.5)
) +
# scale_fill_distiller(palette = 'Spectral', guide='colorbar') +
theme(legend.position = 'right') +
xlab('parameters')
# molt.param.out %>%
#   filter(type=='model', condition=='13', setSize=='s3', params=='bias') %>%
#   select(param_vals, measure_vals) %>%
#   #dplyr::group_by(param_vals) %>%
#   #dplyr::summarise(median(measure_vals)) %>%
#   #plot()
#   cor(use="complete.obs",method = 'spearman')
# Chunk 22: correlations by model
all.cors.byModel <-
molt.param.out %>%
filter(model!='RL', type=='behav') %>%
group_by(model, condition, params, setSize) %>%
dplyr::summarise(cor.pearson=cor(param_vals,measure_vals),
cor.spearman=cor(param_vals,measure_vals, method = 'spearman')
)
# Correlation matrix
all.cors.byModel %>%
filter(is.na(cor.pearson)==F) %>%
ggplot(aes(params, condition, fill=cor.spearman)) +
geom_tile() +
facet_wrap(vars(setSize, model))+
theme_pubclean(base_size = 18) +
geom_text(aes(label=round(cor.spearman,2), size=.5), show.legend = F)+
scale_fill_gradient2(limits=c(-1,1),
low='#2b83ba',
high = '#d7191c',
mid = 'white',
midpoint = 0,
guide='colorbar',
aesthetics = 'fill',
breaks= c(-1,-.5,-.25,0,.25,.5,1)
) +
theme(legend.position = 'right') +
xlab('parameters')
molt.param.out %>%
filter( setSize=='s3', condition==12) %>%
ggplot(aes(param_vals, measure_vals, group=condition, color=condition)) +
geom_point() +
geom_smooth(method = 'lm')+
facet_wrap(vars(model, params))
# Chunk 23
linear_param <-
p.behav.model %>%
select('alpha','egs','bll','imag','ans','bias') %>%
scale(center = F) %>%
data.frame(subjects=p.behav.model$subjects)%>%
dplyr::group_by(subjects,alpha,egs,imag,bll,ans) %>%
dplyr::summarise(newParam= sum( c(alpha,imag,ans,egs,bll), na.rm = T)) %>%
data.frame(learn=p.behav.model$s3.12.behav)
#newParam=alpha+imag-egs-bll-ans
# Chunk 24: parameters:biased model
melted.p.behav.model %>%
filter(model=='biased') %>%
filter(iteration==12)%>%
filter(type== 'behav') %>%
summarySE(groupvars =c( "bias","type", "setSize") , measurevar = "accuracy") %>%
ggplot(aes(as.factor(bias), accuracy, group=setSize,color=setSize)) +
geom_point()+geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se)) +
ylim(0.3,1)
melted.p.behav.model %>%
filter(model=='biased') %>%
filter(iteration==13)%>%
filter(type== 'behav') %>%
summarySE(groupvars =c("bias","type", "setSize") , measurevar = "accuracy") %>%
ggplot(aes(as.factor(bias), accuracy, group=setSize,color=setSize)) +
geom_point() +
geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se))
melted.p.behav.model %>%
filter(model=='biased' | model=='metaRL', iteration==12, type== 'behav') %>%
select(subjects, model,bias, alpha, egs)%>%
merge(s3s6Diff %>%
filter(model=='biased' | model=='metaRL') %>%
select(subjects,learnDiff), by='subjects') %>%
lm(learnDiff ~  egs + alpha, data=.)%>%
#plot(which=4)
summary()
ggplot(aes(bias,learnDiff)) +
geom_point(alpha=.4, size=2) +
geom_smooth()
molt.param.out %>% head
p.param.outcomes %>% head()
p.param.outcomes %>%
filter(model==LTM) %>% head
p.param.outcomes %>%
filter(model=='LTM') %>% head
p.param.outcomes %>% names
p.param.outcomes %>%
filter(model=='LTM') %>%
lm(s3.12.behav ~ bll*ans*egs,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm(s3.12.behav ~ bll*ans*imag,data=.) %>%
summary()
library(broom)
p.param.outcomes %>%
filter(model=='LTM') %>%
lm(s3.12.behav ~ bll*ans*imag,data=.) %>%
tidy()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm(s3.12.behav + s3.13.behav ~ bll*ans*imag,data=.) %>%
tidy()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm(s3.12.behav + s3.13.behav ~ bll*ans*imag,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm( s3.13.behav ~ bll+ ans+imag,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM') %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
plot()
p.param.outcomes %>%
filter(model=='LTM') %>%
p.param.outcomes %>%
filter(model=='LTM')
p.param.outcomes %>%
filter(model=='LTM', subjects!=6207) %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
plot()
p.param.outcomes %>%
filter(model=='LTM') %>% select(subjects)
p.param.outcomes %>%
filter(model=='LTM', subjects!=c(15012,6207,28307)) %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
plot()
filter(model=='LTM', subjects!=15012 | subjects!=6207 | subjects!=28307)
p.param.outcomes
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 | subjects!=6207 | subjects!=28307) %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
plot()
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 | subjects!=6207 | subjects!=28307) %>% select(subjects)
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 & subjects!=6207 & subjects!=28307) %>% select(subjects)
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 & subjects!=6207 & subjects!=28307) %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
plot()
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 & subjects!=6207 & subjects!=28307) %>%
lm( s3.13.behav ~ bll*ans*imag,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 & subjects!=6207 & subjects!=28307) %>%
lm( s3.13.behav ~ bll,data=.) %>%
summary()
p.param.outcomes %>%
filter(model=='LTM', subjects!=15012 & subjects!=6207 & subjects!=28307) %>%
lm( s3.13.behav ~ bll+ ans +imag,data=.) %>%
summary()
p.param.outcomes$ans
p.param.outcomes$alpha
temp4join1
temp4join1 <-
fit.lr %>%
dplyr::filter(estimate.type=='slope') %>%
reshape2::dcast(subjects  + model ~ setSize + estimate.type + type, value.var = 'estimate') %>%
scale()
