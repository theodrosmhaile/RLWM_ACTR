ggplot(aes(level, accuracy, color=variable)) +
geom_point()+
geom_line() +
facet_grid('parameter')+
theme_bw(base_size = 16, base_line_size = 1)+
scale_color_manual(values = tmp.color)+
ylim(c(.3,1)) +
theme(legend.position='top', legend.direction = 'vertical')
}
ggarrange(model_desc_plot(RL.params),model_desc_plot(RLLTMpipe.params),model_desc_plot(RLLTMstr.params),model_desc_plot(LTM.params),  ncol=4, common.legend = TRUE)
#------Descriptive measures: learning rate (beta), accuracy learn & Test, differences between learn3 and learn 6
#--------select data for each level of parameters per model
RL.params        <- param.influence(RL.sim.dat, 'RL')
RLLTMpipe.params <- param.influence(RL_LTMpipe.sim.dat, 'RLLTM')
RLLTMstr.params  <- param.influence(RL_LTMstr.sim.dat, 'RLLTM')
LTM.params       <- param.influence(LTM.sim.dat, 'LTM')
ggarrange(model_desc_plot(RL.params),model_desc_plot(RLLTMpipe.params),model_desc_plot(RLLTMstr.params),model_desc_plot(LTM.params),  ncol=4, common.legend = TRUE)
tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
model_desc_plot <- function(model) {
tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
model %>%
melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>%
ggplot(aes(level, accuracy, color=variable)) +
geom_point()+
geom_line() +
facet_grid('parameter')+
theme_bw(base_size = 16, base_line_size = 1)+
scale_color_manual(values = tmp.color)+
ylim(c(.3,1)) +
theme(legend.position='top', legend.direction = 'vertical')
}
model_desc_plot <- function(model) {
tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
model %>%
melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>%
ggplot(aes(level, accuracy, color=variable)) +
geom_point()+
geom_line() +
facet_grid('parameter')+
theme_bw(base_size = 16, base_line_size = 1)+
scale_color_manual(values = tmp.color)+
ylim(c(.3,1)) +
theme(legend.position='top', legend.direction = 'vertical')
}
ggarrange(model_desc_plot(RL.params),
model_desc_plot(RLLTMpipe.params),
model_desc_plot(RLLTMstr.params),
model_desc_plot(LTM.params),  ncol=4, common.legend = TRUE)
Andys_BIC <- function(rmse, k) {
# RSS first
n = 48 #lean3 + learn 6 + (test3)*12 + (test6)*12
RSS <- ((rmse)^2) * n
# BIC next
bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
return(bic)
}
mseRL.temp         =c()
mseLTM.temp        =c()
mseRL_LTMorig.temp =c()
mseRL_LTMpipe.temp =c()
mseRL_LTMstr.temp  =c()
# model 1
mseRL.temp     <- rbind(mseRL.temp, apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
mseRL.temp
for(s in c(1:nrow(sdat.mod))) { # for each subject
# model 1
mseRL.temp     <- rbind(mseRL.temp, apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
# model 2
mseLTM.temp    <- rbind(mseLTM.temp, apply(LTM.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ] )) %>%  sqrt()
)
# model 3
# mseRL_LTMorig.temp <- rbind(mseRL_LTMorig.temp,
# apply(RL_LTMorig.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
# )
# model 3.1
mseRL_LTMpipe.temp <- rbind(mseRL_LTMpipe.temp,
apply(RL_LTMpipe.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
# model 3.2
mseRL_LTMstr.temp  <- rbind(mseRL_LTMstr.temp,
apply(RL_LTMstr.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
}
simsRL_LTMorig$data$strtg
simsRL_LTMorig$data$strtg %>% histogram()
simsRL_LTMpipe$data$strtg %>% histogram()
simsRL_LTMorig$data$strtg %>% hist()
simsRL_LTMpipe$data$strtg %>% hist()
simsRL_LTMpipe$data$strtg %>% mean()
simsRL_LTMorig$data$strtg %>% mean()
apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
c(1:24,25,37)
(RL.sim.dat[,  c(1:24,25,37)]
)
apply(RL.sim.dat[, (RL.sim.dat[,  c(1:24,25,37)]], 1, function(x,y) MSE(x, sdat.mod[s,,  c(1:24,25,37)] )) %>% sqrt()
apply(RL.sim.dat[, (RL.sim.dat[,  c(1:24,25,37)], 1, function(x,y) MSE(x, sdat.mod[s,,  c(1:24,25,37)] )) %>% sqrt()
apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
apply(RL.sim.dat[, (RL.sim.dat[, c(1:24,25,37)], 1, function(x,y) MSE(x, sdat.mod[s,c(1:24,25,37)] )) %>% sqrt()
apply(RL.sim.dat[, c(1:24,25,37)], 1, function(x,y) MSE(x, sdat.mod[s, c(1:24,25,37)] )) %>% sqrt()
# Chunk 1: set up
#rm(list = ls())
library(matlab)
library(reshape2)
library(ggplot2)
library(dplyr)
library(tidyr)
library(MLmetrics)
library(readr)
library(data.table)
library(jsonlite)
library(data.table)
library(knitr)
library(gridExtra)
source('param_influence.R')
library(Rmisc)
library(ggpubr)
# Chunk 2: import data
#----- import subject data
#
sdat = fread('./RLWM_data/all_subject_n83_learn_test_data.csv', header = T) %>% t()
# sdat contains data fro 83 participants (columns),
# rows 1:12 learn accuracy set 3 ;
# rows 13:24 learn accuracy set 6 ;
# row 25 test set 3 accuracy ;
# row 26 test set 6 accuracy ;
#------ Modify subject data to 'weight' accuracy in test for 3 and 6 by repeating each 12x
sdat.temp <- rep(sdat[ , 25:26], 12) %>%
as.matrix() %>%
reshape(., 996,2) %>%
reshape(., 166,12)
sdat.mod  <- cbind(sdat[, 1:24],
sdat.temp[1:83,],
sdat.temp[84:166, ])
#----- import model data (has to be converted from JSON to data frames)
#--------- Integrated model original
simsRL_LTMorig <- fromJSON('./outdated_sim_data/RLLTMorig_sim_data050520.JSON')
simsRL_LTMorig.set3learn <- simsRL_LTMorig$data$set3_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMorig$data)) %>%
t()
simsRL_LTMorig.set6learn <- simsRL_LTMorig$data$set6_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMorig$data)) %>%
t()
simsRL_LTMorig.s3s6test.temp <-
simsRL_LTMorig$data$set3_test %>%
cbind(., simsRL_LTMorig$data$set6_test) %>%
rep(., 12) %>%
as.matrix() %>%
reshape(., nrow(simsRL_LTMorig$data)*12, 2) %>%
reshape(., nrow(simsRL_LTMorig$data)*2, 12)
RL_LTMorig.sim.dat <- cbind(simsRL_LTMorig.set3learn,
simsRL_LTMorig.set6learn,
simsRL_LTMorig.s3s6test.temp[1:nrow(simsRL_LTMorig$data), ],
simsRL_LTMorig.s3s6test.temp[244:486, ],
simsRL_LTMorig$data[,c('bll','alpha','egs','imag','ans')])
#--------- Integrated model RL to LTM pipe
simsRL_LTMpipe <- fromJSON('./RLLTM_pipe_visual_activation_050720.JSON')
simsRL_LTMpipe.set3learn <- simsRL_LTMpipe$data$set3_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMpipe$data)) %>%
t()
simsRL_LTMpipe.set6learn <- simsRL_LTMpipe$data$set6_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMpipe$data)) %>%
t()
simsRL_LTMpipe.s3s6test.temp <-
simsRL_LTMpipe$data$set3_test %>%
cbind(., simsRL_LTMpipe$data$set6_test) %>%
rep(., 12) %>%
as.matrix() %>%
reshape(., nrow(simsRL_LTMpipe$data) * 12, 2) %>%
reshape(., nrow(simsRL_LTMpipe$data) *2, 12)
RL_LTMpipe.sim.dat <- cbind(simsRL_LTMpipe.set3learn,
simsRL_LTMpipe.set6learn,
simsRL_LTMpipe.s3s6test.temp[1:nrow(simsRL_LTMpipe$data), ],
simsRL_LTMpipe.s3s6test.temp[244 : 486, ],
simsRL_LTMpipe$data[,c('bll','alpha','egs','imag','ans')]) %>%
data.table()
#--------- Integrated model assigned strategy
simsRL_LTMstr <- fromJSON('./RLLTM_str_visual_activation_050720.JSON')
simsRL_LTMstr.set3learn <- simsRL_LTMstr$data$set3_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMstr$data)) %>%
t()
simsRL_LTMstr.set6learn <- simsRL_LTMstr$data$set6_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL_LTMstr$data)) %>%
t()
simsRL_LTMstr.s3s6test.temp <-
simsRL_LTMstr$data$set3_test %>%
cbind(., simsRL_LTMstr$data$set6_test) %>%
rep(., 12) %>%
as.matrix() %>%
reshape(., nrow(simsRL_LTMstr$data) * 12, 2) %>%
reshape(., nrow(simsRL_LTMstr$data) *2, 12)
RL_LTMstr.sim.dat <- cbind(simsRL_LTMstr.set3learn,
simsRL_LTMstr.set6learn,
simsRL_LTMstr.s3s6test.temp[1:nrow(simsRL_LTMstr$data), ],
simsRL_LTMstr.s3s6test.temp[973 : 1944, ],
simsRL_LTMstr$data[,c('bll','alpha','egs','imag','ans')]) %>%
data.table()
#--------- Reinforcement Learning Model
simsRL <- fromJSON('./outdated_sim_data/RL_sim_data_3lvsparams_050420.JSON')
simsRL.set3learn <- simsRL$data$set3_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL$data)) %>%
t()
simsRL.set6learn <- simsRL$data$set6_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsRL$data)) %>%
t()
simsRL.s3s6test.temp <-
simsRL$data$set3_test %>%
cbind(., simsRL$data$set6_test) %>%
rep(., 12) %>%
as.matrix() %>%
reshape(., nrow(simsRL$data)*12, 2) %>%
reshape(., nrow(simsRL$data)*2, 12)
RL.sim.dat <- cbind(simsRL.set3learn,
simsRL.set6learn,
simsRL.s3s6test.temp[1:nrow(simsRL$data), ],
simsRL.s3s6test.temp[10:18, ] ,
simsRL$data[,c('bll','alpha','egs','imag','ans')]) %>%
data.table()
#--------- Longterm Memory/WM/Declarative model
simsLTM    <- fromJSON('LTM_visual_activation_allparams_evals26.JSON')#('LTM_sim_data_3lvparams_050420.JSON')
simsLTM.set3learn <- simsLTM$data$set3_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsLTM$data)) %>%
t()
simsLTM.set6learn <- simsLTM$data$set6_learn %>%
unlist() %>%
as.matrix() %>%
reshape(., 12, nrow(simsLTM$data)) %>%
t()
simsLTM.s3s6test.temp <-  simsLTM$data$set3_test %>%
cbind(., simsLTM$data$set6_test) %>%
rep(., 12) %>%
as.matrix() %>%
reshape(., 324, 2) %>%
reshape(., 54, 12) #54= nrow(sims.LTM) * 2
LTM.sim.dat <- cbind(simsLTM.set3learn,
simsLTM.set6learn,
simsLTM.s3s6test.temp[1:27, ],
simsLTM.s3s6test.temp[28:54, ],
simsLTM$data[,c('bll','alpha','egs','imag','ans')]) %>%
data.table()
# LTM.sim.dat <- cbind('set3_learn'=simsLTM.set3learn %>% c(),
#                    'set6_learn'=simsLTM.set6learn %>% c(),
#                   'time'=rep(1:12,324/12),
#                  'set3_test'=simsLTM.s3s6test.temp[1:27, ] %>% c(),
#                 'set6_test'=simsLTM.s3s6test.temp[28:54, ] %>% c(),
#                simsLTM$data[,c('bll','alpha','egs','imag','ans')]) %>%
#data.table()
# Chunk 3: model description analysis and plots
#------Descriptive measures: learning rate (beta), accuracy learn & Test, differences between learn3 and learn 6
#--------select data for each level of parameters per model
RL.params        <- param.influence(RL.sim.dat, 'RL')
RLLTMpipe.params <- param.influence(RL_LTMpipe.sim.dat, 'RLLTM')
RLLTMstr.params  <- param.influence(RL_LTMstr.sim.dat, 'RLLTM')
LTM.params       <- param.influence(LTM.sim.dat, 'LTM')
model_desc_plot <- function(model) {
tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
model %>%
melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>%
ggplot(aes(level, accuracy, color=variable)) +
geom_point()+
geom_line() +
facet_grid('parameter')+
theme_bw(base_size = 16, base_line_size = 1)+
scale_color_manual(values = tmp.color)+
ylim(c(.3,1)) +
theme(legend.position='top', legend.direction = 'vertical')
}
ggarrange(model_desc_plot(RL.params),
model_desc_plot(RLLTMpipe.params),
model_desc_plot(RLLTMstr.params),
model_desc_plot(LTM.params),  ncol=4, common.legend = TRUE)
# Chunk 4: fit model data to subject data
#(1) Transform RMSE into residual sum of squares by doing RSS = RMSE^2 * n
#11:34
#(2) Calculate BIC as: BIC = n + n log (2*pi) + n log (RSS/n) + log(n) * (k + 1)
#11:36
#In RL, k = 2; in LTM, k = 3; and Integrated, k = 5 or k = 6
Andys_BIC <- function(rmse, k) {
# RSS first
n = 48 #learn3 + learn 6 + (test3)*12 + (test6)*12
RSS <- ((rmse)^2) * n
# BIC next
bic <- n + (n * log(2*pi)) + (n * log(RSS/n)) + (log(n) * (k + 1))
return(bic)
}
#----- loop through subject data and check for fit against model data using mean squared error.
mseRL.temp         =c()
mseLTM.temp        =c()
mseRL_LTMorig.temp =c()
mseRL_LTMpipe.temp =c()
mseRL_LTMstr.temp  =c()
for(s in c(1:nrow(sdat.mod))) { # for each subject
# model 1
mseRL.temp     <- rbind(mseRL.temp, apply(RL.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
# model 2
mseLTM.temp    <- rbind(mseLTM.temp, apply(LTM.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ] )) %>%  sqrt()
)
# model 3
# mseRL_LTMorig.temp <- rbind(mseRL_LTMorig.temp,
# apply(RL_LTMorig.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
# )
# model 3.1
mseRL_LTMpipe.temp <- rbind(mseRL_LTMpipe.temp,
apply(RL_LTMpipe.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
# model 3.2
mseRL_LTMstr.temp  <- rbind(mseRL_LTMstr.temp,
apply(RL_LTMstr.sim.dat[, 1:48], 1, function(x,y) MSE(x, sdat.mod[s, ])) %>% sqrt()
)
}
#------ Exrtact row indices to get parameter set of parameters for best fit model
#------------first find the smallest BIC
RL.bic = Andys_BIC(mseRL.temp, 2)
LTM.bic = Andys_BIC(mseLTM.temp, 3)
RL_LTMpipe.bic = Andys_BIC(mseRL_LTMpipe.temp, 5)
RL_LTMstr.bic = Andys_BIC(mseRL_LTMstr.temp, 6)
RL.fit     = as.matrix(apply(RL.bic , 1, min))
LTM.fit    = as.matrix(apply(LTM.bic , 1, min))
# RL_LTMorig.fit = as.matrix(apply(   (mseRL_LTMorig.temp), 1, min))
RL_LTMpipe.fit = as.matrix(apply(RL_LTMpipe.bic, 1, min))
RL_LTMstr.fit = as.matrix(apply(RL_LTMstr.bic , 1, min))
#temp <- mdat.3 %>%
#  data.table() %>%
#  .[,`:=`(V66 = V3 - mean(V3))]
#-------------second, find actual row number using smallest value
ind.temp.RL <- c()
ind.temp.RL_LTMorig <- c()
ind.temp.RL_LTMstr <- c()
ind.temp.RL_LTMpipe <- c()
ind.temp.LTM <- c()
for ( i in 1:length(RL.fit)) {
ind.temp.RL <- rbind(ind.temp.RL, which(RL.bic[i,] %in% RL.fit[i]))
}
for ( i in 1:length(LTM.fit)) {
ind.temp.LTM <- rbind(ind.temp.LTM, which(LTM.bic[i,] %in% LTM.fit[i]))
}
# for ( i in 1:length(RL_LTMorig.fit)) {
#   ind.temp.RL_LTMorig <- rbind(ind.temp.RL_LTMorig,
#                                which(mseRL_LTMorig.temp[i,] %in% RL_LTMorig.fit[i]))
#
# }
for ( i in 1:length(RL_LTMpipe.fit)) {
ind.temp.RL_LTMpipe <- rbind(ind.temp.RL_LTMpipe,
which(RL_LTMpipe.bic[i,] %in% RL_LTMpipe.fit[i]))
}
for ( i in 1:length(RL_LTMstr.fit)) {
ind.temp.RL_LTMstr <- rbind(ind.temp.RL_LTMstr, which(RL_LTMstr.bic[i,] %in% RL_LTMstr.fit[i]))
}
#--------which model fits a participant most?
#1= RL; 2= LTM; 3 = RL_LTMpipe; 4 = RL_LTMstr
#--------------There are no min.col functions? Work around find the max after inverting:
participants.fit=c()
model.fits <- data.frame(RL.fit, LTM.fit, RL_LTMpipe.fit)#, RL_LTMstr.fit)#, fit.labels)
participant.min <- apply(model.fits, 1, min)
for (s in 1:nrow(model.fits)){
participants.fit =rbind(participants.fit, which(participant.min[s] == model.fits[s,]))
}
#fit plots
#participants.fit %>%
# hist(main='Counts of participants by model', xlab = ("1= RL; 2= LTM; 3=RL_LTM"), #lwd=4.3)
fit.labels <- ifelse(participants.fit==2, 'LTM',
ifelse(participants.fit==3, 'RL-LTM',
ifelse(participants.fit==4,'RL-LTMexplicit','RL')
)
)
models.name=c('RL', 'LTM', 'combined RL-LTM ')#, 'RL_LTM explicit')
data.frame('model'= participants.fit)  %>%
ggplot(aes(factor(model))) +
geom_bar() +
# ggtitle('Counts of participants by model') +
theme_bw(base_size = 20)+
scale_x_discrete(labels=models.name )+
xlab("Models")
model.fits %>%
melt() %>%
ggplot(aes(y=value,variable, group=variable)) +
geom_boxplot() +
ggtitle('BIC')+
xlab('model')+
theme_bw(base_family = 'Calibri') +
theme(legend.position='none') +
scale_colour_brewer( palette = "Set1")
data.frame('model'= participants.fit)  %>%
ggplot(aes(factor(model), fill=factor(model))) +
geom_bar() +
ggtitle('Counts of participants by model') +
theme_minimal(base_size = 20)+
scale_x_discrete(labels=models.name )+
xlab("Models")+
scale_fill_brewer( palette = "Paired")+
theme(legend.position='none')
participants.fit
#--------------There are no min.col functions? Work around find the max after inverting:
participants.fit=c()
model.fits <- data.frame(RL.fit, LTM.fit, RL_LTMpipe.fit, RL_LTMstr.fit)#, fit.labels)
participant.min <- apply(model.fits, 1, min)
for (s in 1:nrow(model.fits)){
participants.fit =rbind(participants.fit, which(participant.min[s] == model.fits[s,]))
}
fit.labels <- ifelse(participants.fit==2, 'LTM',
ifelse(participants.fit==3, 'RL-LTM',
ifelse(participants.fit==4,'RL-LTM biased','RL')
)
)
#fit plots
#participants.fit %>%
# hist(main='Counts of participants by model', xlab = ("1= RL; 2= LTM; 3=RL_LTM"), #lwd=4.3)
fit.labels <- ifelse(participants.fit==2, 'LTM',
ifelse(participants.fit==3, 'RL-LTM',
ifelse(participants.fit==4,'RL-LTM biased','RL')
)
)
data.frame('model'= participants.fit)  %>%
ggplot(aes(factor(model), fill=factor(model))) +
geom_bar() +
ggtitle('Counts of participants by model') +
theme_minimal(base_size = 20)+
scale_x_discrete(labels=models.name )+
xlab("Models")+
scale_fill_brewer( palette = "Paired")+
theme(legend.position='none')
model.fits %>%
melt() %>%
ggplot(aes(y=value,variable, group=variable)) +
geom_boxplot() +
ggtitle('BIC')+
xlab('model')+
theme_bw(base_family = 'Calibri') +
theme(legend.position='none') +
scale_colour_brewer( palette = "Set1")
models.name <- c('RL', 'LTM', ' RL-LTM', 'RL-LTM biased')
data.frame('model'= participants.fit)  %>%
ggplot(aes(factor(model), fill=factor(model))) +
geom_bar() +
ggtitle('Counts of participants by model') +
theme_minimal(base_size = 20)+
scale_x_discrete(labels=models.name )+
xlab("Models")+
scale_fill_brewer( palette = "Paired")+
theme(legend.position='none')
model.fits %>%
melt() %>%
ggplot(aes(y=value,variable, group=variable, fill=variable)) +
geom_boxplot() +
ggtitle('BIC')+
xlab('model')+
theme_bw(base_family = 'Calibri') +
theme(legend.position='none') +
scale_colour_brewer( palette = "Set1")
model.fits %>%
melt() %>%
ggplot(aes(y=value,variable, group=variable, fill=variable)) +
geom_boxplot() +
ggtitle('BIC')+
xlab('model')+
theme_bw(base_family = 'Calibri') +
theme(legend.position='none') +
scale_colour_brewer( palette = "Paired")
model.fits %>%
melt() %>%
ggplot(aes(y=value,variable, group=variable, fill=variable)) +
geom_boxplot() +
ggtitle('BIC')+
xlab('model')+
theme_bw(base_family = 'Calibri') +
scale_x_discrete(labels=models.name )+
theme(legend.position='none') +
scale_colour_brewer( palette = "Paired")
ind.temp.RL
#------Descriptive measures: learning rate (beta), accuracy learn & Test, differences between learn3 and learn 6
#--------select data for each level of parameters per model
RL.params        <- param.influence(RL.sim.dat, 'RL')
RLLTMpipe.params <- param.influence(RL_LTMpipe.sim.dat, 'RLLTM')
RLLTMstr.params  <- param.influence(RL_LTMstr.sim.dat, 'RLLTM')
LTM.params       <- param.influence(LTM.sim.dat, 'LTM')
model_desc_plot <- function(model) {
tmp.color = c('#ca0020','#f4a582' ,'#0571b0','#92c5de')
model %>%
melt(value.name = 'accuracy',id.vars=c('parameter','level')) %>%
ggplot(aes(level, accuracy, color=variable)) +
geom_point()+
geom_line() +
facet_grid('parameter')+
theme_minimal(base_size = 16, base_line_size = 1)+
scale_color_manual(values = tmp.color)+
ylim(c(.3,1)) +
theme(legend.position='top', legend.direction = 'horizontal')
}
ggarrange(model_desc_plot(RL.params),
model_desc_plot(RLLTMpipe.params),
model_desc_plot(RLLTMstr.params),
model_desc_plot(LTM.params),  ncol=4, common.legend = TRUE)
